Cracking Code Sorting Searching : 11 Algorithms Enhanced Efficiency - Armin Norouzi Armin Norouzi Work Experience Projects Education Awards Community Involvement Publications Teaching Blog Armin Norouzi Applied AI Software Engineer Google Contact waterloo , Canada ResearchGate LinkedIn GitHub ORCID Google Scholar Medium Cracking Code Sorting Searching : 11 Algorithms Enhanced Efficiency 41 minute read Published : June 21 , 2023 Unravel secrets sorting searching algorithms comprehensive post . Discover algorithms equip tools sort search data efficiently . Elevate data structure algorithms expertise invaluable resource . post , learn sorting algorithms Python . Let dive ! run post Google Colab link : 1 . Bubble Sort Bubble Sort simple comparison - based sorting algorithm . repeatedly steps list , compares adjacent elements , swaps wrong order . process repeated entire list sorted . def bubble_sort ( array ): n = len ( array ) range ( n - 1 ): j range ( n - - 1 ): array [ j ] > array [ j + 1 ] : array [ j ] , array [ j + 1 ] = array [ j + 1 ] , array [ j ] return array Explanation : bubble sort algorithm starts outer loop iterates array perform multiple passes . pass , inner loop compares adjacent elements swaps wrong order . end pass , largest element “ bubbles ” correct position end array . outer loop ( ) runs 0 n-2 ( inclusive ) n-1 passes , largest element correct position . inner loop ( j ) runs 0 n - i-2 ( inclusive ) largest elements sorted end array pass . current element array[j ] greater element array[j+1 ] , swap performed . process continues entire array sorted , swaps needed . Time Space Complexity : bubble sort algorithm worst - case time complexity O(n^2 ) , n size input array . involves nested loops , worst case , requires comparisons swaps pair elements array . space complexity O(1 ) algorithm uses constant additional space perform sorting . depend size input array . Test : arr = [ 5 , 3 , 8 , 2 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , bubble_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 5 , 8 ] arr = [ 1 , 2 , 3 , 4 , 5 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , bubble_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] arr = [ 10 , 5 , 2 , 8 , 3 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , bubble_sort ( arr ) ) # Output : [ 2 , 3 , 5 , 8 , 10 ] arr = [ 9 , 7 , 5 , 3 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , bubble_sort ( arr ) ) # Output : [ 1 , 3 , 5 , 7 , 9 ] Input : arr = [ 5 , 3 , 8 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 5 , 8 ] 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : arr = [ 10 , 5 , 2 , 8 , 3 ] 
 Output : [ 2 , 3 , 5 , 8 , 10 ] 
 Input : arr = [ 9 , 7 , 5 , 3 , 1 ] 
 Output : [ 1 , 3 , 5 , 7 , 9 ] 2 . Insertion Sort Insertion Sort simple comparison - based sorting algorithm . builds final sorted array item time iteratively inserting element proper position sorted array . def insertion_sort ( array ): range ( 1 , len ( array ) ): j = j > 0 array [ j ] < array [ j - 1 ] : array [ j ] , array [ j - 1 ] = array [ j - 1 ] , array [ j ] j -= 1 return array Explanation : insertion sort algorithm starts outer loop iterates second element element array . considers current element ( array[i ] ) moves correct position sorted array iteration . inner loop ( loop ) starts current element index ( j = ) continues moving beginning array ( j > 0 ) long current element smaller adjacent element ( array[j ] < array[j-1 ] ) . iteration inner loop , condition satisfied , swap performed current element position . process continues current element correct sorted position , outer loop moves element . Time space complexity : insertion sort algorithm worst - case time complexity O(n^2 ) , n size input array . worst case , element , traverse entire sorted portion array . space complexity O(1 ) algorithm uses constant additional space perform sorting . depend size input array . Test : arr = [ 5 , 3 , 8 , 2 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , insertion_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 5 , 8 ] arr = [ 1 , 2 , 3 , 4 , 5 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , insertion_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] arr = [ 10 , 5 , 2 , 8 , 3 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , insertion_sort ( arr ) ) # Output : [ 2 , 3 , 5 , 8 , 10 ] arr = [ 9 , 7 , 5 , 3 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , insertion_sort ( arr ) ) # Output : [ 1 , 3 , 5 , 7 , 9 ] Input : arr = [ 5 , 3 , 8 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 5 , 8 ] 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : arr = [ 10 , 5 , 2 , 8 , 3 ] 
 Output : [ 2 , 3 , 5 , 8 , 10 ] 
 Input : arr = [ 9 , 7 , 5 , 3 , 1 ] 
 Output : [ 1 , 3 , 5 , 7 , 9 ] 3 . selection sort Selection Sort simple comparison - based sorting algorithm . divides input array parts : sorted beginning unsorted end . repeatedly selects smallest ( largest ) element unsorted swaps element unsorted . def selection_sort ( array ): current_idx = 0 current_idx < len ( array ) - 1 : smallest_idx = current_idx range ( current_idx + 1 , len ( array ) ): array [ ] < array [ smallest_idx ] : smallest_idx = array [ current_idx ] , array [ smallest_idx ] = array [ smallest_idx ] , array [ current_idx ] current_idx + = 1 return array Explanation : selection sort algorithm starts outer loop represents boundary sorted unsorted parts array . iteration , finds smallest element unsorted swaps element current index . variable current_idx keeps track current index separates sorted unsorted parts . variable smallest_idx initialized current_idx , representing index smallest element found far . inner loop ( loop ) starts current_idx + 1 iterates remaining unsorted array . compares element element smallest_idx updates smallest_idx smaller element found . finding smallest element , swap performed element current_idx element smallest_idx . current_idx incremented , process continues entire array sorted . Time space complexity : selection sort algorithm worst - case time complexity O(n^2 ) , n size input array . involves nested loops , worst case , requires comparisons swaps pair elements array . space complexity O(1 ) algorithm uses constant additional space perform sorting . depend size input array . Test : arr = [ 5 , 3 , 8 , 2 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , selection_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 5 , 8 ] arr = [ 1 , 2 , 3 , 4 , 5 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , selection_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] arr = [ 10 , 5 , 2 , 8 , 3 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , selection_sort ( arr ) ) # Output : [ 2 , 3 , 5 , 8 , 10 ] arr = [ 9 , 7 , 5 , 3 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , selection_sort ( arr ) ) # Output : [ 1 , 3 , 5 , 7 , 9 ] Input : arr = [ 5 , 3 , 8 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 5 , 8 ] 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : arr = [ 10 , 5 , 2 , 8 , 3 ] 
 Output : [ 2 , 3 , 5 , 8 , 10 ] 
 Input : arr = [ 9 , 7 , 5 , 3 , 1 ] 
 Output : [ 1 , 3 , 5 , 7 , 9 ] 4 . Merge Sort Merge Sort divide - - conquer sorting algorithm recursively divides input array halves , sorts individually , merges single sorted array . Think recursive algorithm continuously splits array half divided . means array element left , dividing stop , i.e. base case stop recursion . array multiple elements , split array halves recursively invoke merge sort halves . Finally , halves sorted , merge operation applied . Merge operation process taking smaller sorted arrays combining eventually larger . def merge_sort ( array ): len ( array ) < = 1 : return array mid = len ( array ) // 2 left_arr = array [: mid ] right_arr = array [ mid :] return merge_sorted_arrays ( merge_sort ( left_arr ) , merge_sort ( right_arr ) ) def merge_sorted_arrays ( left_arr , right_arr ): sorted_arr = [ ] = j = 0 < len ( left_arr ) j < len ( right_arr ): left_arr [ ] < = right_arr [ j ] : sorted_arr . append ( left_arr [ ] ) + = 1 : sorted_arr . append ( right_arr [ j ] ) j + = 1 sorted_arr . extend ( left_arr [ :] ) sorted_arr . extend ( right_arr [ j :] ) return sorted_arr Explanation : merge sort algorithm follows recursive divide - - conquer approach : merge_sort function recursively called left right halves input array base case reached ( array element ) . array divided halves finding middle index ( mid ) , left right subarrays created . merge_sorted_arrays function responsible merging sorted left right arrays single sorted array . merging process occurs comparing elements arrays ( left_arr right_arr ) adding smaller element sorted_arr . exhausting arrays , remaining elements array appended sorted_arr . Finally , sorted array returned . Time space complexity : merge sort algorithm worst - case time complexity O(n log(n ) ) , n size input array . divides array halves recursively performs merging operations linear time . log(n ) factor arises recursive division , n factor arises merging step . space complexity O(n log(n ) ) additional space required recursive function calls merging process . recursive , additional space left right subarrays . , space usage cumulative recursive active time . Test : arr = [ 5 , 3 , 8 , 2 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , merge_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 5 , 8 ] arr = [ 1 , 2 , 3 , 4 , 5 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , merge_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] arr = [ 10 , 5 , 2 , 8 , 3 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , merge_sort ( arr ) ) # Output : [ 2 , 3 , 5 , 8 , 10 ] arr = [ 9 , 7 , 5 , 3 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , merge_sort ( arr ) ) # Output [ 1 , 3 , 5 , 7 , 9 ] Input : arr = [ 5 , 3 , 8 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 5 , 8 ] 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : arr = [ 10 , 5 , 2 , 8 , 3 ] 
 Output : [ 2 , 3 , 5 , 8 , 10 ] 
 Input : arr = [ 9 , 7 , 5 , 3 , 1 ] 
 Output : [ 1 , 3 , 5 , 7 , 9 ] 5 . Quick Sort Like Merge Sort , Quick Sort divide - - conquer sorting algorithm selects pivot element partitions array pivot . recursively sorts subarrays pivot entire array sorted . def quick_sort ( array ): quick_sort_helper ( array , 0 , len ( array ) - 1 ) return array def quick_sort_helper ( array , start , end ): # Base case : subarray 0 1 element start > = end : return # Choose element pivot pivot = start left = start + 1 right = end right > = left : # Swap elements wrong pivot array [ left ] > array [ pivot ] array [ right ] < array [ pivot ] : array [ left ] , array [ right ] = array [ right ] , array [ left ] array [ left ] < = array [ pivot ] : left + = 1 array [ right ] > = array [ pivot ] : right -= 1 # pivot sorted position array [ pivot ] , array [ right ] = array [ right ] , array [ pivot ] # Recursively sort subarrays is_left_subarray_smaller = right - 1 - start < end - ( right + 1 ) is_left_subarray_smaller : quick_sort_helper ( array , start , right - 1 ) quick_sort_helper ( array , right + 1 , end ) : quick_sort_helper ( array , right + 1 , end ) quick_sort_helper ( array , start , right - 1 ) Explanation : quick sort algorithm follows recursive divide - - conquer approach : quick_sort function calls quick_sort_helper function perform sorting . quick_sort_helper function takes start end indices subarray sorted . recursive , function selects pivot element ( case , element ) partitions array pivot . partitioning process performed pointers , left right , cross . elements compared pivot , wrong , swapped . partitioning process , pivot element sorted position , subarray divided parts . Depending size subarrays , function makes recursive calls sort smaller subarray minimize stack space recursion . process continues base case reached ( subarray 0 1 element ) . Time space complexity : quick sort algorithm average - case time complexity O(n log(n ) ) , n size input array . , worst case , time complexity O(n^2 ) pivot selection unfavorable . partitioning step takes linear time , recursive calls smaller subarrays . space complexity O(log(n ) ) average , representing stack space recursive calls . worst case , O(n ) recursive calls subarrays size close n. Test : arr = [ 5 , 3 , 8 , 2 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , quick_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 5 , 8 ] arr = [ 1 , 2 , 3 , 4 , 5 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , quick_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] arr = [ 10 , 5 , 2 , 8 , 3 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , quick_sort ( arr ) ) # Output : [ 2 , 3 , 5 , 8 , 10 ] arr = [ 9 , 7 , 5 , 3 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , quick_sort ( arr ) ) # Output [ 1 , 3 , 5 , 7 , 9 ] Input : arr = [ 5 , 3 , 8 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 5 , 8 ] 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : arr = [ 10 , 5 , 2 , 8 , 3 ] 
 Output : [ 2 , 3 , 5 , 8 , 10 ] 
 Input : arr = [ 9 , 7 , 5 , 3 , 1 ] 
 Output : [ 1 , 3 , 5 , 7 , 9 ] 6 . Heap Sort ( Binary Heap ) Heap Sort comparison - based sorting algorithm uses binary heap data structure sort elements . builds max heap input array repeatedly extracts maximum element heap , swapping element heap reducing heap size . process continues entire array sorted . def heapify ( arr , n , ): largest = left = 2 * + 1 right = 2 * + 2 left < n arr [ left ] > arr [ largest ] : largest = left right < n arr [ right ] > arr [ largest ] : largest = right largest ! = : arr [ ] , arr [ largest ] = arr [ largest ] , arr [ ] heapify ( arr , n , largest ) def heap_sort ( array ): n = len ( array ) # Build max heap range ( n // 2 - 1 , - 1 , - 1 ): heapify ( array , n , ) # Extract elements heap range ( n - 1 , 0 , - 1 ): array [ ] , array [ 0 ] = array [ 0 ] , array [ ] heapify ( array , , 0 ) return array Explanation : heap sort algorithm divided main steps : heapify function responsible creating max heap unsorted array . takes parameters : array , size heap ( n ) , index current element ( ) considered . compares element index left right child ( exist ) swaps larger child necessary . process repeated recursively ensure heap property maintained . heap_sort function builds max heap input array calling heapify non - leaf nodes starting non - leaf node root . building max heap , repeatedly extracts maximum element heap swapping element reducing heap size . step performed reverse order sort array ascending order . final sorted array returned . Time space complexity : heap sort algorithm worst - case time complexity O(n log(n ) ) , n size input array . build heap step extract max step O(log(n ) ) time , performed n times . space complexity O(1 ) sorting place , additional data structures . Test : arr = [ 5 , 3 , 8 , 2 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , heap_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 5 , 8 ] arr = [ 1 , 2 , 3 , 4 , 5 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , heap_sort ( arr ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] arr = [ 10 , 5 , 2 , 8 , 3 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , heap_sort ( arr ) ) # Output : [ 2 , 3 , 5 , 8 , 10 ] arr = [ 9 , 7 , 5 , 3 , 1 ] print ( f " Input : arr = { arr } " ) print ( " Output : " , heap_sort ( arr ) ) # Output [ 1 , 3 , 5 , 7 , 9 ] Input : arr = [ 5 , 3 , 8 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 5 , 8 ] 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : arr = [ 10 , 5 , 2 , 8 , 3 ] 
 Output : [ 2 , 3 , 5 , 8 , 10 ] 
 Input : arr = [ 9 , 7 , 5 , 3 , 1 ] 
 Output : [ 1 , 3 , 5 , 7 , 9 ] 7 . Topological Sort Academic definition : Topological Sort algorithm order nodes directed acyclic graph ( DAG ) directed edge ( u , v ) , node u comes node v ordering . commonly tasks dependencies , task scheduling determining order courses curriculum . def topological_sort ( jobs , deps ): graph = create_job_graph ( jobs , deps ) return get_ordered_jobs ( graph ) def create_job_graph ( jobs , deps ): graph = JobGraph ( jobs ) prereq , job deps : graph . add_prereq ( job , prereq ) return graph def get_ordered_jobs ( graph ): ordered_jobs = [ ] nodes = graph . nodes nodes : node = nodes . pop ( ) contains_cycle = depth_first_traverse ( node , ordered_jobs ) contains_cycle : return [ ] return ordered_jobs def depth_first_traverse ( node , ordered_jobs ): node . visited : return False node . visiting : return True node . visiting = True prereq_node node . prereqs : contains_cycle = depth_first_traverse ( prereq_node , ordered_jobs ) contains_cycle : return True node . visited = True node . visiting = False ordered_jobs . append ( node . job ) return False class JobGraph : def _ _ init _ _ ( self , jobs ): self . nodes = [ ] self . graph = { } job jobs : self . add_node ( job ) def add_prereq ( self , job , prereq ): job_node = self . get_node ( job ) prereq_node = self . get_node ( prereq ) job_node . prereqs . append ( prereq_node ) def add_node ( self , job ): self . graph [ job ] = JobNode ( job ) self . nodes . append ( self . graph [ job ] ) def get_node ( self , job ): job self . graph : self . add_node ( job ) return self . graph [ job ] class JobNode : def _ _ init _ _ ( self , job ): self . job = job self . prereqs = [ ] self . visited = False self . visiting = False Explanation : topological sort algorithm uses depth - search ( DFS ) traverse graph find valid ordering jobs . code summarized follows : topological_sort function entry point algorithm . takes list jobs dependencies returns ordered jobs . create_job_graph function creates directed graph JobGraph object . adds nodes job dependencies edges . get_ordered_jobs function performs topological sort calling depth_first_traverse node graph . starts node explores dependencies recursively . depth_first_traverse function checks cycles maintaining flags : visited visiting . returns True cycle detected False . adds jobs ordered_jobs list correct order . JobGraph class represents graph provides methods add nodes edges . uses hash table ( graph ) map job names corresponding nodes ( JobNode ) . JobNode class represents job node graph . contains job , list prerequisite nodes , flags represent node status traversal . Time space complexity : time complexity topological sort algorithm O(j + d ) , j number jobs d number dependencies . algorithm traverses job dependencies , resulting linear time complexity . space complexity O(j + d ) algorithm constructs graph representation jobs dependencies . space store nodes , edges , additional data structures traversal . test : jobs = [ 1 , 2 , 3 , 4 ] deps = [ ( 1 , 2 ) , ( 1 , 3 ) , ( 3 , 2 ) , ( 4 , 2 ) , ( 4 , 3 ) ] print ( f " Input : jobs = { jobs } , deps = { deps } " ) print ( " Output : " , topological_sort ( jobs , deps ) ) # Output : [ 4 , 1 , 3 , 2 ] jobs = [ 1 , 2 , 3 , 4 , 5 ] deps = [ ( 1 , 2 ) , ( 2 , 3 ) , ( 3 , 4 ) , ( 4 , 5 ) ] print ( f " Input : jobs = { jobs } , deps = { deps } " ) print ( " Output : " , topological_sort ( jobs , deps ) ) # Output : [ 1 , 2 , 3 , 4 , 5 ] jobs = [ 1 , 2 , 3 , 4 ] deps = [ ( 1 , 2 ) , ( 2 , 3 ) , ( 3 , 4 ) , ( 4 , 2 ) ] print ( f " Input : jobs = { jobs } , deps = { deps } " ) print ( " Output : " , topological_sort ( jobs , deps ) ) # Output : [ ] jobs = [ 1 , 2 , 3 ] deps = [ ( 1 , 2 ) , ( 2 , 3 ) , ( 3 , 1 ) ] print ( f " Input : jobs = { jobs } , deps = { deps } " ) print ( " Output : " , topological_sort ( jobs , deps ) ) # Output : [ ] Input : jobs = [ 1 , 2 , 3 , 4 ] , deps = [ ( 1 , 2 ) , ( 1 , 3 ) , ( 3 , 2 ) , ( 4 , 2 ) , ( 4 , 3 ) ] 
 Output : [ 4 , 1 , 3 , 2 ] 
 Input : jobs = [ 1 , 2 , 3 , 4 , 5 ] , deps = [ ( 1 , 2 ) , ( 2 , 3 ) , ( 3 , 4 ) , ( 4 , 5 ) ] 
 Output : [ 1 , 2 , 3 , 4 , 5 ] 
 Input : jobs = [ 1 , 2 , 3 , 4 ] , deps = [ ( 1 , 2 ) , ( 2 , 3 ) , ( 3 , 4 ) , ( 4 , 2 ) ] 
 Output : [ ] 
 Input : jobs = [ 1 , 2 , 3 ] , deps = [ ( 1 , 2 ) , ( 2 , 3 ) , ( 3 , 1 ) ] 
 Output : [ ] 8 . Radix Sort Radix Sort non - comparative sorting algorithm sorts numbers processing individual digits . starts sorting numbers based significant digit gradually moves significant digit . algorithm repeatedly uses stable sorting algorithm , Counting Sort , sort numbers based digit . def radix_sort ( array ): len ( array ) = = 0 : return array max_number = max ( array ) num_digits = len ( str ( max_number ) ) digit range ( num_digits ): counting_sort ( array , digit ) return array def counting_sort ( array , digit ): sorted_array = [ 0 ] * len ( array ) count_array = [ 0 ] * 10 num array : count_index = ( num // ( 10 * * digit ) ) % 10 count_array [ count_index ] + = 1 idx range ( 1 , 10 ): count_array [ idx ] + = count_array [ idx - 1 ] idx range ( len ( array ) - 1 , - 1 , - 1 ): count_index = ( array [ idx ] // ( 10 * * digit ) ) % 10 count_array [ count_index ] -= 1 sorted_index = count_array [ count_index ] sorted_array [ sorted_index ] = array [ idx ] idx range ( len ( array ) ): array [ idx ] = sorted_array [ idx ] Explanation : radix sort algorithm processes digits numbers significant digit significant digit . code summarized follows : radix_sort function entry point algorithm . checks input array finds maximum number determine number - digits largest number . performs radix sort calling counting_sort digit position . counting_sort function subroutine sort numbers based current digit . creates count array count occurrences digit value ( 0 9 ) current digit position . count array modified store positions digit value placed sorted array . sorted array constructed iterating input array reverse order placing element correct position based count array . Finally , original array updated sorted elements . Time space complexity : time complexity radix sort O(d * ( n + k ) ) , n number elements array , d number digits maximum number , k range digit values ( typically 10 decimal digits ) . algorithm performs counting sort digit position , takes O(n + k ) time . space complexity O(n + k ) additional space required sorted array , count array , variables . space complexity increases range digit values . Test : array = [ 170 , 45 , 75 , 90 , 802 , 24 , 2 , 66 ] print ( f " Input : { array } " ) radix_sort ( array ) print ( " Output : " , array ) # Output : [ 2 , 24 , 45 , 66 , 75 , 90 , 170 , 802 ] array = [ 321 , 56 , 789 , 12 , 456 , 234 , 901 ] print ( f " Input : { array } " ) radix_sort ( array ) print ( " Output : " , array ) # Output : [ 12 , 56 , 234 , 321 , 456 , 789 , 901 ] array = [ 9 , 8 , 7 , 6 , 5 , 4 , 3 , 2 , 1 ] print ( f " Input : { array } " ) radix_sort ( array ) print ( " Output : " , array ) # Output : [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] array = [ 1000 , 100 , 10 , 1 , 10000 , 100000 ] print ( f " Input : { array } " ) radix_sort ( array ) print ( " Output : " , array ) # Output : [ 1 , 10 , 100 , 1000 , 10000 , 100000 ] Input : [ 170 , 45 , 75 , 90 , 802 , 24 , 2 , 66 ] 
 Output : [ 2 , 24 , 45 , 66 , 75 , 90 , 170 , 802 ] 
 Input : [ 321 , 56 , 789 , 12 , 456 , 234 , 901 ] 
 Output : [ 12 , 56 , 234 , 321 , 456 , 789 , 901 ] 
 Input : [ 9 , 8 , 7 , 6 , 5 , 4 , 3 , 2 , 1 ] 
 Output : [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ] 
 Input : [ 1000 , 100 , 10 , 1 , 10000 , 100000 ] 
 Output : [ 1 , 10 , 100 , 1000 , 10000 , 100000 ] 9 . Binary Search Binary search efficient algorithm find specific target value sorted array . works repeatedly dividing search interval half target value found interval . def binary_search ( arr , target ): left = 0 right = len ( arr ) - 1 left < = right : mid = ( left + right ) // 2 target = = arr [ mid ] : return mid elif target < arr [ mid ] : right = mid - 1 : left = mid + 1 return - 1 Explanation : binary search algorithm starts initial left index right index representing boundaries search interval . calculates middle index compares target value ( target ) value middle index array ( arr[mid ] ) . target value found , returns index ( mid ) . target value middle element , updates right index mid - 1 search left half interval . target value greater middle element , updates left index mid + 1 search right half interval . process continues target value found interval ( left index surpasses right index ) . target value found , function returns -1 . Time Space Complexity : binary search algorithm time complexity O(log n ) , n size input array . performs halving search interval iteration , resulting logarithmic time complexity . space complexity O(1 ) algorithm uses fixed additional space store left , right , mid indices . depend size input array . Test : arr = [ 1 , 2 , 3 , 4 , 5 ] x = 3 print ( f " Input : arr = { arr } , x = { x } " ) print ( " Output : " , binary_search ( arr , x ) ) # Output : 2 arr = [ 1 , 2 , 3 , 4 , 5 ] x = 6 print ( f " Input : arr = { arr } , x = { x } " ) print ( " Output : " , binary_search ( arr , x ) ) # Output : -1 arr = [ 10 , 20 , 30 , 40 , 50 , 60 ] x = 40 print ( f " Input : arr = { arr } , x = { x } " ) print ( " Output : " , binary_search ( arr , x ) ) # Output : 3 arr = [ 10 , 20 , 30 , 40 , 50 , 60 ] x = 25 print ( f " Input : arr = { arr } , x = { x } " ) print ( " Output : " , binary_search ( arr , x ) ) # Output : -1 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] , x = 3 
 Output : 2 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] , x = 6 
 Output : -1 
 Input : arr = [ 10 , 20 , 30 , 40 , 50 , 60 ] , x = 40 
 Output : 3 
 Input : arr = [ 10 , 20 , 30 , 40 , 50 , 60 ] , x = 25 
 Output : -1 10 . Find Kth Smallest / Largest Element Unsorted Array Method 1 : Sorting Algorithm Select Kth Time Complexity : O(nlog(n ) ) Explanation : method involves sorting array sorting algorithm time complexity O(nlog(n ) ) . array sorted , kth smallest largest element easily identified accessing corresponding index . Code Explanation : method explicitly provided given code . , involves sorting array sorting algorithm ( e.g. , merge sort , quicksort ) returning kth element . Method 2 : Heap Time Complexity : O(nlog(k ) ) Explanation : method utilizes min - heap efficiently find kth smallest element unsorted array . maintains heap size k , smallest k elements stored . element array , heap size k , element added heap . heap size reaches k , smallest element replaced current element larger , ensuring heap contains k smallest elements . smallest element heap kth smallest element array . import heapq def kth_smallest ( arr , k ): # Initialize min - heap heap = [ ] # Iterate element array value arr : # Push negative value heap # simulate max - heap behavior len ( heap ) < k : heapq . heappush ( heap , - value ) : # heap size reaches k , push current # element simultaneously pop smallest element heapq . heappushpop ( heap , - value ) # Return negation element heap # retrieve kth smallest element return - heap [ 0 ] Explanation : function kth_smallest takes array arr integer k input . min - heap , represented heap list , initialized store k smallest elements encountered far . function iterates element value array . size heap k , negative value current element pushed heap heapq.heappush , simulating max - heap behavior . heap size reaches k , current element pushed heap heapq.heappushpop , simultaneously pushes element pops smallest element . ensures heap contains k smallest elements encountered far . iterating elements , kth smallest element present heap . negation element returned final result , giving kth smallest element original array . Test : arr = [ 7 , 2 , 1 , 6 , 8 , 5 ] k = 3 print ( f " Array : { arr } " ) print ( f " kth Smallest Element ( { k } ): { kth_smallest ( arr , k ) } " ) # Output : kth Smallest Element ( 3 ): 5 arr = [ 9 , 4 , 2 , 7 , 1 , 5 ] k = 2 print ( f " Array : { arr } " ) print ( f " kth Smallest Element ( { k } ): { kth_smallest ( arr , k ) } " ) # Output : kth Smallest Element ( 2 ): 2 arr = [ 3 , 9 , 1 , 6 , 2 , 8 ] k = 4 print ( f " Array : { arr } " ) print ( f " kth Smallest Element ( { k } ): { kth_smallest ( arr , k ) } " ) # Output : kth Smallest Element ( 4 ): 6 Array : [ 7 , 2 , 1 , 6 , 8 , 5 ] 
 kth Smallest Element ( 3 ): 5 
 Array : [ 9 , 4 , 2 , 7 , 1 , 5 ] 
 kth Smallest Element ( 2 ): 2 
 Array : [ 3 , 9 , 1 , 6 , 2 , 8 ] 
 kth Smallest Element ( 4 ): 6 Method 3 : Pivot Partitioning Concept ( Similar Quick Sort ) Time Complexity : O(n ) average , O(n^2 ) worst case Explanation : method based partitioning concept quicksort . selects pivot element partitions array elements smaller pivot left elements larger pivot right . comparing pivot position k , determine kth smallest element lies left right subarray . process recursively applied corresponding subarray kth element found . def kth_smallest ( arr , k ): left = 0 right = len ( arr ) - 1 return kth_smallest_helper ( arr , left , right , k ) def kth_smallest_helper ( arr , left , right , k ): k > 0 k < = right - left + 1 : # Partition array element position pivot element sorted array pos = partition ( arr , left , right ) # position k , pivot element kth smallest element pos - left = = k - 1 : return arr [ pos ] # position greater k , recur left subarray pos - left > k - 1 : return kth_smallest_helper ( arr , left , pos - 1 , k ) # , recur right subarray return kth_smallest_helper ( arr , pos + 1 , right , k - pos + left - 1 ) # k greater number elements array , return -1 return - 1 def partition ( arr , left , right ): pivot = arr [ right ] # Choose element pivot = left j range ( left , right ): arr [ j ] < = pivot : # Swap arr[i ] arr[j ] place elements smaller pivot left arr [ ] , arr [ j ] = arr [ j ] , arr [ ] + = 1 # Swap arr[i ] arr[right ] place pivot element correct position arr [ ] , arr [ right ] = arr [ right ] , arr [ ] return Explanation : function kth_smallest takes array arr integer k input . function kth_smallest_helper recursive helper function performs actual calculation . k valid range ( greater 0 equal number elements array ) , function proceeds . array partitioned element ( arr[right ] ) pivot partition function . partition function rearranges elements elements smaller pivot placed left , elements greater pivot placed right . position pivot element sorted array obtained . position pivot element equal k - 1 , means pivot element kth smallest element , returned . position pivot element greater k - 1 , means kth smallest element lies left subarray , function recursively calls kthSmallest_helper left subarray . position pivot element k - 1 , means kth smallest element lies right subarray , function recursively calls kth_smallest_helper right subarray , adjusting value k accordingly . k outside valid range , indicating fewer elements array k , function returns -1 . partition function follows traditional partitioning process QuickSort . chooses element pivot . initializes index leftmost element ( left ) iterates left right-1 variable j . element index j equal pivot , swaps elements indices j , increments . process ensures elements smaller pivot placed left . Finally , swaps pivot element ( arr[right ] ) element index pivot correct sorted position . function returns index , represents position pivot rearranged array . Test : arr = [ 7 , 2 , 1 , 6 , 8 , 5 ] k = 3 print ( f " Array : { arr } " ) print ( f " kth Smallest Element ( { k } ): { kth_smallest ( arr , k ) } " ) # Output : kth Smallest Element ( 3 ): 5 arr = [ 9 , 4 , 2 , 7 , 1 , 5 ] k = 2 print ( f " Array : { arr } " ) print ( f " kth Smallest Element ( { k } ): { kth_smallest ( arr , k ) } " ) # Output : kth Smallest Element ( 2 ): 2 arr = [ 3 , 9 , 1 , 6 , 2 , 8 ] k = 4 print ( f " Array : { arr } " ) print ( f " kth Smallest Element ( { k } ): { kth_smallest ( arr , k ) } " ) # Output : kth Smallest Element ( 4 ): 6 Array : [ 7 , 2 , 1 , 6 , 8 , 5 ] 
 kth Smallest Element ( 3 ): 5 
 Array : [ 9 , 4 , 2 , 7 , 1 , 5 ] 
 kth Smallest Element ( 2 ): 2 
 Array : [ 3 , 9 , 1 , 6 , 2 , 8 ] 
 kth Smallest Element ( 4 ): 6 11 . Interpolation Search Interpolation search algorithm search target element sorted array . improves performance binary search formula estimate likely position target array . algorithm works best uniformly distributed arrays . def interpolation_search ( arr , target ): left = 0 right = len ( arr ) - 1 return interpolation_search_helper ( arr , left , right , target ) def interpolation_search_helper ( arr , left , right , target ): left < = right target > = arr [ left ] target < = arr [ right ] : pos = left + ( ( right - left ) // ( arr [ right ] - arr [ left ] ) ) * ( target - arr [ left ] ) arr [ pos ] = = target : return pos arr [ pos ] < target : return interpolation_search_helper ( arr , pos + 1 , right , target ) arr [ pos ] > target : return interpolation_search_helper ( arr , left , pos - 1 , target ) return - 1 Explanation : interpolation_search function takes array ( arr ) target value ( target ) input . initializes left pointer beginning array right pointer end array . calls interpolation_search_helper function parameters . interpolation_search_helper function checks target value range defined left right pointers range values array . , calculates estimated position ( pos ) target interpolation formula . interpolation formula calculates position considering proportion target value difference left element difference left right elements . formula assumes uniform distribution values array . value estimated position ( arr[pos ] ) matches target value , returns position . estimated value smaller target value , recursively calls interpolation_search_helper function updated left pointer ( pos + 1 ) right pointer . estimated value larger target value , recursively calls interpolation_search_helper function updated right pointer ( pos - 1 ) left pointer . target value found given range left pointer exceeds right pointer , function returns -1 indicate target value found array . Time space complexity : time complexity interpolation search O(log(log n ) ) average case , n size input array . , worst case , data uniformly distributed , time complexity O(n ) . space complexity algorithm O(1 ) require additional data structures . Test : arr = [ 2 , 4 , 6 , 8 , 10 ] target = 6 print ( " Input : arr = " , arr , " target = " , target ) print ( " Output : " , interpolation_search ( arr , target ) ) # Expected output : 2 arr = [ 1 , 3 , 5 , 7 , 9 ] target = 10 print ( " Input : arr = " , arr , " target = " , target ) print ( " Output : " , interpolation_search ( arr , target ) ) # Expected output : -1 arr = [ 1 , 2 , 3 , 4 , 5 ] target = 1 print ( " Input : arr = " , arr , " target = " , target ) print ( " Output : " , interpolation_search ( arr , target ) ) # Expected output : 0 Input : arr = [ 2 , 4 , 6 , 8 , 10 ] target = 6 
 Output : 2 
 Input : arr = [ 1 , 3 , 5 , 7 , 9 ] target = 10 
 Output : -1 
 Input : arr = [ 1 , 2 , 3 , 4 , 5 ] target = 1 
 Output : 0 Tags : Algorithms , Data Structures , Sorting Searching Share Twitter Facebook LinkedIn Previous Enjoy Mastering Dynamic Programming : 4 Essential Algorithms Optimal Solutions 19 minute read Published : June 29 , 2023 Dive world dynamic programming insightful post . Explore essential algorithms leverage dynamic programming solve complex problems optimally . Enhance understanding data structure algorithms comprehensive guide . Mastering Heaps : 5 Essential Algorithms Optimal Performance 37 minute read Published : June 16 , 2023 Immerse world heaps informative post . Explore essential algorithms leverage heaps optimize performance efficiency . Unlock potential heaps data structure algorithms toolkit indispensable guide . Mastering Linked Lists : 11 Algorithms Efficient Data Manipulation 44 minute read Published : June 13 , 2023 Unlock potential linked lists comprehensive post . Explore powerful algorithms revolutionize way manipulate operate linked list data structures . Elevate data structure algorithms expertise transformative content . post focuses linked lists demonstrates operations performed linked lists Python . linked list fundamental data structure composed nodes , node contains value reference node list . notebook covers basics linked lists , including insertion , deletion , traversal , searching operations . run post Google Colab link : Unraveling Secrets Trees Graphs : 3 Essential Algorithms Revealed 30 minute read Published : June 07 , 2023 Embark journey fascinating world trees graphs enlightening post . Discover essential algorithms empower traverse , analyze , manipulate tree graph structures effectively . Strengthen knowledge data structure algorithms invaluable resource . Sitemap Follow : GitHub Feed © 2024 Armin Norouzi . Powered Jekyll & AcademicPages , fork Minimal Mistakes .