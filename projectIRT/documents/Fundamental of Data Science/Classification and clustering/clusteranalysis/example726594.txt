Cluster analysis - Wikipedia Jump content Main menu Main menu sidebar hide Navigation Main page Contents Current events Random article Wikipedia Contact Contribute Help Learn edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log Personal tools Donate Create account Log Pages logged editors learn Contributions Talk Contents sidebar hide ( ) 1 Definition 2 Algorithms Toggle Algorithms subsection 2.1 Connectivity - based clustering ( hierarchical clustering ) 2.2 Centroid - based clustering 2.3 Model - based clustering 2.4 Density - based clustering 2.5 Grid - based clustering 2.6 Recent developments 3 Evaluation assessment Toggle Evaluation assessment subsection 3.1 Internal evaluation 3.1.1 Davies – Bouldin index 3.1.2 Dunn index 3.1.3 Silhouette coefficient 3.2 External evaluation 3.2.1 Purity 3.2.2 Rand index 3.2.3 F - measure 3.2.4 Jaccard index 3.2.5 Dice index 3.2.6 Fowlkes – Mallows index 3.2.7 Chi Index 3.2.8 Mutual Information 3.2.9 Confusion matrix 3.2.10 Validity Measure 3.3 Cluster tendency 4 Applications Toggle Applications subsection 4.1 Biology , computational biology bioinformatics 4.2 Medicine 4.3 Business marketing 4.4 World Wide Web 4.5 Computer science 4.6 Social science 4.7 5 Toggle subsection 5.1 Specialized types cluster analysis 5.2 Techniques cluster analysis 5.3 Data projection preprocessing 5.4 6 References Toggle table contents Cluster analysis 40 languages العربية বাংলা Български Català Čeština Dansk Deutsch Eesti Ελληνικά Español Euskara فارسی Français 한국어 Հայերեն हिन्दी Hrvatski Bahasa Indonesia Italiano עברית Latviešu Magyar Nederlands 日本語 Norsk bokmål Polski Português Русский Simple English Slovenčina Slovenščina Српски / srpski Srpskohrvatski / српскохрватски Svenska ไทย Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools sidebar hide Actions Read Edit View history General links Related changes Upload file Permanent link Page information Cite page shortened URL Download QR code Print / export Download PDF Printable version projects Wikimedia Commons Wikidata item Appearance sidebar hide Wikipedia , free encyclopedia Grouping set objects similarity result cluster analysis shown coloring squares clusters series Machine learning data mining Paradigms Supervised learning Unsupervised learning Semi - supervised learning Self - supervised learning Reinforcement learning Meta - learning Online learning Batch learning Curriculum learning Rule - based learning Neuro - symbolic AI Neuromorphic engineering Quantum machine learning Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning rank Grammar induction Ontology learning Multimodal learning Supervised learning ( classification • regression ) Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest k -NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine ( RVM ) Support vector machine ( SVM ) Clustering BIRCH CURE Hierarchical k -means Fuzzy Expectation – maximization ( EM ) DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD t - SNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC k -NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network U - Net LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM ( ECRAM ) Reinforcement learning Q - learning SARSA Temporal difference ( TD ) Multi - agent Self - play Learning humans Active learning Crowdsourcing Human - - - loop RLHF Model diagnostics Coefficient determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Bias – variance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Topological deep learning Journals conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary artificial intelligence List datasets machine - learning research List datasets computer vision image processing Outline machine learning v t e Cluster analysis clustering data analyzing technique task grouping set objects way objects group ( called cluster ) similar ( specific sense defined analyst ) groups ( clusters ) . main task exploratory data analysis , common technique statistical data analysis , fields , including pattern recognition , image analysis , information retrieval , bioinformatics , data compression , computer graphics machine learning . Cluster analysis refers family algorithms tasks specific algorithm . achieved algorithms differ significantly understanding constitutes cluster efficiently find . Popular notions clusters include groups small distances cluster members , dense areas data space , intervals particular statistical distributions . Clustering formulated multi - objective optimization problem . appropriate clustering algorithm parameter settings ( including parameters distance function use , density threshold number expected clusters ) depend individual data set intended use results . Cluster analysis automatic task , iterative process knowledge discovery interactive multi - objective optimization involves trial failure . necessary modify data preprocessing model parameters result achieves desired properties . term clustering , number terms similar meanings , including automatic classification , numerical taxonomy , botryology ( Greek : βότρυς ' grape ' ) , typological analysis , community detection . subtle differences use results : data mining , resulting groups matter interest , automatic classification resulting discriminative power interest . Cluster analysis originated anthropology Driver Kroeber 1932 [ 1 ] introduced psychology Joseph Zubin 1938 [ 2 ] Robert Tryon 1939 [ 3 ] famously Cattell beginning 1943 [ 4 ] trait theory classification personality psychology . Definition [ edit ] notion " cluster " precisely defined , reasons clustering algorithms . [ 5 ] common denominator : group data objects . , different researchers employ different cluster models , cluster models different algorithms given . notion cluster , found different algorithms , varies significantly properties . Understanding " cluster models " key understanding differences algorithms . Typical cluster models include : Connectivity model s : example , hierarchical clustering builds models based distance connectivity . Centroid model s : example , k - means algorithm represents cluster single mean vector . Distribution model s : clusters modeled statistical distributions , multivariate normal distributions expectation - maximization algorithm . Density model s : example , DBSCAN OPTICS defines clusters connected dense regions data space . Subspace model s : biclustering ( known co - clustering - mode - clustering ) , clusters modeled cluster members relevant attributes . Group model s : algorithms provide refined model results provide grouping information . Graph - based model s : clique , , subset nodes graph nodes subset connected edge considered prototypical form cluster . Relaxations complete connectivity requirement ( fraction edges missing ) known quasi - cliques , HCS clustering algorithm . Signed graph models : path signed graph sign product signs edges . assumptions balance theory , edges change sign result bifurcated graph . weaker " clusterability axiom " ( cycle exactly negative edge ) yields results clusters , subgraphs positive edges . [ 6 ] Neural model s : - known unsupervised neural network self - organizing map models usually characterized similar models , including subspace models neural networks implement form Principal Component Analysis Independent Component Analysis . " clustering " essentially set clusters , usually containing objects data set . Additionally , specify relationship clusters , example , hierarchy clusters embedded . Clusterings roughly distinguished : Hard clustering : object belongs cluster Soft clustering ( : fuzzy clustering ): object belongs cluster certain degree ( example , likelihood belonging cluster ) finer distinctions possible , example : Strict partitioning clustering : object belongs exactly cluster Strict partitioning clustering outliers : objects belong cluster ; case considered outliers Overlapping clustering ( : alternative clustering , multi - view clustering ): objects belong cluster ; usually involving hard clusters Hierarchical clustering : objects belong child cluster belong parent cluster Subspace clustering : overlapping clustering , uniquely defined subspace , clusters expected overlap Algorithms [ edit ] Main category : Cluster analysis algorithms listed , clustering algorithms categorized based cluster model . following overview list prominent examples clustering algorithms , possibly 100 published clustering algorithms . provide models clusters easily categorized . overview algorithms explained Wikipedia found list statistics algorithms . objectively " correct " clustering algorithm , noted , " clustering eye beholder . " [ 5 ] fact , axiomatic approach clustering demonstrates impossible clustering method meet fundamental properties simultaneously : scale invariance ( results remain unchanged proportional scaling distances ) , richness ( possible partitions data achieved ) , consistency distances clustering structure . [ 7 ] appropriate clustering algorithm particular problem needs chosen experimentally , mathematical reason prefer cluster model . algorithm designed kind model generally fail data set contains radically different kind model . [ 5 ] example , k - means find non - convex clusters . [ 5 ] traditional clustering methods assume clusters exhibit spherical , elliptical convex shape . [ 8 ] Connectivity - based clustering ( hierarchical clustering ) [ edit ] Main article : Hierarchical clustering Connectivity - based clustering , known hierarchical clustering , based core idea objects related nearby objects objects farther away . algorithms connect " objects " form " clusters " based distance . cluster described largely maximum distance needed connect parts cluster . different distances , different clusters form , represented dendrogram , explains common " hierarchical clustering " comes : algorithms provide single partitioning data set , instead provide extensive hierarchy clusters merge certain distances . dendrogram , y - axis marks distance clusters merge , objects placed x - axis clusters mix . Connectivity - based clustering family methods differ way distances computed . Apart usual choice distance functions , user needs decide linkage criterion ( cluster consists multiple objects , multiple candidates compute distance ) use . Popular choices known single - linkage clustering ( minimum object distances ) , complete linkage clustering ( maximum object distances ) , UPGMA WPGMA ( " Unweighted Weighted Pair Group Method Arithmetic Mean " , known average linkage clustering ) . Furthermore , hierarchical clustering agglomerative ( starting single elements aggregating clusters ) divisive ( starting complete data set dividing partitions ) . methods produce unique partitioning data set , hierarchy user needs choose appropriate clusters . robust outliers , additional clusters cause clusters merge ( known " chaining phenomenon " , particular single - linkage clustering ) . general case , complexity O ( n 3 ) { \displaystyle { \mathcal { O}}(n^{3 } ) } agglomerative clustering O ( 2 n − 1 ) { \displaystyle { \mathcal { O}}(2^{n-1 } ) } divisive clustering , [ 9 ] makes slow large data sets . special cases , optimal efficient methods ( complexity O ( n 2 ) { \displaystyle { \mathcal { O}}(n^{2 } ) } ) known : SLINK [ 10 ] single - linkage CLINK [ 11 ] complete - linkage clustering . Linkage clustering examples Single - linkage Gaussian data . 35 clusters , biggest cluster starts fragmenting smaller parts , connected second largest single - link effect . Single - linkage density - based clusters . 20 clusters extracted , contain single elements , linkage clustering notion " noise " . Centroid - based clustering [ edit ] Main article : k - means clustering centroid - based clustering , cluster represented central vector , necessarily member data set . number clusters fixed k , k -means clustering gives formal definition optimization problem : find k cluster centers assign objects nearest cluster center , squared distances cluster minimized . optimization problem known NP - hard , common approach search approximate solutions . particularly - known approximate method Lloyd algorithm , [ 12 ] referred " k - means algorithm " ( algorithm introduced ) . find local optimum , commonly run multiple times different random initializations . Variations k -means include optimizations choosing best multiple runs , restricting centroids members data set ( k -medoids ) , choosing medians ( k -medians clustering ) , choosing initial centers randomly ( k -means++ ) allowing fuzzy cluster assignment ( fuzzy c - means ) . k -means - type algorithms require number clusters – k – specified advance , considered biggest drawbacks algorithms . Furthermore , algorithms prefer clusters approximately similar size , assign object nearest centroid ; yielding improperly cut borders clusters . happens primarily algorithm optimizes cluster centers , cluster borders . Steps involved centroid - based clustering algorithm : Choose , random , k distinct clusters . initial centroids improved . Suppose set observations , ( x 1 , x 2 , ... , x n ) . Assign observation centroid squared Euclidean distance . produces k lists , containing distinct observations . Recalculate centroids ( k -means clustering ) . Exit iff new centroids equivalent previous iteration centroids . Repeat centroids converged previous step . K - means number interesting theoretical properties . , partitions data space structure known Voronoi diagram . Second , conceptually close nearest neighbor classification , popular machine learning . , seen variation model - based clustering , Lloyd algorithm variation Expectation - maximization algorithm model discussed . k -means clustering examples k -means separates data Voronoi cells , assumes equal - sized clusters ( adequate ) . k -means represent density - based clusters . Centroid - based clustering problems k -means k -medoids special cases uncapacitated , metric facility location problem , canonical problem operations research computational geometry communities . basic facility location problem ( numerous variants model elaborate settings ) , task find best warehouse locations optimally service given set consumers . view " warehouses " cluster centroids " consumer locations " data clustered . makes possible apply - developed algorithmic solutions facility location literature presently considered centroid - based clustering problem . Model - based clustering [ edit ] clustering framework closely related statistics model - based clustering , based distribution models . approach models data arising mixture probability distributions . advantages providing principled statistical answers questions clusters , clustering method model use , detect deal outliers . theoretical foundation methods excellent , suffer overfitting constraints model complexity . complex model usually able explain data better , makes choosing appropriate model complexity inherently difficult . Standard model - based clustering methods include parsimonious models based eigenvalue decomposition covariance matrices , provide balance overfitting fidelity data . prominent method known Gaussian mixture models ( expectation - maximization algorithm ) . , data set usually modeled fixed ( avoid overfitting ) number Gaussian distributions initialized randomly parameters iteratively optimized better fit data set . converge local optimum , multiple runs produce different results . order obtain hard clustering , objects assigned Gaussian distribution likely belong ; soft clusterings , necessary . Distribution - based clustering produces complex models clusters capture correlation dependence attributes . , algorithms extra burden user : real data sets , concisely defined mathematical model ( e.g. assuming Gaussian distributions strong assumption data ) . Gaussian mixture model clustering examples Gaussian - distributed data , EM works , uses Gaussians modelling clusters . Density - based clusters modeled Gaussian distributions . Density - based clustering [ edit ] density - based clustering , [ 13 ] clusters defined areas higher density remainder data set . Objects sparse areas – required separate clusters – usually considered noise border points . popular [ 14 ] density - based clustering method DBSCAN . [ 15 ] contrast newer methods , features - defined cluster model called " density - reachability " . Similar linkage - based clustering , based connecting points certain distance thresholds . , connects points satisfy density criterion , original variant defined minimum number objects radius . cluster consists density - connected objects ( form cluster arbitrary shape , contrast methods ) plus objects objects ' range . interesting property DBSCAN complexity fairly low – requires linear number range queries database – discover essentially results ( deterministic core noise points , border points ) run , need run multiple times . OPTICS [ 16 ] generalization DBSCAN removes need choose appropriate value range parameter ε { \displaystyle \varepsilon } , produces hierarchical result related linkage clustering . DeLi - Clu , [ 17 ] Density - Link - Clustering combines ideas single - linkage clustering OPTICS , eliminating ε { \displaystyle \varepsilon } parameter entirely offering performance improvements OPTICS R - tree index . key drawback DBSCAN OPTICS expect kind density drop detect cluster borders . data sets , example , overlapping Gaussian distributions – common use case artificial data – cluster borders produced algorithms look arbitrary , cluster density decreases continuously . data set consisting mixtures Gaussians , algorithms nearly outperformed methods EM clustering able precisely model kind data . Mean - shift clustering approach object moved densest area vicinity , based kernel density estimation . Eventually , objects converge local maxima density . Similar k - means clustering , " density attractors " serve representatives data set , mean - shift detect arbitrary - shaped clusters similar DBSCAN . expensive iterative procedure density estimation , mean - shift usually slower DBSCAN k - Means . , applicability mean - shift algorithm multidimensional data hindered unsmooth behaviour kernel density estimate , results - fragmentation cluster tails . [ 17 ] Density - based clustering examples Density - based clustering DBSCAN DBSCAN assumes clusters similar density , problems separating nearby clusters . OPTICS DBSCAN variant , improving handling different densities clusters . Grid - based clustering [ edit ] grid - based technique multi - dimensional data set . [ 18 ] technique , create grid structure , comparison performed grids ( known cells ) . grid - based technique fast low computational complexity . types grid - based clustering methods : STING CLIQUE . Steps involved grid - based clustering algorithm : Divide data space finite number cells . Randomly select cell ‘ c ’ , c traversed . Calculate density ‘ c ’ density ‘ c ’ greater threshold density Mark cell ‘ c ’ new cluster Calculate density neighbors ‘ c ’ density neighboring cell greater threshold density , add cell cluster repeat steps 4.2 4.3 till neighbor density greater threshold density . Repeat steps 2,3 4 till cells traversed . Stop . Recent developments [ edit ] recent years , considerable effort improving performance existing algorithms . [ 19 ] [ 20 ] CLARANS , [ 21 ] BIRCH . [ 22 ] recent need process larger larger data sets ( known big data ) , willingness trade semantic meaning generated clusters performance increasing . led development pre - clustering methods canopy clustering , process huge data sets efficiently , resulting " clusters " merely rough pre - partitioning data set analyze partitions existing slower methods k - means clustering . high - dimensional data , existing methods fail curse dimensionality , renders particular distance functions problematic high - dimensional spaces . led new clustering algorithms high - dimensional data focus subspace clustering ( attributes , cluster models include relevant attributes cluster ) correlation clustering looks arbitrary rotated ( " correlated " ) subspace clusters modeled giving correlation attributes . [ 23 ] Examples clustering algorithms CLIQUE [ 24 ] SUBCLU . [ 25 ] Ideas density - based clustering methods ( particular DBSCAN / OPTICS family algorithms ) adapted subspace clustering ( HiSC , [ 26 ] hierarchical subspace clustering DiSH [ 27 ] ) correlation clustering ( HiCO , [ 28 ] hierarchical correlation clustering , 4C [ 29 ] " correlation connectivity " ERiC [ 30 ] exploring hierarchical density - based correlation clusters ) . different clustering systems based mutual information proposed . Marina Meilă variation information metric ; [ 31 ] provides hierarchical clustering . [ 32 ] genetic algorithms , wide range different fit - functions optimized , including mutual information . [ 33 ] belief propagation , recent development computer science statistical physics , led creation new types clustering algorithms . [ 34 ] Evaluation assessment [ edit ] Evaluation ( " validation " ) clustering results difficult clustering . [ 35 ] Popular approaches involve " internal " evaluation , clustering summarized single quality score , " external " evaluation , clustering compared existing " ground truth " classification , " manual " evaluation human expert , " indirect " evaluation evaluating utility clustering intended application . [ 36 ] Internal evaluation measures suffer problem represent functions seen clustering objective . example , cluster data set Silhouette coefficient ; known efficient algorithm . internal measure evaluation , compares similarity optimization problems , [ 36 ] necessarily useful clustering . External evaluation similar problems : " ground truth " labels , need cluster ; practical applications usually labels . hand , labels reflect possible partitioning data set , imply exist different , maybe better , clustering . approaches ultimately judge actual quality clustering , needs human evaluation , [ 36 ] highly subjective . , statistics informative identifying bad clusterings , [ 37 ] dismiss subjective human evaluation . [ 37 ] Internal evaluation [ edit ] : Determining number clusters data set clustering result evaluated based data clustered , called internal evaluation . methods usually assign best score algorithm produces clusters high similarity cluster low similarity clusters . drawback internal criteria cluster evaluation high scores internal measure necessarily result effective information retrieval applications . [ 38 ] Additionally , evaluation biased algorithms use cluster model . example , k - means clustering naturally optimizes object distances , distance - based internal criterion likely overrate resulting clustering . , internal evaluation measures best suited insight situations algorithm performs better , shall imply algorithm produces valid results . [ 5 ] Validity measured index depends claim kind structure exists data set . algorithm designed kind models chance data set contains radically different set models , evaluation measures radically different criterion . [ 5 ] example , k - means clustering find convex clusters , evaluation indexes assume convex clusters . data set non - convex clusters use k -means , evaluation criterion assumes convexity , sound . dozen internal evaluation measures exist , usually based intuition items cluster similar items different clusters . [ 39 ] :   115–121 example , following methods assess quality clustering algorithms based internal criterion : Davies – Bouldin index [ edit ] Davies – Bouldin index calculated following formula : D B = 1 n ∑ = 1 n max j ≠ ( σ + σ j d ( c , c j ) ) { \displaystyle DB={\frac { 1}{n}}\sum _ { i=1}^{n}\max _ { j\neq i}\left({\frac { \sigma _ { i}+\sigma _ { j}}{d(c_{i},c_{j})}}\right ) } n number clusters , c { \displaystyle c_{i } } centroid cluster { \displaystyle } , σ { \displaystyle \sigma _ { } } average distance elements cluster { \displaystyle } centroid c { \displaystyle c_{i } } , d ( c , c j ) { \displaystyle d(c_{i},c_{j } ) } distance centroids c { \displaystyle c_{i } } c j { \displaystyle c_{j } } . algorithms produce clusters low intra - cluster distances ( high intra - cluster similarity ) high inter - cluster distances ( low inter - cluster similarity ) low Davies – Bouldin index , clustering algorithm produces collection clusters smallest Davies – Bouldin index considered best algorithm based criterion . Dunn index [ edit ] Dunn index aims identify dense - separated clusters . defined ratio minimal inter - cluster distance maximal intra - cluster distance . cluster partition , Dunn index calculated following formula : [ 40 ] D = min 1 ≤ < j ≤ n d ( , j ) max 1 ≤ k ≤ n d ′ ( k ) , { \displaystyle D={\frac { \min _ { 1\leq < j\leq n}d(i , j)}{\max _ { 1\leq k\leq n}d^{\prime } ( k)}}\ , , } d ( , j ) represents distance clusters j , d ' ( k ) measures intra - cluster distance cluster k . inter - cluster distance d ( , j ) clusters number distance measures , distance centroids clusters . Similarly , intra - cluster distance d ' ( k ) measured variety ways , maximal distance pair elements cluster k . internal criterion seek clusters high intra - cluster similarity low inter - cluster similarity , algorithms produce clusters high Dunn index desirable . Silhouette coefficient [ edit ] silhouette coefficient contrasts average distance elements cluster average distance elements clusters . Objects high silhouette value considered clustered , objects low value outliers . index works k -means clustering , determine optimal number clusters . [ 41 ] External evaluation [ edit ] external evaluation , clustering results evaluated based data clustering , known class labels external benchmarks . benchmarks consist set pre - classified items , sets created ( expert ) humans . , benchmark sets thought gold standard evaluation . [ 35 ] types evaluation methods measure close clustering predetermined benchmark classes . , recently discussed adequate real data , synthetic data sets factual ground truth , classes contain internal structure , attributes present allow separation clusters classes contain anomalies . [ 42 ] Additionally , knowledge discovery point view , reproduction known knowledge necessarily intended result . [ 42 ] special scenario constrained clustering , meta information ( class labels ) clustering process , hold - information evaluation purposes non - trivial . [ 43 ] number measures adapted variants evaluate classification tasks . place counting number times class correctly assigned single data point ( known true positives ) , pair counting metrics assess pair data points truly cluster predicted cluster . [ 35 ] internal evaluation , external evaluation measures exist , [ 39 ] :   125–129 example : Purity [ edit ] Purity measure extent clusters contain single class . [ 38 ] calculation thought follows : cluster , count number data points common class said cluster . sum clusters divide total number data points . Formally , given set clusters M { \displaystyle M } set classes D { \displaystyle D } , partitioning N { \displaystyle N } data points , purity defined : 1 N ∑ m ∈ M max d ∈ D | m ∩ d | { \displaystyle { \frac { 1}{N}}\sum _ { m\in M}\max _ { d\in D}{|m\cap d| } } measure penalize having clusters , clusters easier produce high purity . purity score 1 possible putting data point cluster . , purity work imbalanced data , poorly performing clustering algorithms high purity value . example , size 1000 dataset consists classes , containing 999 points containing 1 point , possible partition purity 99.9 % . Rand index [ edit ] Rand index [ 44 ] computes similar clusters ( returned clustering algorithm ) benchmark classifications . computed following formula : R = T P + T N T P + F P + F N + T N { \displaystyle RI={\frac { TP+TN}{TP+FP+FN+TN } } } T P { \displaystyle TP } number true positives , T N { \displaystyle TN } number true negatives , F P { \displaystyle FP } number false positives , F N { \displaystyle FN } number false negatives . instances counted number correct pairwise assignments . , T P { \displaystyle TP } number pairs points clustered predicted partition ground truth partition , F P { \displaystyle FP } number pairs points clustered predicted partition ground truth partition etc . dataset size N , T P + T N + F P + F N = ( N 2 ) { \displaystyle TP+TN+FP+FN={\binom { N}{2 } } } . 
 issue Rand index false positives false negatives equally weighted . undesirable characteristic clustering applications . F - measure addresses concern , [ citation needed ] chance - corrected adjusted Rand index . F - measure [ edit ] F - measure balance contribution false negatives weighting recall parameter β ≥ 0 { \displaystyle \beta \geq 0 } . Let precision recall ( external evaluation measures ) defined follows : P = T P T P + F P { \displaystyle P={\frac { TP}{TP+FP } } } R = T P T P + F N { \displaystyle R={\frac { TP}{TP+FN } } } P { \displaystyle P } precision rate R { \displaystyle R } recall rate . calculate F - measure following formula : [ 38 ] F β = ( β 2 + 1 ) ⋅ P ⋅ R β 2 ⋅ P + R { \displaystyle F_{\beta } = { \frac { ( \beta ^{2}+1)\cdot P\cdot R}{\beta ^{2}\cdot P+R } } } β = 0 { \displaystyle \beta = 0 } , F 0 = P { \displaystyle F_{0}=P } . words , recall impact F - measure β = 0 { \displaystyle \beta = 0 } , increasing β { \displaystyle \beta } allocates increasing weight recall final F - measure . 
 T N { \displaystyle TN } taken account vary 0 upward bound . Jaccard index [ edit ] Jaccard index quantify similarity datasets . Jaccard index takes value 0 1 . index 1 means dataset identical , index 0 indicates datasets common elements . Jaccard index defined following formula : J ( , B ) = | ∩ B | | ∪ B | = T P T P + F P + F N { \displaystyle J(A , B)={\frac { |A\cap B|}{|A\cup B|}}={\frac { TP}{TP+FP+FN } } } simply number unique elements common sets divided total number unique elements sets . 
 Note T N { \displaystyle TN } taken account . Dice index [ edit ] Dice symmetric measure doubles weight T P { \displaystyle TP } ignoring T N { \displaystyle TN } : D S C = 2 T P 2 T P + F P + F N { \displaystyle DSC={\frac { 2TP}{2TP+FP+FN } } } Fowlkes – Mallows index [ edit ] Fowlkes – Mallows index [ 45 ] computes similarity clusters returned clustering algorithm benchmark classifications . higher value Fowlkes – Mallows index similar clusters benchmark classifications . computed following formula : F M = T P T P + F P ⋅ T P T P + F N { \displaystyle FM={\sqrt { { \frac { TP}{TP+FP}}\cdot { \frac { TP}{TP+FN } } } } } T P { \displaystyle TP } number true positives , F P { \displaystyle FP } number false positives , F N { \displaystyle FN } number false negatives . F M { \displaystyle FM } index geometric mean precision recall P { \displaystyle P } R { \displaystyle R } , known G - measure , F - measure harmonic mean . [ 46 ] [ 47 ] , precision recall known Wallace indices B { \displaystyle B^{I } } B { \displaystyle B^{II } } . [ 48 ] Chance normalized versions recall , precision G - measure correspond Informedness , Markedness Matthews Correlation relate strongly Kappa . [ 49 ] Chi Index [ edit ] Chi index [ 50 ] external validation index measure clustering results applying chi - squared statistic . index scores positively fact labels sparse possible clusters , i.e. , cluster different labels possible . higher value Chi Index greater relationship resulting clusters label . Mutual Information [ edit ] mututal information information theoretic measure information shared clustering ground - truth classification detect non - linear similarity clusterings . Normalized mutual information family corrected - - chance variants reduced bias varying cluster numbers . [ 35 ] Confusion matrix [ edit ] confusion matrix quickly visualize results classification ( clustering ) algorithm . shows different cluster gold standard cluster . Validity Measure [ edit ] validity measure ( short v - measure ) combined metric homogeneity completeness clusters [ 51 ] Cluster tendency [ edit ] section needs additional citations verification . help improve article adding citations reliable sources section . Unsourced material challenged removed . ( April 2025 ) ( Learn remove message ) measure cluster tendency measure degree clusters exist data clustered , performed initial test , attempting clustering . way compare data random data . average , random data clusters [ verification needed ] . Hopkins statistic multiple formulations Hopkins statistic . [ 52 ] typical follows . [ 53 ] Let X { \displaystyle X } set n { \displaystyle n } data points d { \displaystyle d } dimensional space . Consider random sample ( replacement ) m ≪ n { \displaystyle m\ll n } data points members x { \displaystyle x_{i } } . generate set Y { \displaystyle Y } m { \displaystyle m } uniformly randomly distributed data points . define distance measures , u { \displaystyle u_{i } } distance y ∈ Y { \displaystyle y_{i}\in Y } nearest neighbor X w { \displaystyle w_{i } } distance x ∈ X { \displaystyle x_{i}\in X } nearest neighbor X. define Hopkins statistic : H = ∑ = 1 m u d ∑ = 1 m u d + ∑ = 1 m w d , { \displaystyle H={\frac { \sum _ { i=1}^{m}{u_{i}^{d}}}{\sum _ { i=1}^{m}{u_{i}^{d}}+\sum _ { i=1}^{m}{w_{i}^{d}}}}\ , , } definition , uniform random data tend values near 0.5 , clustered data tend values nearer 1 . , data containing single Gaussian score close 1 , statistic measures deviation uniform distribution , multimodality , making statistic largely useless application ( real data remotely uniform ) . Applications [ edit ] section needs additional citations verification . help improve article adding citations reliable sources section . Unsourced material challenged removed . ( November 2016 ) ( Learn remove message ) Biology , computational biology bioinformatics [ edit ] : Distance matrices phylogeny Plant animal ecology Cluster analysis describe spatial temporal comparisons communities ( assemblages ) organisms heterogeneous environments . plant systematics generate artificial phylogenies clusters organisms ( individuals ) species , genus higher level share number attributes . Transcriptomics Clustering build groups genes related expression patterns ( known coexpressed genes ) HCS clustering algorithm . [ 54 ] [ 55 ] groups contain functionally related proteins , enzymes specific pathway , genes co - regulated . High throughput experiments expressed sequence tags ( ESTs ) DNA microarrays powerful tool genome annotation – general aspect genomics . Sequence analysis Sequence clustering group homologous sequences gene families . [ 56 ] important concept bioinformatics , evolutionary biology general . evolution gene duplication . High - throughput genotyping platforms Clustering algorithms automatically assign genotypes . [ 57 ] Human genetic clustering similarity genetic data clustering infer population structures . Medicine [ edit ] Medical imaging PET scans , cluster analysis differentiate different types tissue - dimensional image different purposes . [ 58 ] Analysis antimicrobial activity Cluster analysis analyse patterns antibiotic resistance , classify antimicrobial compounds according mechanism action , classify antibiotics according antibacterial activity . IMRT segmentation Clustering divide fluence map distinct regions conversion deliverable fields MLC - based Radiation Therapy . Business marketing [ edit ] Market research Cluster analysis widely market research working multivariate data surveys test panels . Market researchers use cluster analysis partition general population consumers market segments better understand relationships different groups consumers / potential customers , use market segmentation , product positioning , new product development selecting test markets . Grouping shopping items Clustering group shopping items available web set unique products . example , items eBay grouped unique products ( eBay concept SKU ) . World Wide Web [ edit ] Social network analysis study social networks , clustering recognize communities large groups people . Search result grouping process intelligent grouping files websites , clustering create relevant set search results compared normal search engines like Google [ citation needed ] . currently number web - based clustering tools Clusty . return comprehensive set results cases search term refer vastly different things . distinct use term corresponds unique cluster results , allowing ranking algorithm return comprehensive results picking result cluster . [ 59 ] Slippy map optimization Flickr map photos map sites use clustering reduce number markers map . [ citation needed ] makes faster reduces visual clutter . Computer science [ edit ] Software evolution Clustering useful software evolution helps reduce legacy properties code reforming functionality dispersed . form restructuring way direct preventative maintenance . Image segmentation Image segmentation process dividing digital image multiple meaningful regions segments simplify and/or change representation image , making easier analyze . segments correspond different objects , parts objects , background areas . goal assign label pixel image pixels similar attributes grouped . process fields like medical imaging , computer vision , satellite imaging , daily applications like face detection photo editing . aurora borealis , northern lights , Bear Lake , Alaska Image running k - means clustering k = 16 . Clustering Image Segmentation : Clustering plays significant role image segmentation . groups pixels clusters based similarity needing labeled data . clusters define segments image . commonly clustering algorithms image segmentation : K -means Clustering : popular straightforward methods . Pixels treated data points feature space ( usually defined color intensity ) grouped k clusters . pixel assigned nearest cluster center , centers updated iteratively . Mean Shift Clustering : non - parametric method require specifying number clusters advance . identifies clusters locating dense areas data points feature space . Fuzzy C -means : Unlike k -means , assigns pixels exactly cluster , fuzzy c -means allows pixel belong multiple clusters varying degrees membership . Evolutionary algorithms Clustering identify different niches population evolutionary algorithm reproductive opportunity distributed evenly evolving species subspecies . Recommender systems Recommender Systems designed recommend new items , products , users based user past activity current preferences . systems use clustering algorithms predict unknown user preferences specific user based preferences activity users located said user cluster . Recommendation algorithms fall main categories : Collaborative filtering , Content - Based filtering , hybrid collaborative content - based . Collaborative Filtering Recommendation Algorithm “ Collaborative filtering based collecting analyzing large information behavior , activities , preferences users predicting user likes based similarity user users . ” [ 60 ] generate predictions algorithm groups entities based similar rating patterns form distinct “ neighborhoods ” similar entities . Recommendations generated leveraging highly rated items related entities neighborhood target user . algorithm adapted group user items . Flow diagram shows basic generic approach recommendation systems utilize clustering . Content - Based Filtering Recommendation Algorithm “ content - based filtering algorithm based description element profile user preferences . algorithms try recommend items similar user liked past . ” [ 60 ] generate recommendations , algorithm evaluates distance features different " neighborhoods " items . neighborhoods pre - defined clustering algorithm . user past interactions items represented vector assigned weights specific features , algorithm compares vector features item neighborhoods . Recommendations generated leveraging distinct neighborhoods items user past interactions items locate “ closest ” neighborhood user preference . Hybrid Recommendation “ hybrid recommendation algorithm combines collaborative filtering content - based filtering . cases , hybrid approaches effective . ” [ 60 ] Markov chain Monte Carlo methods Clustering utilized locate characterize extrema target distribution . Anomaly detection Anomalies / outliers typically – explicitly implicitly – defined respect clustering structure data . Natural language processing Clustering resolve lexical ambiguity . [ 59 ] DevOps Clustering analyse effectiveness DevOps teams . [ 61 ] Social science [ edit ] Sequence analysis social sciences Cluster analysis identify patterns family life trajectories , professional careers , daily weekly time use example . Crime analysis Cluster analysis identify areas greater incidences particular types crime . identifying distinct areas " hot spots " similar crime happened period time , possible manage law enforcement resources effectively . Educational data mining Cluster analysis example identify groups schools students similar properties . Typologies poll data , projects undertaken Pew Research Center use cluster analysis discern typologies opinions , habits , demographics useful politics marketing . [ edit ] Field robotics Clustering algorithms robotic situational awareness track objects detect outliers sensor data . [ 62 ] Mathematical chemistry find structural similarity , etc . , example , 3000 chemical compounds clustered space 90 topological indices . [ 63 ] Climatology find weather regimes preferred sea level pressure atmospheric patterns . [ 64 ] Finance Cluster analysis cluster stocks sectors . [ 65 ] Petroleum geology Cluster analysis reconstruct missing hole core data missing log curves order evaluate reservoir properties . Geochemistry clustering chemical properties different sample locations . [ edit ] Wikimedia Commons media related Cluster analysis . Specialized types cluster analysis [ edit ] Automatic clustering algorithms Balanced clustering Clustering high - dimensional data Conceptual clustering Consensus clustering Constrained clustering Community detection Data stream clustering HCS clustering Sequence clustering Spectral clustering Techniques cluster analysis [ edit ] Artificial neural network ( ANN ) Nearest neighbor search Neighbourhood components analysis Latent class analysis Affinity propagation Data projection preprocessing [ edit ] Dimension reduction Principal component analysis Multidimensional scaling [ edit ] Cluster - weighted modeling Curse dimensionality Determining number clusters data set Parallel coordinates Structured data analysis Linear separability References [ edit ] ^ Driver Kroeber ( 1932 ) . " Quantitative Expression Cultural Relationships " . University California Publications American Archaeology Ethnology . Quantitative Expression Cultural Relationships . Berkeley , : University California Press : 211 – 256 . Archived original 2020 - 12 - 06 . Retrieved 2019 - 02 - 18 . ^ Zubin , Joseph ( 1938 ) . " technique measuring like - mindedness " . Journal Abnormal Social Psychology . 33 ( 4 ): 508 – 516 . doi : 10.1037 / h0055441 . ISSN 0096 - 851X . ^ Tryon , Robert C. ( 1939 ) . Cluster Analysis : Correlation Profile Orthometric ( factor ) Analysis Isolation Unities Mind Personality . Edwards Brothers . ^ Cattell , R. B. ( 1943 ) . " description personality : Basic traits resolved clusters " . Journal Abnormal Social Psychology . 38 ( 4 ): 476 – 506 . doi : 10.1037 / h0054116 . ^ b c d e f Estivill - Castro , Vladimir ( 20 June 2002 ) . " clustering algorithms – Position Paper " . ACM SIGKDD Explorations Newsletter . 4 ( 1 ): 65 – 75 . doi : 10.1145/568574.568575 . S2CID 7329935 . ^ James A. Davis ( 1967 ) " Clustering structural balance graphs " , Human Relations 20:181–7 ^ Kleinberg , Jon ( 2002 ) . Impossibility Theorem Clustering ( PDF ) . Advances Neural Information Processing Systems . Vol .   15 . MIT Press . ^ Gao , Caroline X. ; Dwyer , Dominic ; Zhu , Ye ; Smith , Catherine L. ; Du , Lan ; Filia , Kate M. ; Bayer , Johanna ; Menssink , Jana M. ; Wang , Teresa ; Bergmeir , Christoph ; Wood , Stephen ; Cotton , Sue M. ( 2023 - 09 - 01 ) . " overview clustering methods guidelines application mental health research " . Psychiatry Research . 327 : 115265 . doi : 10.1016 / j.psychres.2023.115265 . hdl : 10481/84538 . ISSN 0165 - 1781 . PMID 37348404 . ^ Everitt , Brian ( 2011 ) . Cluster analysis . Chichester , West Sussex , U.K : Wiley . ISBN 9780470749913 . ^ Sibson , R. ( 1973 ) . " SLINK : optimally efficient algorithm single - link cluster method " ( PDF ) . Computer Journal . 16 ( 1 ) . British Computer Society : 30 – 34 . doi : 10.1093 / comjnl/16.1.30 . ^ Defays , D. ( 1977 ) . " efficient algorithm complete link method " . Computer Journal . 20 ( 4 ) . British Computer Society : 364 – 366 . doi : 10.1093 / comjnl/20.4.364 . ^ Lloyd , S. ( 1982 ) . " squares quantization PCM " . IEEE Transactions Information Theory . 28 ( 2 ): 129 – 137 . doi : 10.1109 / TIT.1982.1056489 . S2CID 10833328 . ^ Kriegel , Hans - Peter ; Kröger , Peer ; Sander , Jörg ; Zimek , Arthur ( 2011 ) . " Density - based Clustering " . WIREs Data Mining Knowledge Discovery . 1 ( 3 ): 231 – 240 . doi : 10.1002 / widm.30 . S2CID 36920706 . ^ Microsoft academic search : cited data mining articles Archived 2010 - 04 - 21 Wayback Machine : DBSCAN rank 24 , accessed : 4/18/2010 ^ Ester , Martin ; Kriegel , Hans - Peter ; Sander , Jörg ; Xu , Xiaowei ( 1996 ) . " density - based algorithm discovering clusters large spatial databases noise " . Simoudis , Evangelos ; Han , Jiawei ; Fayyad , Usama M. ( eds . ) . Proceedings Second International Conference Knowledge Discovery Data Mining ( KDD-96 ) . AAAI Press . pp . 226 – 231 . ISBN 1 - 57735 - 004 - 9 . ^ Ankerst , Mihael ; Breunig , Markus M. ; Kriegel , Hans - Peter ; Sander , Jörg ( 1999 ) . " OPTICS : Ordering Points Identify Clustering Structure " . ACM SIGMOD international conference Management data . ACM Press . pp . 49 – 60 . CiteSeerX 10.1.1.129.6542 . ^ b Achtert , E. ; Böhm , C. ; Kröger , P. ( 2006 ) . " DeLi - Clu : Boosting Robustness , Completeness , Usability , Efficiency Hierarchical Clustering Closest Pair Ranking " . Advances Knowledge Discovery Data Mining . Lecture Notes Computer Science . Vol .   3918 . pp . 119 – 128 . CiteSeerX 10.1.1.64.1161 . doi : 10.1007/11731139_16 . ISBN 978 - 3 - 540 - 33206 - 0 . ^ Aggarwal , Charu C. ; Reddy , Chandan K. ( eds . ) . Data Clustering   : Algorithms Applications . ISBN 978 - 1 - 315 - 37351 - 5 . OCLC 1110589522 . ^ Sculley , D. ( 2010 ) . Web - scale k - means clustering . Proc . 19th WWW . ^ Huang , Z. ( 1998 ) . " Extensions k -means algorithm clustering large data sets categorical values " . Data Mining Knowledge Discovery . 2 ( 3 ): 283 – 304 . doi : 10.1023 / A:1009769707641 . S2CID 11323096 . ^ R. Ng J. Han . " Efficient effective clustering method spatial data mining " . : Proceedings 20th VLDB Conference , pages 144–155 , Santiago , Chile , 1994 . ^ Tian Zhang , Raghu Ramakrishnan , Miron Livny . " Efficient Data Clustering Method Large Databases . " : Proc . Int'l Conf . Management Data , ACM SIGMOD , pp . 103–114 . ^ Kriegel , Hans - Peter ; Kröger , Peer ; Zimek , Arthur ( July 2012 ) . " Subspace clustering " . Wiley Interdisciplinary Reviews : Data Mining Knowledge Discovery . 2 ( 4 ): 351 – 364 . doi : 10.1002 / widm.1057 . S2CID 7241355 . ^ Agrawal , R. ; Gehrke , J. ; Gunopulos , D. ; Raghavan , P. ( 2005 ) . " Automatic Subspace Clustering High Dimensional Data " . Data Mining Knowledge Discovery . 11 : 5 – 33 . CiteSeerX 10.1.1.131.5152 . doi : 10.1007 / s10618 - 005 - 1396 - 1 . S2CID 9289572 . ^ Karin Kailing , Hans - Peter Kriegel Peer Kröger . Density - Connected Subspace Clustering High - Dimensional Data . : Proc . SIAM Int . Conf . Data Mining ( SDM'04 ) , pp . 246–257 , 2004 . ^ Achtert , E. ; Böhm , C. ; Kriegel , H.-P. ; Kröger , P. ; Müller - Gorman , I. ; Zimek , A. ( 2006 ) . " Finding Hierarchies Subspace Clusters " . Knowledge Discovery Databases : PKDD 2006 . Lecture Notes Computer Science . Vol .   4213 . pp . 446 – 453 . CiteSeerX 10.1.1.705.2956 . doi : 10.1007/11871637_42 . ISBN 978 - 3 - 540 - 45374 - 1 . ^ Achtert , E. ; Böhm , C. ; Kriegel , H. P. ; Kröger , P. ; Müller - Gorman , I. ; Zimek , A. ( 2007 ) . " Detection Visualization Subspace Cluster Hierarchies " . Advances Databases : Concepts , Systems Applications . Lecture Notes Computer Science . Vol .   4443 . pp . 152 – 163 . CiteSeerX 10.1.1.70.7843 . doi : 10.1007/978 - 3 - 540 - 71703 - 4_15 . ISBN 978 - 3 - 540 - 71702 - 7 . ^ Achtert , E. ; Böhm , C. ; Kröger , P. ; Zimek , A. ( 2006 ) . " Mining Hierarchies Correlation Clusters " . 18th International Conference Scientific Statistical Database Management ( SSDBM'06 ) . pp . 119 – 128 . CiteSeerX 10.1.1.707.7872 . doi : 10.1109 / SSDBM.2006.35 . ISBN 978 - 0 - 7695 - 2590 - 7 . S2CID 2679909 . ^ Böhm , C. ; Kailing , K. ; Kröger , P. ; Zimek , A. ( 2004 ) . " Computing Clusters Correlation Connected objects " . Proceedings 2004 ACM SIGMOD international conference Management data - SIGMOD ' 04 . p.   455 . CiteSeerX 10.1.1.5.1279 . doi : 10.1145/1007568.1007620 . ISBN 978 - 1581138597 . S2CID 6411037 . ^ Achtert , E. ; Bohm , C. ; Kriegel , H. P. ; Kröger , P. ; Zimek , A. ( 2007 ) . " Exploring Complex Relationships Correlation Clusters " . 19th International Conference Scientific Statistical Database Management ( SSDBM 2007 ) . p.   7 . CiteSeerX 10.1.1.71.5021 . doi : 10.1109 / SSDBM.2007.21 . ISBN 978 - 0 - 7695 - 2868 - 7 . S2CID 1554722 . ^ Meilă , Marina ( 2003 ) . " Comparing Clusterings Variation Information " . Learning Theory Kernel Machines . Lecture Notes Computer Science . Vol .   2777 . pp . 173 – 187 . doi : 10.1007/978 - 3 - 540 - 45167 - 9_14 . ISBN 978 - 3 - 540 - 40720 - 1 . ^ Kraskov , Alexander ; Stögbauer , Harald ; Andrzejak , Ralph G. ; Grassberger , Peter ( 1 December 2003 ) . " Hierarchical Clustering Based Mutual Information " . arXiv : q - bio/0311039 . Bibcode : 2003q.bio .... 11039 K . { { cite journal } } : Cite journal requires |journal= ( help ) ^ Auffarth , B. ( July 18–23 , 2010 ) . " Clustering Genetic Algorithm Biased Mutation Operator " . Wcci Cec . IEEE . ^ Frey , B. J. ; Dueck , D. ( 2007 ) . " Clustering Passing Messages Data Points " . Science . 315 ( 5814 ): 972 – 976 . Bibcode : 2007Sci ... 315 .. 972F . CiteSeerX 10.1.1.121.3145 . doi : 10.1126 / science.1136800 . PMID 17218491 . S2CID 6502291 . ^ b c d Pfitzner , Darius ; Leibbrandt , Richard ; Powers , David ( 2009 ) . " Characterization evaluation similarity measures pairs clusterings " . Knowledge Information Systems . 19 ( 3 ) . Springer : 361 – 394 . doi : 10.1007 / s10115 - 008 - 0150 - 6 . S2CID 6935380 . ^ b c Feldman , Ronen ; Sanger , James ( 2007 - 01 - 01 ) . Text Mining Handbook : Advanced Approaches Analyzing Unstructured Data . Cambridge Univ . Press . ISBN 978 - 0521836579 . OCLC 915286380 . ^ b Weiss , Sholom M. ; Indurkhya , Nitin ; Zhang , Tong ; Damerau , Fred J. ( 2005 ) . Text Mining : Predictive Methods Analyzing Unstructured Information . Springer . ISBN 978 - 0387954332 . OCLC 803401334 . ^ b c Manning , Christopher D. ; Raghavan , Prabhakar ; Schütze , Hinrich ( 2008 - 07 - 07 ) . Introduction Information Retrieval . Cambridge University Press . ISBN 978 - 0 - 521 - 86571 - 5 . ^ b Knowledge Discovery Databases – III – Clustering ( PDF ) , Heidelberg University , 2017 { { citation } } :   CS1 maint : location missing publisher ( link ) ^ Dunn , J. ( 1974 ) . " separated clusters optimal fuzzy partitions " . Journal Cybernetics . 4 : 95 – 104 . doi : 10.1080/01969727408546059 . ^ Peter J. Rousseeuw ( 1987 ) . " Silhouettes : graphical aid interpretation validation cluster analysis " . Journal Computational Applied Mathematics . 20 : 53 – 65 . doi : 10.1016/0377 - 0427(87)90125 - 7 . ^ b Färber , Ines ; Günnemann , Stephan ; Kriegel , Hans - Peter ; Kröger , Peer ; Müller , Emmanuel ; Schubert , Erich ; Seidl , Thomas ; Zimek , Arthur ( 2010 ) . " Class - Labels Evaluation Clusterings " ( PDF ) . Fern , Xiaoli Z. ; Davidson , Ian ; Dy , Jennifer ( eds . ) . MultiClust : Discovering , Summarizing , Multiple Clusterings . ACM SIGKDD . ^ Pourrajabi , M. ; Moulavi , D. ; Campello , R. J. G. B. ; Zimek , A. ; Sander , J. ; Goebel , R. ( 2014 ) . " Model Selection Semi - Supervised Clustering " . Proceedings 17th International Conference Extending Database Technology ( EDBT ) . pp . 331 – 342 . doi : 10.5441/002 / edbt.2014.31 . ^ Rand , W. M. ( 1971 ) . " Objective criteria evaluation clustering methods " . Journal American Statistical Association . 66 ( 336 ) . American Statistical Association : 846 – 850 . arXiv : 1704.01036 . doi : 10.2307/2284239 . JSTOR 2284239 . ^ Fowlkes , E. B. ; Mallows , C. L. ( 1983 ) . " Method Comparing Hierarchical Clusterings " . Journal American Statistical Association . 78 ( 383 ): 553 – 569 . doi : 10.1080/01621459.1983.10478008 . JSTOR 2288117 . ^ Powers , David ( 2003 ) . Recall Precision versus Bookmaker . International Conference Cognitive Science . pp . 529 – 534 . ^ Arabie , P. ( 1985 ) . " Comparing partitions " . Journal Classification . 2 ( 1 ): 1985 . doi : 10.1007 / BF01908075 . S2CID 189915041 . ^ Wallace , D. L. ( 1983 ) . " Comment " . Journal American Statistical Association . 78 ( 383 ): 569 – 579 . doi : 10.1080/01621459.1983.10478009 . ^ Powers , David ( 2012 ) . Problem Kappa . European Chapter Association Computational Linguistics . pp . 345 – 355 . ^ Luna - Romera , José María ; Martínez - Ballesteros , María ; García - Gutiérrez , Jorge ; Riquelme , José C. ( June 2019 ) . " External clustering validity index based chi - squared statistical test " . Information Sciences . 487 : 1 – 17 . doi : 10.1016 / j.ins.2019.02.046 . hdl : 11441/132081 . S2CID 93003939 . ^ Rosenberg , Andrew , Julia Hirschberg . " V - measure : conditional entropy - based external cluster evaluation measure . " Proceedings 2007 joint conference empirical methods natural language processing computational natural language learning ( EMNLP - CoNLL ) . 2007 . pdf ^ Hopkins , Brian ; Skellam , John Gordon ( 1954 ) . " new method determining type distribution plant individuals " . Annals Botany . 18 ( 2 ) . Annals Botany Co : 213 – 227 . doi : 10.1093 / oxfordjournals.aob.a083391 . ^ Banerjee , A. ( 2004 ) . " Validating clusters Hopkins statistic " . 2004 IEEE International Conference Fuzzy Systems ( IEEE Cat . No.04CH37542 ) . Vol .   1 . pp . 149 – 153 . doi : 10.1109 / FUZZY.2004.1375706 . ISBN 978 - 0 - 7803 - 8353 - 1 . S2CID 36701919 . ^ Johnson , Stephen C. ( 1967 - 09 - 01 ) . " Hierarchical clustering schemes " . Psychometrika . 32 ( 3 ): 241 – 254 . doi : 10.1007 / BF02289588 . ISSN 1860 - 0980 . PMID 5234703 . S2CID 930698 . ^ Hartuv , Erez ; Shamir , Ron ( 2000 - 12 - 31 ) . " clustering algorithm based graph connectivity " . Information Processing Letters . 76 ( 4 ): 175 – 181 . doi : 10.1016 / S0020 - 0190(00)00142 - 3 . ISSN 0020 - 0190 . ^ Remm , Maido ; Storm , Christian E. V. ; Sonnhammer , Erik L. L. ( 2001 - 12 - 14 ) . " Automatic clustering orthologs - paralogs pairwise species comparisons11Edited F. Cohen " . Journal Molecular Biology . 314 ( 5 ): 1041 – 1052 . doi : 10.1006 / jmbi.2000.5197 . ISSN 0022 - 2836 . PMID 11743721 . ^ Botstein , David ; Cox , David R. ; Risch , Neil ; Olshen , Richard ; Curb , David ; Dzau , Victor J. ; Chen , Yii - Der I. ; Hebert , Joan ; Pesich , Robert ( 2001 - 07 - 01 ) . " High - Throughput Genotyping Single Nucleotide Polymorphisms " . Genome Research . 11 ( 7 ): 1262 – 1268 . doi : 10.1101 / gr.157801 . ISSN 1088 - 9051 . PMC 311112 . PMID 11435409 . ^ Filipovych , Roman ; Resnick , Susan M. ; Davatzikos , Christos ( 2011 ) . " Semi - supervised Cluster Analysis Imaging Data " . NeuroImage . 54 ( 3 ): 2185 – 2197 . doi : 10.1016 / j.neuroimage.2010.09.074 . PMC 3008313 . PMID 20933091 . ^ b Di Marco , Antonio ; Navigli , Roberto ( 2013 ) . " Clustering Diversifying Web Search Results Graph - Based Word Sense Induction " . Computational Linguistics . 39 ( 3 ): 709 – 754 . doi : 10.1162 / COLI_a_00148 . S2CID 1775181 . ^ b c Beregovskaya , Irina ; Koroteev , Mikhail ( 2021 ) . " Review Clustering - Based Recommender Systems " . CoRR . ^ 2022 Accelerate State DevOps Report ( PDF ) ( Report ) . Google Cloud DevOps Research Assessment ( DORA ) . 29 September 2022 . pp .   8 , 14 , 74 . ^ Bewley , A. ; et   al . " Real - time volume estimation dragline payload " . IEEE International Conference Robotics Automation . 2011 : 1571 – 1576 . ^ Basak , S.C. ; Magnuson , V.R. ; Niemi , C.J. ; Regal , R.R. ( 1988 ) . " Determining Structural Similarity Chemicals Graph Theoretic Indices " . Discr . Appl . Math . 19 ( 1 – 3 ): 17 – 44 . doi : 10.1016/0166 - 218x(88)90004 - 2 . ^ Huth , R. ; et   al . ( 2008 ) . " Classifications Atmospheric Circulation Patterns : Recent Advances Applications " ( PDF ) . Ann . N.Y. Acad . Sci . 1146 ( 1 ): 105 – 152 . Bibcode : 2008NYASA1146 .. 105H . doi : 10.1196 / annals.1446.019 . PMID 19076414 . S2CID 22655306 . ^ Arnott , Robert D. ( 1980 - 11 - 01 ) . " Cluster Analysis Stock Price Comovement " . Financial Analysts Journal . 36 ( 6 ): 56 – 62 . doi : 10.2469 / faj.v36.n6.56 . ISSN 0015 - 198X . v t e Artificial intelligence ( AI ) History ( timeline ) Concepts Parameter Hyperparameter Loss functions Regression Bias – variance tradeoff Double descent Overfitting Clustering Gradient descent SGD Quasi - Newton method Conjugate gradient method Backpropagation Attention Convolution Normalization Batchnorm Activation Softmax Sigmoid Rectifier Gating Weight initialization Regularization Datasets Augmentation Prompt engineering Reinforcement learning Q - learning SARSA Imitation Policy gradient Diffusion Latent diffusion model Autoregression Adversary RAG Uncanny valley RLHF Self - supervised learning Recursive self - improvement Word embedding Hallucination Applications Machine learning - context learning Artificial neural network Deep learning Language model Large language model NMT Artificial general intelligence ( AGI ) Implementations Audio – visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis 15.ai ElevenLabs Speech recognition Whisper Facial recognition AlphaFold Text - - image models Aurora DALL - E Firefly Flux Ideogram Imagen Midjourney Stable Diffusion Text - - video models Dream Machine Runway Gen Hailuo AI Kling Sora Veo Music generation Suno AI Udio Text Word2vec Seq2seq GloVe BERT T5 Llama Chinchilla AI PaLM GPT 1 2 3 J ChatGPT 4 4o o1 o3 4.5 4.1 o4 Claude Gemini chatbot Grok LaMDA BLOOM Project Debater IBM Watson IBM Watsonx Granite PanGu - Σ DeepSeek Qwen Decisional AlphaGo AlphaZero OpenAI Self - driving car MuZero Action selection AutoGPT Robot control People Alan Turing Warren Sturgis McCulloch Walter Pitts John von Neumann Claude Shannon Marvin Minsky John McCarthy Nathaniel Rochester Allen Newell Cliff Shaw Herbert A. Simon Oliver Selfridge Frank Rosenblatt Bernard Widrow Joseph Weizenbaum Seymour Papert Seppo Linnainmaa Paul Werbos Jürgen Schmidhuber Yann LeCun Geoffrey Hinton John Hopfield Yoshua Bengio Lotfi A. Zadeh Stephen Grossberg Alex Graves Andrew Ng Fei - Fei Li Alex Krizhevsky Ilya Sutskever Demis Hassabis David Silver Ian Goodfellow Andrej Karpathy James Goodnight Architectures Neural Turing machine Differentiable neural computer Transformer Vision transformer ( ViT ) Recurrent neural network ( RNN ) Long short - term memory ( LSTM ) Gated recurrent unit ( GRU ) Echo state network Multilayer perceptron ( MLP ) Convolutional neural network ( CNN ) Residual neural network ( RNN ) Highway network Mamba Autoencoder Variational autoencoder ( VAE ) Generative adversarial network ( GAN ) Graph neural network ( GNN ) Portals Technology Category Artificial neural networks Machine learning List Companies Projects v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic - Geometric Contraharmonic Cubic Generalized / power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L - moments Skewness Count data Index dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product - moment correlation Rank correlation Kendall τ Spearman ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q – Q plot Radar chart Run chart Scatter plot Stem - - leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation - - designs Observational studies Cohort study Cross - sectional study Natural experiment Quasi - experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood ( monotone ) Location – scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method moments M - estimator Minimum distance Unbiased estimators Mean - unbiased minimum - variance Rao – Blackwellization Lehmann – Scheffé theorem Median unbiased Plug - Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2 - tails Power Uniformly powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood - ratio Score / Lagrange multiplier Wald Specific tests Z -test ( normal ) Student t -test F -test Goodness fit Chi - squared G -test Kolmogorov – Smirnov Anderson – Darling Lilliefors Jarque – Bera Normality ( Shapiro – Wilk ) Likelihood - ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank ( Wilcoxon ) Hodges – Lehmann estimator Rank sum ( Mann – Whitney ) Nonparametric anova 1 - way ( Kruskal – Wallis ) 2 - way ( Friedman ) Ordered alternative ( Jonckheere – Terpstra ) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product - moment Partial correlation Confounding variable Coefficient determination Regression analysis Errors residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines ( MARS ) Linear regression Simple linear regression Ordinary squares General linear model Bayesian regression Non - standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity Heteroscedasticity Generalized linear model Exponential families Logistic ( Bernoulli ) / Binomial / Poisson regressions Partition variance Analysis variance ( ANOVA , anova ) Analysis covariance Multivariate ANOVA Degrees freedom Categorical / Multivariate / Time - series / Survival analysis Categorical Cohen kappa Contingency table Graphical model Log - linear model McNemar test Cochran – Mantel – Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time - series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey – Fuller Johansen Q - statistic ( Ljung – Box ) Durbin – Watson Breusch – Godfrey Time domain Autocorrelation ( ACF ) partial ( PACF ) Cross - correlation ( XCF ) ARMA model ARIMA model ( Box – Jenkins ) Autoregressive conditional heteroskedasticity ( ARCH ) Vector autoregression ( VAR ) Frequency domain Spectral density estimation Fourier analysis - squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan – Meier estimator ( product limit ) Proportional hazards models Accelerated failure time ( AFT ) model hitting time Hazard function Nelson – Aalen estimator Test Log - rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject Retrieved " https://en.wikipedia.org/w/index.php?title=Cluster_analysis&oldid=1287404411 " Categories : Cluster analysis Data mining Geostatistics Hidden categories : CS1 : long volume value Webarchive template wayback links CS1 errors : missing periodical CS1 maint : location missing publisher Articles short description Short description different Wikidata Articles containing Greek - language text articles unsourced statements Articles unsourced statements 2018 Articles needing additional references April 2025 articles needing additional references pages needing factual verification Wikipedia articles needing factual verification April 2025 Articles needing additional references November 2016 Articles unsourced statements July 2018 Articles unsourced statements 2023 Commons category link Wikidata page edited 26 April 2025 , 01:16 ( UTC ) . Text available Creative Commons Attribution - ShareAlike 4.0 License ; 
 additional terms apply . site , agree Terms Use Privacy Policy . Wikipedia ® registered trademark Wikimedia Foundation , Inc. , non - profit organization . Privacy policy Wikipedia Disclaimers Contact Wikipedia Code Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle table contents Cluster analysis 40 languages Add topic