Measuring Data Similarity Dissimilarity Data Mining - Scaler Topics Experience Academy Data Science Neovarsity Topics Explore New Skill Test Courses Free Masterclass Search Articles , Topics Experience Experience Scaler Data Mining Tutorial Measuring Data Similarity Dissimilarity Data Mining Measuring Data Similarity Dissimilarity Data Mining Measuring Data Similarity Dissimilarity Data Mining Utkarsh 11 mins read updated : 7 Jul 2023 451 views Learn video courses Topics Covered Overview Data similarity dissimilarity important measures data mining help identifying patterns trends datasets . Similarity measures determine similar datasets data points , dissimilarity measures determine different . article , discuss commonly measures similarity dissimilarity data mining . Introduction Measuring similarity dissimilarity data mining important task helps identify patterns relationships large datasets . quantify degree similarity dissimilarity data points objects , mathematical functions called similarity dissimilarity measures . Similarity measures produce score indicates degree similarity data points , dissimilarity measures produce score indicates degree dissimilarity data points . measures crucial data mining tasks , identifying duplicate records ,   clustering , classification , anomaly detection . Let understand measures similarity dissimilarity data mining explore methods use measures . Basics Similarity Dissimilarity Measures Similarity Measure similarity measure mathematical function quantifies degree similarity objects data points . numerical score measuring alike data points . takes data points input produces similarity score output , typically ranging 0 ( completely dissimilar ) 1 ( identical perfectly similar ) . similarity measure based mathematical techniques Cosine similarity , Jaccard similarity , Pearson correlation coefficient . Similarity measures generally identify duplicate records , equivalent instances , identifying clusters . Dissimilarity Measure dissimilarity measure mathematical function quantifies degree dissimilarity objects data points . numerical score measuring different data points . takes data points input produces dissimilarity score output , ranging 0 ( identical perfectly similar ) 1 ( completely dissimilar ) . dissimilarity measures infinity upper limit . dissimilarity measure obtained different techniques Euclidean distance , Manhattan distance , Hamming distance . Dissimilarity measures identifying outliers , anomalies , clusters . Data Types Similarity Dissimilarity Measures nominal variables , measures binary , indicating values equal . ordinal variables , difference values normalized max distance . variables , distance function . Distinction Distance Similarity Distance typical measure dissimilarity data points objects , similarity measure similar alike data points objects . Distance measures typically produce non - negative value increases data points dissimilar . Distance measures fundamental principles algorithms , KNN , K - Means , etc . hand , similarity measures typically produce non - negative value increases data points similar . Similarity Measures Similarity measures mathematical functions determine degree similarity data points objects . measures produce score indicates similar alike data points . takes data points input produces similarity score output , typically ranging 0 ( completely dissimilar ) 1 ( identical perfectly similar ) . Similarity measures - known properties - s m ( , B ) = 1 sim(A , B ) = 1 s m ( , B ) = 1 ( maximum similarity ) = B = B = B Typical range - ( 0 ≤ s m ≤ 1 ) ( 0 ≤ sim ≤ 1 ) ( 0 ≤ s m ≤ 1 ) Symmetry - s m ( , B ) = s m ( B , ) sim(A , B ) = sim(B , ) s m ( , B ) = s m ( B , ) B B B let explore commonly similarity measures data mining . Cosine Similarity Cosine similarity widely similarity measure data mining information retrieval . measures cosine angle non - zero vectors multi - dimensional space . context data mining , vectors represent feature vectors data points . cosine similarity score ranges 0 1 , 0 indicating similarity 1 indicating perfect similarity . cosine similarity vectors calculated dot product vectors divided product magnitudes . calculation represented mathematically follows - cos ⁡ ( θ ) = ⋅ B ∥ ∥ ∥ B ∥ = ∑ = 1 n B ∑ = 1 n 2 ∑ = 1 n B 2 \cos ( \theta ) = \frac{\mathbf{A } \cdot \mathbf{B}}{\|\mathbf{A}\| \|\mathbf{B}\| } = \frac{\sum_{i=1}^{n } A_i B_i}{\sqrt{\sum_{i=1}^{n } A_i^2 } \sqrt{\sum_{i=1}^{n } B_i^2 } } cos ( θ ) = ∥ ∥ ∥ B ∥ ⋅ B ​ = ∑ = 1 n ​ 2 ​ ​ ∑ = 1 n ​ B 2 ​ ​ ∑ = 1 n ​ ​ B ​ ​ B feature vectors data points , " . " denotes dot product , " || " denotes magnitude vector . Jaccard Similarity Jaccard similarity widely similarity measure data mining , particularly text analysis clustering . measures similarity sets data calculating ratio intersection sets union . Jaccard similarity score ranges 0 1 , 0 indicating similarity 1 indicating perfect similarity . Jaccard similarity sets B calculated follows - J ( , B ) = ∣ ∩ B ∣ ∣ ∪ B ∣ = ∣ ∩ B ∣ ∣ ∣ + ∣ B ∣ − ∣ ∩ B ∣ J(A , B ) = \frac{|\mathbf{A } \cap \mathbf{B}|}{|\mathbf{A } \cup \mathbf{B}| } = \frac{|\mathbf{A } \cap \mathbf{B}|}{|\mathbf{A}| + |\mathbf{B}| - |\mathbf{A } \cap \mathbf{B}| } J ( , B ) = ∣ ∪ B ∣ ∣ ∩ B ∣ ​ = ∣ ∣ + ∣ B ∣ − ∣ ∩ B ∣ ∣ ∩ B ∣ ​ ∣ ∩ B ∣ |\mathbf{A } ∩ \mathbf{B}| ∣ ∩ B ∣ size intersection sets \mathbf{A } B \mathbf{B } B , ∣ ∪ B ∣ |\mathbf{A } ∪ \mathbf{B}| ∣ ∪ B ∣ size union sets \mathbf{A } B \mathbf{B } B . Pearson Correlation Coefficient Pearson correlation coefficient widely similarity measure data mining statistical analysis . measures linear correlation continuous variables , X Y. Pearson correlation coefficient ranges -1 +1 , -1 indicating perfect negative correlation , 0 indicating correlation , +1 indicating perfect positive correlation . Pearson correlation coefficient commonly data mining applications feature selection regression analysis . help identify variables highly correlated , useful reducing dimensionality dataset . regression analysis , predict value variable based value variable . Pearson correlation coefficient variables , X Y , calculated follows - ρ X , Y = cov ⁡ ( X , Y ) σ X σ Y = ∑ = 1 n ( X − X ˉ ) ( Y − Y ˉ ) ∑ = 1 n ( X − X ˉ ) 2 ∑ = 1 n ( Y − Y ˉ ) 2 \rho_{X , Y } = \frac{\operatorname{cov}(X , Y)}{\sigma_X \sigma_Y } = \frac{\sum_{i=1}^n ( X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum_{i=1}^n ( X_i - \bar{X})^2 } \sqrt{\sum_{i=1}^n ( Y_i - \bar{Y})^2 } } ρ X , Y ​ = σ X ​ σ Y ​ cov ( X , Y ) ​ = ∑ = 1 n ​ ( X ​ − X ˉ ) 2 ​ ∑ = 1 n ​ ( Y ​ − Y ˉ ) 2 ​ ∑ = 1 n ​ ( X ​ − X ˉ ) ( Y ​ − Y ˉ ) ​ cov ⁡ ( X , Y ) \operatorname{cov}(X , Y ) cov ( X , Y ) covariance variables X X X Y Y Y , σ X \sigma_X σ X ​ σ Y \sigma_Y σ Y ​ standard deviations variables X X X Y Y Y , respectively . Sørensen - Dice Coefficient Sørensen - Dice coefficient , known Dice similarity index Dice coefficient , similarity measure compare similarity sets data , typically context text image analysis . coefficient ranges 0 1 , 0 indicating similarity 1 indicating perfect similarity . Sørensen - Dice coefficient commonly text analysis compare similarity documents based set words terms contain . image analysis compare similarity images based set pixels contain . Sørensen - Dice coefficient sets , B , calculated follows - S ( , B ) = 2 ∣ ∩ B ∣ ∣ ∣ + ∣ B ∣ S(A , B ) = \frac{2 |A \cap B|}{|A| + |B| } S ( , B ) = ∣ ∣ + ∣ B ∣ 2 ∣ ∩ B ∣ ​ ∣ ∩ B ∣ |A ∩ B| ∣ ∩ B ∣ size intersection sets B B B , ∣ ∣ |A| ∣ ∣ ∣ B ∣ |B| ∣ B ∣ sizes sets B B B , respectively . Choosing Appropriate Similarity Measure Choosing appropriate similarity measure depends nature data specific task hand . factors consider choosing similarity measure - Different similarity measures suitable different data types , continuous categorical data , text image data , etc . example , Pearson correlation coefficient , suitable continuous variables . similarity measures sensitive scale measurement data . choice similarity measure depends specific task hand . example , cosine similarity information retrieval text mining , Jaccard similarity commonly clustering recommendation systems . similarity measures robust noise outliers data . example , Sørensen - Dice coefficient sensitive noise . Dissimilarity Measures Dissimilarity measures quantify degree difference distance objects data points . Dissimilarity measures considered inverse similarity measures , similarity measure returns high value similar objects low value dissimilar objects , dissimilarity measure returns low value similar objects high value dissimilar objects . Dissimilarity measures - known properties - Positivity - d s s m ( , B ) ≥ 0 dissim(A , B ) ≥ 0 d s s m ( , B ) ≥ 0 B B B , d s s m ( , B ) = 0 dissim(A , B ) = 0 d s s m ( , B ) = 0 = B = B = B . Symmetry - d s s m ( , B ) = d s s m ( B , ) dissim(A , B ) = dissim(B , ) d s s m ( , B ) = d s s m ( B , ) B B B Triangle Inequality - d s s m ( , C ) ≤ d s s m ( , B ) + d ( B , C ) dissim(A , C ) ≤ dissim(A , B ) + d(B , C ) d s s m ( , C ) ≤ d s s m ( , B ) + d ( B , C ) points , B B B , C C C . Let explore commonly dissimilarity distance measures data mining . Euclidean Distance Euclidean distance commonly dissimilarity measure quantifies distance points multidimensional space . named ancient Greek mathematician Euclid , studied properties . Euclidean distance points X X X Y Y Y n - dimensional space defined square root sum squared differences corresponding coordinates , shown - d ( X , Y ) = ∑ = 1 n ( X − Y ) 2 d(X , Y ) = \sqrt{\sum_{i=1}^n ( X_i - Y_i)^2 } d ( X , Y ) = = 1 ∑ n ​ ( X ​ − Y ​ ) 2 ​ Euclidean distance commonly clustering , classification , anomaly detection applications data mining machine learning . advantage easy interpret visualize . , sensitive scale data perform dealing high - dimensional data data outliers . Manhattan Distance Manhattan distance , known city block distance , dissimilarity measure quantifies distance points multidimensional space . named geometric structure streets Manhattan , distance points measured number blocks walk horizontally vertically reach point . Manhattan distance points x x x y y y n - dimensional space defined sum absolute differences corresponding coordinates , shown - d M ( x , y ) = ∑ = 1 n ∣ x − y ∣ d_{M}(x , y ) = \sum_{i=1}^{n } |x_i - y_i| d M ​ ( x , y ) = = 1 ∑ n ​ ∣ x ​ − y ​ ∣ data mining machine learning , Manhattan distance commonly clustering , classification , anomaly detection applications . particularly useful dealing high - dimensional data , sparse data , data outliers , sensitive extreme values Euclidean distance . , suitable data exhibit complex geometric structures nonlinear relationships features . Minkowski Distance Minkowski distance generalization Euclidean distance Manhattan distance , special cases Minkowski distance . Minkowski distance points x x x y y y n - dimensional space defined - D ( x , y ) = ( ∑ = 1 n ∣ x − y ∣ p ) 1 p D(x , y ) = \left ( \sum_{i=1}^n |x_i - y_i|^p \right)^\frac{1}{p } D ( x , y ) = ( = 1 ∑ n ​ ∣ x ​ − y ​ ∣ p ) p 1 ​ p p p parameter determines degree Minkowski distance . p = 1 p = 1 p = 1 , Minkowski distance reduces Manhattan distance , p = 2 p = 2 p = 2 , reduces Euclidean distance . p > 2 p > 2 p > 2 , referred " higher - order " distance metric . Hamming Distance Hamming distance distance metric measure dissimilarity strings equal length . defined number positions corresponding symbols strings different . example , consider strings " 101010 " " 111000 " . Hamming distance strings positions corresponding symbols different : second , fourth , sixth positions . Hamming distance error - correcting codes cryptography , important detect correct errors data transmission . data mining machine learning applications compare categorical binary data , DNA sequences binary feature vectors . Choosing Appropriate Dissimilarity Measure Similar similarity measures , choosing appropriate dissimilarity measure depends nature data specific task hand . factors consider selecting dissimilarity measure - Different dissimilarity measures appropriate different types data . example , Hamming distance suitable binary string data , Euclidean distance appropriate continuous numerical data . scale data affect choice dissimilarity measure . instance , range feature larger range feature , Euclidean distance best measure use . case , normalization standardization data required , different measure , Manhattan distance , . number features dimensions data impact choice dissimilarity measure . high - dimensional data , robust measure Mahalanobis distance appropriate . Advanced Techniques Recent Developments Measures similarity dissimilarity data mining learned labeled data supervised learning setting . common approach learning supervised similarity dissimilarity measures train binary classifier distinguishes similar dissimilar pairs examples . approach train regression model predicts degree similarity dissimilarity pairs examples . Similarly , ensemble techniques measures similarity dissimilarity data mining single measure performs multiple measures capture different aspects data . Ensemble techniques similarity dissimilarity measures involve combining multiple measures single measure improve overall performance . example , k - NN classifier , neighbor classified different similarity measure . final classification decision combining decisions neighbors ensemble technique . Recently , deep learning learn measures similarity dissimilarity data mining . involves neural networks learn similarity dissimilarity pairs examples . common approach deep learning similarity dissimilarity measures use Siamese networks . Siamese networks consist identical neural networks share weights . network takes input examples compared produces feature vector represents example . feature vectors compared distance similarity measure , Euclidean distance cosine similarity , produce final output . Conclusion Measures similarity dissimilarity essential tools data mining comparing analyzing data . measures allow quantify similarity dissimilarity data points data sets identify complex datasets ' patterns relationships . different measures similarity dissimilarity available , cosine similarity , Jaccard similarity , Euclidean distance , hamming distance , etc . Choosing appropriate measure depends specific task characteristics data analyzed . Ensemble techniques deep learning approaches combine learn similarity dissimilarity measures , effectively improving performance robustness . Got suggestions ? love hear feedback . feedback important help improve Close Submit Free learning platform Explore Scaler Academy Data Science & ML Neovarsity Explore Topics Free Online Courses Challenges Contest Topics Articles Events Resources Blog Careers Review Download app ! scaler resources roof ! 4.4 1.71 K Reviews 100K+ Downloads Popular Free Certification Courses Java Course Beginners C++ Course Certificate Python Course Beginners Javascript Free Course Beginners Data Science Course Beginners DBMS Course Python SQL Data Science Course DSA Problem Solving Interviews Instagram System Design Course Dynamic Programming Course Free Online Courses Popular Tutorials Python Tutorial Java Tutorial DBMS Tutorial Javascript Tutorial C++ Tutorial SQL Tutorial Software Engineering Tutorial Data Science Tutorial Pandas Tutorial Deep Learning Tutorial Tutorials Compilers Python Compiler Java Compiler Javascript Compiler C Compiler C++ Compiler Tools Json Validator SQL Formatter XML Formatter CSS Formatter JavaScript Formatter Copyright 2025 InterviewBit Technologies Pvt . Ltd. Rights Reserved . Privacy Policy Terms Use Contact