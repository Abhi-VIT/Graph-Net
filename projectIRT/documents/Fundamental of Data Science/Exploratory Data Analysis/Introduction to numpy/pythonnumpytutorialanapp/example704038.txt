Python NumPy Tutorial : Applied Introduction Beginners – LearnDataSci Cookie Policy use cookies operate website , improve usability , personalize experience , improve marketing . Privacy Policy . clicking " Accept " use website , agree allow cookies . Accept Learn Machine Learning Learn internet best courses : Data Science Machine Learning Python Toggle navigation Daily Learning Curriculum Tutorials Articles Glossary Books Solutions Courses Data Science Data Analytics Machine Learning Python SQL Excel AI Team 2.6 K 554 reading tutorials 9 SHARES Author : Ricky Dunbar Solar Energy Engineer , Ph.D. Physics Python NumPy Tutorial : Applied Introduction Beginners LearnDataSci reader - supported . purchase links site , earned commissions help support team writers , researchers , designers extra cost . know : Linear Algebra . good intro Linear Algebra found Andrew Ng machine learning course . Basics Python . Treehouse interactive lessons . NumPy ? Numpy open - source library working efficiently arrays . Developed 2005 Travis Oliphant , stands Numerical Python . critical data science library Python , libraries depend . NumPy popular ? NumPy extremely popular dramatically improves ease performance working multidimensional arrays . Numpy advantages : Mathematical operations NumPy ndarray objects 50x faster iterating native Python lists loops . efficiency gains primarily NumPy storing array elements ordered single location memory , eliminating redundancies having elements type making use modern CPUs . efficiency advantages particularly apparent operating arrays thousands millions elements , pretty standard data science . offers Indexing syntax easily accessing portions data array . contains built - functions improve quality life working arrays math , functions linear algebra , array transformations , matrix math . requires fewer lines code mathematical operations native Python lists . Best place info online documentation ( https://numpy.org/doc/ ) great place look information topics introduced article . documentation goes detail introduction continually updated evolving best practices . start NumPy ? NumPy good candidate library explore gaining basic comfort Python environment . NumPy , logical choices growing data science scientific computing capabilities SciPy pandas . short , learn Python , NumPy , SciPy , pandas . relationship NumPy , SciPy , Scikit - learn , Pandas ? NumPy provides foundation data science packages built , including SciPy , Scikit - learn , Pandas . SciPy provides menu libraries scientific computations . extends NumPy including integration , interpolation , signal processing , linear algebra functions , descriptive inferential statistics , numerical optimizations , . Scikit - learn extends NumPy SciPy advanced machine - learning algorithms . Pandas extends NumPy providing functions exploratory data analysis , statistics , data visualization . thought Python equivalent Microsoft Excel spreadsheets working exploring tabular data ( tutorial ) . Alternative MATLAB ? readers likely familiar commercial scientific computing software MATLAB . Python libraries like Matplotlib , NumPy considered fully - fledged alternative MATLAB core functionality . Python attractive alternative MATLAB following reasons : Python open - source , means option inspecting source code . Access vast - growing possibilities open Python users . Unlike MATLAB , Python Numpy free . explanation needed ! Installation check NumPy installed Python installation ( likely ) , run following command : import numpy np Learn Data Science error message returned , good sign NumPy available . error message like ModuleNotFoundError : module named ' numpy ' probably means NumPy needs installed . use pip Python package manager , required command ' pip install numpy ' . need detailed installation instructions , refer https://numpy.org/. List useful NumPy functions NumPy numerous useful functions . list functions NumPy docs . overview , popular useful ones sense NumPy . cover tutorial . Array Creation : arange , array , copy , , empty_like , eye , fromfile , fromfunction , identity , linspace , logspace , mgrid , ogrid , ones , ones_like , r _ , zeros , zeros_like Conversions : ndarray.astype , atleast_1d , atleast_2d , atleast_3d , mat Manipulations : array_split , column_stack , concatenate , diagonal , dsplit , dstack , hsplit , hstack , ndarray.item , newaxis , ravel , repeat , reshape , resize , squeeze , swapaxes , , transpose , vsplit , vstack Questions : , , nonzero , Ordering : argmax , argmin , argsort , max , min , ptp , searchsorted , sort Operations : choose , compress , cumprod , cumsum , inner , ndarray.fill , imag , prod , , putmask , real , sum Basic Statistics : cov , mean , std , var Basic Linear Algebra : cross , dot , outer , linalg.svd , vdot Section 1 : basics NumPy arrays NumPy array - n - dimensional data structure - central object NumPy package . - dimensional NumPy array thought vector , - dimensional array matrix ( i.e. , set vectors ) , - dimensional array tensor ( i.e. , set matrices ) . Need dimensions ? entirely possible arrays dimensions , including dimensions longer humanly possible conceptualize . Array data types array consist integers , floating - point numbers , strings . array , data type consistent ( e.g. , integers floats ) . Need array mixed data types ? Consider Numpy record array format pandas dataframes instead ( Pandas tutorial ) . article , restrict focus conventional NumPy arrays consisting single data type . Defining arrays define NumPy arrays number ways . detail common approaches . np.array ( ) define array manually , use np.array ( ) function . , pass list elements , list containing values . result 2x2 matrix : np.array([[1,2],[3,4 ] ] ) Learn Data Science : array([[1 , 2 ] , 
        [ 3 , 4 ] ] ) Learn Data Science simple ! data NumPy array , vast suite computing possibilities available . article concerned exploring possibilities . NumPy numerous functions generating commonly - arrays having enter elements manually . shown : Defining arrays : np.arange ( ) function np.arange ( ) great creating vectors easily . , create vector values spanning 1 ( including ) 5 : np.arange(1,5 ) Learn Data Science : array([1 , 2 , 3 , 4 ] ) Learn Data Science Defining arrays : np.zeros , np.ones , np.full programming tasks , useful initialize variable write value later code . variable happens NumPy array , common approach create array zeros element . np.zeros ( ) . , create array zeros rows column . np.zeros((3,1 ) ) Learn Data Science : array([[0 . ] , 
        [ 0 . ] , 
        [ 0 . ] ] ) Learn Data Science initialize array ones instead zeros : np.ones((3 , 1 ) ) Learn Data Science : array([[1 . ] , 
        [ 1 . ] , 
        [ 1 . ] ] ) Learn Data Science np.full ( ) creates array repeating fixed value ( defaults zero ) . create 2x3 array number 7 element : np.full((2,3),7 ) Learn Data Science : array([[7 , 7 , 7 ] , 
        [ 7 , 7 , 7 ] ] ) Learn Data Science Making arrays way helpful appending columns rows existing arrays , covered little later . Array shape arrays shape accessible .shape . example , let shape vector , matrix , tensor . vector = np.arange(5 ) 
 print("Vector shape : " , vector.shape ) 

 matrix = np.ones([3 , 2 ] ) 
 print("Matrix shape : " , matrix.shape ) 

 tensor = np.zeros([2 , 3 , 3 ] ) 
 print("Tensor shape : " , tensor.shape ) Learn Data Science : Vector shape : ( 5 , ) 
 Matrix shape : ( 3 , 2 ) 
 Tensor shape : ( 2 , 3 , 3 ) Learn Data Science shape vector - dimensional . number shape number elements ( rows ) . matrix , .shape tells rows columns . tensor slightly different . number matrices / slices . second gives number rows . provides number columns . familiar pandas , noticed syntax number rows columns strikingly similar equivalent pandas . continue explore NumPy arrays , notice similarities . print tensor , representation list 3x3 matrices : tensor Learn Data Science : array([[[0 . , 0 . , 0 . ] , 
         [ 0 . , 0 . , 0 . ] , 
         [ 0 . , 0 . , 0 . ] ] , 

        [ [ 0 . , 0 . , 0 . ] , 
         [ 0 . , 0 . , 0 . ] , 
         [ 0 . , 0 . , 0 . ] ] ] ) Learn Data Science Reshaping arrays reshape array compatible dimensions .reshape . example , want 3x3 matrix element incremented 1 9 . Easy : arr = np.arange(1 , 10 ) 
 print(arr , ' \n ' ) 

 # Reshape 3x3 matrix 
 arr = arr.reshape(3 , 3 ) 
 print(arr , ' \n ' ) 

 # Reshape original size 
 arr = arr.reshape(9 ) 
 print(arr ) Learn Data Science : [ 1 2 3 4 5 6 7 8 9 ] 

 [ [ 1 2 3 ] 
  [ 4 5 6 ] 
  [ 7 8 9 ] ] 

 [ 1 2 3 4 5 6 7 8 9 ] Learn Data Science Numpy try infer dimensions use -1 . need precisely correct number digits inference work . arr = np.arange(1 , 10).reshape(3 , -1 ) 
 print(arr ) Learn Data Science : [ [ 1 2 3 ] 
  [ 4 5 6 ] 
  [ 7 8 9 ] ] Learn Data Science Reading data file array Usually , data sets large define manually . Instead , common use case import data data file NumPy array . example , let publicly - available data U.S. Energy Information Administration . dataset explore contains information electricity generation USA range sources . download file , MER_T07_02A.csv , : https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T07.02A. data file CSV file , use csv module import data . worth noting NumPy functions read types data files directly NumPy arrays , np.genfromtxt ( ) text files . reading CSV file row - - row , appending list , converting NumPy array : import csv 

 data = [ ] 

 open('MER_T07_02A.csv ' , ' r ' ) csvfile : 
     file_reader = csv.reader(csvfile , delimiter= ' , ' ) 
     row file_reader : 
         data.append(row ) 
        
 data = np.array(data ) # convert list lists NumPy array Learn Data Science Note familiar pandas , simpler option use read_csv ( ) . pandas tutorial info . data stored NumPy array named data . remainder article , exploring NumPy functionality manipulate gain insights data . , explore attributes array . thing want know array dimensions : data.shape Learn Data Science : ( 8399 , 6 ) Learn Data Science - dimensional array , 8230 rows 6 columns data . property NumPy array wish know data type . information stored dtype attribute . Calling dtype reveals array strings : data.dtype.type Learn Data Science : numpy.str _ Learn Data Science Saving ready save data , use save function . np.save(open('data.npy ' , ' wb ' ) , data )       # Saves data binary file .npy extension Learn Data Science Indexing point , necessary index ( select ) subsets NumPy array . instance , want plot column data perform manipulation column . NumPy uses indexing notation MATLAB . Basics indexing notation Commas separate axes array . Colons mean " " . example , x[0:4 ] means 5 rows ( rows 0 4 ) x. Negative numbers mean " end array . " example , x[-1 ] means row x. Blanks colons means " rest " . example , x[3 :] means rest rows x row 3 . Similarly , x[:3 ] means rows row 3 . x [: ] means rows x. fewer indices axes , missing indices considered complete slices . example , 3 - axis array , x[0,0 ] means data 3rd axis 1st row 1st column . Dots " ... " mean colons needed produce complete indexing tuple . example , x[1,2 , ... ] x[1,2 , : , : , :] . following code , explore useful examples selecting subsets array . Examples Indexing example 1 : Colons commas Let interested rows 4th column . use following syntax index array section : _ _ array[start_row : end_row , col ] _ _ data[0:10,4 ] Learn Data Science : array(['Description ' , ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' ] , dtype='<U80 ' ) Learn Data Science row header column . Column 4 contains description energy sectors . Indexing example 1 : Colons * * rows columns colon denote rows , columns . , index rows column 4 . data[:,4 ] Learn Data Science : array(['Description ' , ' Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Coal , Sectors ' , ... , 
        ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
        ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
        ' Electricity Net Generation Total ( including sources shown ) , Sectors ' ] , 
       dtype='<U80 ' ) Learn Data Science Indexing example 3 : Subset columns use format dimension array . general syntax : array[start_row : end_row , start_col : end_col ] . following indexes rows second column ( including ) 4th column : data[:,2:4 ] Learn Data Science : array([['Value ' , ' Column_Order ' ] , 
        [ ' 135451.32 ' , ' 1 ' ] , 
        [ ' 154519.994 ' , ' 1 ' ] , 
        ... , 
        [ ' 334166.94 ' , ' 13 ' ] , 
        [ ' 314400.63 ' , ' 13 ' ] , 
        [ ' 301776.141 ' , ' 13 ' ] ] , dtype='<U80 ' ) Learn Data Science Indexing example 4 : Explicitly specifying column numbers columns need ? Instead indexing range columns , useful specify explicitly . explicitly specify particular columns , include list . Let index rows header , selecting columns 2 3 . time , write output new array named subset - use following example . subset = data[1:6 , [ 2,3 ] ] 
 subset Learn Data Science : array([['135451.32 ' , ' 1 ' ] , 
        [ ' 154519.994 ' , ' 1 ' ] , 
        [ ' 185203.657 ' , ' 1 ' ] , 
        [ ' 195436.666 ' , ' 1 ' ] , 
        [ ' 218846.325 ' , ' 1 ' ] ] , dtype='<U80 ' ) Learn Data Science Indexing example 5 : Mask arrays convenient way index certain sections NumPy array use mask array . mask array , known logical array , contains boolean elements ( i.e. True False ) . Indexing given array element determined value mask array corresponding element . , define NumPy array True / False values , True values ones want . mask subset array previous example . result retaining rows correspond elements True mask array . mask_array = np.array([False , True , False , True , True ] ) 

 subset[mask_array ] Learn Data Science : array([['154519.994 ' , ' 1 ' ] , 
        [ ' 195436.666 ' , ' 1 ' ] , 
        [ ' 218846.325 ' , ' 1 ' ] ] , dtype='<U80 ' ) Learn Data Science , mask array retained rows corresponding True excluded ones corresponding False . worth noting similar approach indexing pandas dataframes . Masking powerful tool allows index elements based logical expressions . good use case study later article . Concatenating NumPy provides useful functions concatenating ( i.e. , joining ) arrays . Let wanted restrict attention rows dataset . , define new sub - arrays follows : array_start = data[:3 , :] 
 array_start Learn Data Science : array([['MSN ' , ' YYYYMM ' , ' Value ' , ' Column_Order ' , ' Description ' , ' Unit ' ] , 
        [ ' CLETPUS ' , ' 194913 ' , ' 135451.32 ' , ' 1 ' , 
         ' Electricity Net Generation Coal , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' CLETPUS ' , ' 195013 ' , ' 154519.994 ' , ' 1 ' , 
         ' Electricity Net Generation Coal , Sectors ' , 
         ' Million Kilowatthours ' ] ] , dtype='<U80 ' ) Learn Data Science array_end = data[-3 : , :] 
 array_end Learn Data Science : array([['ELETPUS ' , ' 202009 ' , ' 334166.94 ' , ' 13 ' , 
         ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' ELETPUS ' , ' 202010 ' , ' 314400.63 ' , ' 13 ' , 
         ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' ELETPUS ' , ' 202011 ' , ' 301776.141 ' , ' 13 ' , 
         ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
         ' Million Kilowatthours ' ] ] , dtype='<U80 ' ) Learn Data Science concatenate arrays use np.vstack , v denotes vertical , row - wise , stacking sub - arrays : np.vstack((array_start , array_end ) ) Learn Data Science : array([['MSN ' , ' YYYYMM ' , ' Value ' , ' Column_Order ' , ' Description ' , ' Unit ' ] , 
        [ ' CLETPUS ' , ' 194913 ' , ' 135451.32 ' , ' 1 ' , 
         ' Electricity Net Generation Coal , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' CLETPUS ' , ' 195013 ' , ' 154519.994 ' , ' 1 ' , 
         ' Electricity Net Generation Coal , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' ELETPUS ' , ' 202009 ' , ' 334166.94 ' , ' 13 ' , 
         ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' ELETPUS ' , ' 202010 ' , ' 314400.63 ' , ' 13 ' , 
         ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' ELETPUS ' , ' 202011 ' , ' 301776.141 ' , ' 13 ' , 
         ' Electricity Net Generation Total ( including sources shown ) , Sectors ' , 
         ' Million Kilowatthours ' ] ] , dtype='<U80 ' ) Learn Data Science stacked rows rows . horizontal counterpart np.vstack ( ) np.hstack ( ) , combines sub - arrays column - wise . higher dimensional joins , common function np.concatenate ( ) . syntax function similar 2D versions , additional requirement specifying axis concatenation performed . Calling np.concatenate((array_start , array_end ) , axis = 0 ) generate identical output np.vstack ( ) . Axis=1 generate identical output np.hstack ( ) . Splitting opposite concatenating ( i.e. , joining ) arrays splitting . split array , NumPy provides following commands : hsplit : splits horizontal axis vsplit : splits vertical axis dsplit : Splits array 3rd axis ( depth ) array_split : lets specify axis use splitting Adding / Removing Elements NumPy provides functions adding deleting data array : resize : Returns new array specified shape , zeros placeholders new cells . append : Adds values end array insert : Adds values middle array delete : Returns new array given data removed unique : Finds unique values array Sorting useful functions sorting array elements . available sorting algorithms include quicksort , heapsort , mergesort , timesort . example , merge sort columns array : = np.array([[3,8,1,2 ] , [ 9,5,4,8 ] ] ) 
 np.sort(a , axis=1 , kind='mergesort ' ) 	   # Sort column Learn Data Science : array([[1 , 2 , 3 , 8 ] , 
        [ 4 , 5 , 8 , 9 ] ] ) Learn Data Science Copy vs. Shallow Copy vs. Deep Copy common source confusion NumPy beginners knowing data copied new object . copy : function calls assignments : print(id(a ) ) 

 # Object " b " points object " " . new object created . 
 b =       

 # Python passes objects references . copy . 
 def f(x ):   
     print(id(x ) ) 
    
 f(b ) Learn Data Science : 2270228861696 
 2270228861696 Learn Data Science Notice d b , passed function . View / Shallow Copy : Arrays share data . view method creates object looking data . Slicing array returns view array . # View 
 = b.view ( ) 

 # shape b change 
 = a.reshape((4 , 2 ) )    

 # Slice 
 # [: ] view " " . 
 [: ] = 5 Learn Data Science Deep copy : Use copy method complete copy array data . c = a.copy ( ) Learn Data Science copy ( ) method creates new array object c identical . Section 2 : - know tools Let look NumPy tools especially handy data science applications : broadcasting , vectorization , pseudo - random number generation . section , electricity dataset aside favor straightforward examples . Broadcasting Broadcasting process performed NumPy allows mathematical operations work objects necessarily compatible dimensions . Let explore broadcasting examples . Broadcasting example 1 : Adding scalar matrix Suppose like add 1 element 2x2 array . NumPy arrays , simple defining array adding 1 : array_a = np.array([[1 , 2 ] , 
                     [ 3 , 4 ] ] ) 

 array_a + 1 Learn Data Science : array([[2 , 3 ] , 
        [ 4 , 5 ] ] ) Learn Data Science mind university linear algebra instructor furious mentioned notion adding scalar matrix . reason : mathematically valid operation . , NumPy background valid . NumPy creates second array value 1 elements ( depicted transparent blocks figure ) . NumPy adds second array . words , NumPy broadcast scalar new array appropriate dimensions perform computation . Numpy accomplishes broadcasting computationally efficient way , key advantages broadcasting code . Broadcasting code simpler readable . Let look examples . Broadcasting example 2 : Multiplying matrix scalar Multiplication works way addition . array_a * 2 Learn Data Science : array([[2 , 4 ] , 
        [ 6 , 8 ] ] ) Learn Data Science Broadcasting example 3 : use broadcasting cases overcoming dimensional mismatch scalar array . NumPy broadcast arrays enable computations arrays . Let row array_a , defined , collection objects . coordinates object ( row array_a ) located ( x = 1 , y = 2 ) , object ( second row array_a ) located ( x = 3 , y = 4 ) . find coordinates objects translated 3 units x direction 1 unit y direction , need add ( 3 , 1 ) array_a : array_a + np.array([3 , 1 ] ) Learn Data Science : array([[4 , 3 ] , 
        [ 6 , 5 ] ] ) Learn Data Science time , NumPy created second 2x2 matrix ( background ) , rows equal [ 3 , 1 ] , perform operation . words , Numpy broadcasts 1x2 array array appropriate perform operation 2x2 array . operation equivalent depicted second row figure . examples broadcasting , best place look documentation . Let essential tool : vectorization . Vectorization Vectorization process modifying code utilize array operation methods . Array operations computed internally NumPy lower - level language , leads benefits : Vectorized code tends execute faster equivalent code uses loops ( - loops - loops ) . Usually lot faster . , vectorization important machine learning , work large datasets Vectorized code compact . Having fewer lines code write potentially speed - code - writing process , code readable , reduce risk errors Vectorization Example 1 Let consider problem - dimensional arrays , b , need multiply element corresponding element b . define arbitrary values b : = np.arange(1,51 ) 
 b = np.arange(51,101 ) 

 print("array : " , ) 
 print("\narray b : " , b ) Learn Data Science : array : [ 1   2   3   4   5   6   7   8   9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 
  25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 
  49 50 ] 

 array b : [ 51   52   53   54   55   56   57   58   59   60   61   62   63   64   65   66   67   68 
   69   70   71   72   73   74   75   76   77   78   79   80   81   82   83   84   85   86 
   87   88   89   90   91   92   93   94   95   96   97   98   99 100 ] Learn Data Science multiply elements simple Python loop . non - vectorized version : def non_vectorized_output(a , b ): 
     output = [ ] 
     j range(len(a ) ): 
         output.append(a[j]*b[j ] ) 
     return output Learn Data Science Calculating speed Jupyter magic timeit command , calculate long takes run function executions : nv_time = % timeit -o non_vectorized_output(a , b ) Learn Data Science : 21.4 µs ± 506 ns loop ( mean ± std . dev . 7 runs , 10000 loops ) Learn Data Science % timeit -o command run function executions store timing results variable . run % timeit non_vectorized_output(a , b ) care storing result variable . use multiplication operator arrays allow Numpy handle multiplication instead . vectorized version : def vectorized_output(a , b ): 
     return * b Learn Data Science v_time = % timeit -o vectorized_output(a , b ) Learn Data Science : 701 ns ± 14.3 ns loop ( mean ± std . dev . 7 runs , 1000000 loops ) Learn Data Science , looping non - vectorized version performed pure Python ( i.e. , NumPy ) - loop . challenging non - vectorized code function compactly , occupies lines code vectorized version . compactness looping vectorized version happens background . clear vectorized code compact , difference computation time ? Let print results way easier read : print('Non - vectorized version : ' , f'{1E6 * nv_time.average:0.2f } ' , ' microseconds execution , average ' ) 

 print('Vectorized version : ' , f'{1E6 * v_time.average:0.2f } ' , ' microseconds execution , average ' ) 

 print('Computation ' , " % .0f " % ( nv_time.average / v_time.average ) , ' times faster vectorization ' ) Learn Data Science : Non - vectorized version : 21.40 microseconds execution , average 
 Vectorized version : 0.70 microseconds execution , average 
 Computation 31 times faster vectorization Learn Data Science Vectorization example 2 second example , evaluate set linear expressions . , task accomplished - loops vectorized code . case , vectorized version use matrix multiplication evaluate linear expressions . familiar machine learning ( ML ) , paragraph provide context encounter ML . Machine Learning context Let imagine machine learning problem use linear regression algorithm model cost electricity . Let denote model features $ x_1 , x_2 ... x_{n}$. Features represent things like available wind energy , current gas price , current load grid . train algorithm , obtain model parameters , $ \theta_0,\theta_1,\theta_2 ... \theta_{n}$. model parameters constitute weights feature . instance , $ x_2 $ represent price gas . model find gas prices particularly decisive determining price electricity . corresponding weight $ \theta_2 $ expected larger magnitude weights important features . result ( hypothesis / prediction ) returned linear regression model given set $ x$ linear expression : $ $ h=\theta_0 + x_1 \theta_1 + x_2 \theta_2 + ... + x_{n } \theta_{n}$$ Furthermore , let assume set $ m$ test examples . words , $ m$ sets $ x$ like obtain model prediction . linear expression , $ h$ , calculated test examples . total $ m$ individual hypothesis outputs . , calculated concisely vectorized statement . start , define arbitrary values array test examples ( $ x$ ) , vector model parameters ( $ \theta$ , theta ) . ML problem , model parameters calculated output optimization procedure . sake example , use arbitrary values . , define 10x4 array ( x ) row training set . , $ m = 10 $ $ n = 4 $ : x = np.arange(1,41).reshape(10,4 ) 

 print('x:\n ' , x ) Learn Data Science : x : 
  [ [ 1   2   3   4 ] 
  [ 5   6   7   8 ] 
  [ 9 10 11 12 ] 
  [ 13 14 15 16 ] 
  [ 17 18 19 20 ] 
  [ 21 22 23 24 ] 
  [ 25 26 27 28 ] 
  [ 29 30 31 32 ] 
  [ 33 34 35 36 ] 
  [ 37 38 39 40 ] ] Learn Data Science x range 40 numbers reshaped 10 rows 4 columns . , add column ones represent $ x_0 $ , known machine learning bias term . x 10x5 array : ones = np.full((10,1),1 ) 

 x = np.hstack((ones , x ) ) 

 print('x:\n ' , x ) Learn Data Science : x : 
  [ [ 1   1   2   3   4 ] 
  [ 1   5   6   7   8 ] 
  [ 1   9 10 11 12 ] 
  [ 1 13 14 15 16 ] 
  [ 1 17 18 19 20 ] 
  [ 1 21 22 23 24 ] 
  [ 1 25 26 27 28 ] 
  [ 1 29 30 31 32 ] 
  [ 1 33 34 35 36 ] 
  [ 1 37 38 39 40 ] ] Learn Data Science np.full , created 10x1 array ones horizontally stacked ( np.hstack ) x . let initialize model parameters 5x1 array theta = np.arange(1,6).reshape(5,1 ) 

 print('theta:\n ' , theta ) Learn Data Science : theta : 
  [ [ 1 ] 
  [ 2 ] 
  [ 3 ] 
  [ 4 ] 
  [ 5 ] ] Learn Data Science Armed matrix $ x$ vector $ \theta$ , proceed define vectorized non - vectorized versions evaluating linear expressions compare computation time . # Non - vectorized version 
 def non_vectorized_output(x , theta ): 
     h = [ ] 
     range(x.shape[0 ] ): 
         total = 0 
         j range(x.shape[1 ] ): 
             total = total + x[i , j ] * theta[j , 0 ] 
         h.append(total ) 
     return h 
    
 # Vectorized version 
 def vectorized_output(x , theta ): 
     h = np.matmul(x , theta ) # NumPy matrix multiplication function 
     return h Learn Data Science nv_time = % timeit -o non_vectorized_output(x , theta ) Learn Data Science : 34.7 µs ± 410 ns loop ( mean ± std . dev . 7 runs , 10000 loops ) Learn Data Science v_time = % timeit -o vectorized_output(x , theta ) Learn Data Science : 1.58 µs ± 9.66 ns loop ( mean ± std . dev . 7 runs , 1000000 loops ) Learn Data Science print('Non - vectorized version : ' , f'{1E6 * nv_time.average:0.2f } ' , ' microseconds execution , average ' ) 

 print('Vectorized version : ' , f'{1E6 * v_time.average:0.2f } ' , ' microseconds execution , average ' ) 

 print('Computation ' , " % .0f " % ( nv_time.average / v_time.average ) , ' times faster vectorization ' ) Learn Data Science : Non - vectorized version : 34.69 microseconds execution , average 
 Vectorized version : 1.58 microseconds execution , average 
 Computation 22 times faster vectorization Learn Data Science Note examples , NumPy vectorized calculations significantly outperformed native Python calculations loops . improved performance substantial . , vectorization potential disadvantages . Vectorized code intuitive know read . memory intensive . skill knowing vectorization use code develop experience . decision need based nature application question . Pseudo - random number generation finish section , NumPy functionality cover : pseudo - random number generation . able generate pseudo - random numbers necessary data science applications . Examples include modeling system noise Monte Carlo simulations . generate random numbers ( x ) commonly encountered probability distributions : uniform distribution normal ( Gaussian ) distribution . , import matplotlib set default plotting styles : import matplotlib.pyplot plt 
 import matplotlib 

 # Set default plotting parameters 
 matplotlib.rcParams.update({'font.size ' : 16 , 
                            ' figure.figsize ' : [ 10 , 6 ] , 
                            ' lines.markersize ' : 6 } ) Learn Data Science Uniform , generate NumPy array 1000 samples randomly selected uniform distribution random.rand . Normal , generate NumPy array 1000 samples normal distribution centred 5 standard deviation 3 random.normal : uniform_data = np.random.rand(1000 ) 
 normal_data = np.random.normal(loc=5 , scale=3.0 , size=1000 ) Learn Data Science plot histograms Uniform data ( subplot ) Normal data ( second subplot ): fig = plt.figure ( )    # Define figure 

 ax1 = fig.add_subplot(1,2,1 )    # define location subplot 
 ax1.hist(x = uniform_data , bins='auto',alpha=0.7 , rwidth=0.85 ) 
 ax1.set_title("Uniform Distribution " ) 

 ax2 = fig.add_subplot(1,2,2 )    # define location second subplot 
 ax2.hist(x = normal_data , bins='auto ' , alpha=0.7 , rwidth=0.7 ) 
 ax2.set_title("Normal Distribution " ) 

 ax1.set_ylabel('Frequency ' ) 
 ax1.set_xlabel('x ' ) 
 ax2.set_xlabel('x ' ) 
 plt.show ( ) Learn Data Science RESULT : expect , uniform distribution random values equally spaced zero . contrast , values normal distribution characteristic bell - curve shape . use sets random numbers generated computations , leave time . wrap article , let learned electricity dataset . Section 3 : Putting know basics NumPy , broadcasting , vectorization , need start diving electricity data imported start article . Let assume like understand USA electricity generation changed time . Viewing data learned indexing , start separating column labels rest data . header = data[0 , :]    # create new NumPy array containing column labels 
 data = data[1 : , :]    # remove header rest data 

 print('Header:\n',header , ' \n\nFirst rows:\n ' , data[:2 , :] ) Learn Data Science : Header : 
  [ ' MSN ' ' YYYYMM ' ' Value ' ' Column_Order ' ' Description ' ' Unit ' ] 

 rows : 
  [ [ ' CLETPUS ' ' 194913 ' ' 135451.32 ' ' 1 ' 
   ' Electricity Net Generation Coal , Sectors ' 
   ' Million Kilowatthours ' ] 
  [ ' CLETPUS ' ' 195013 ' ' 154519.994 ' ' 1 ' 
   ' Electricity Net Generation Coal , Sectors ' 
   ' Million Kilowatthours ' ] ] Learn Data Science understand electricity generation changed time , need pay attention column 1 ( date ) , column 2 ( energy generated ) , column 4 ( description ) . dataset , rows containing monthly data express date format ' YYYYMM ' . Rows containing annual data express date format ' YYYY13 ' . dataset happens contain generation data different energy sources , let determine energy sources present dataset inspecting descriptions ( column 4 ) . np.unique ( ) function makes easy energy sources . suggests , return unique values array . np.unique(data[:,4 ] ) Learn Data Science : array(['Electricity Net Generation Coal , Sectors ' , 
        ' Electricity Net Generation Conventional Hydroelectric Power , Sectors ' , 
        ' Electricity Net Generation Geothermal , Sectors ' , 
        ' Electricity Net Generation Hydroelectric Pumped Storage , Sectors ' , 
        ' Electricity Net Generation Natural Gas , Sectors ' , 
        ' Electricity Net Generation Nuclear Electric Power , Sectors ' , 
        ' Electricity Net Generation Gases , Sectors ' , 
        ' Electricity Net Generation Petroleum , Sectors ' , 
        ' Electricity Net Generation Solar , Sectors ' , 
        ' Electricity Net Generation Waste , Sectors ' , 
        ' Electricity Net Generation Wind , Sectors ' , 
        ' Electricity Net Generation Wood , Sectors ' , 
        ' Electricity Net Generation Total ( including sources shown ) , Sectors ' ] , 
       dtype='<U80 ' ) Learn Data Science dataset contains information total 13 categories energy sources . Extracting wind energy data , extract subset containing wind energy generation data . making extensive use indexing mask arrays , looked earlier . Let start retaining rows contain wind data . , create mask array contains True entries row wind data : mask_array = ( data[:,4 ] = = ' Electricity Net Generation Wind , Sectors ' ) 
 mask_array Learn Data Science : array([False , False , False , ... , False , False , False ] ) Learn Data Science mask array essentially says " rows column equals ' Electricity Net Generation ... ' " use mask data : wind_data = data[mask_array ] 
 wind_data Learn Data Science : array([['WYETPUS ' , ' 194913 ' , ' Available ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 195013 ' , ' Available ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 195113 ' , ' Available ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        ... , 
        [ ' WYETPUS ' , ' 202009 ' , ' 23176.032 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 202010 ' , ' 29418.649 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 202011 ' , ' 33848.129 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] ] , dtype='<U80 ' ) Learn Data Science notice broadcasting generate mask array ? Broadcasting allowed generation new array based logical evaluation string element array equal single string . output , notice early rows contain string _ Available _ ' Value ' column . _ Available _ suggests records began later . Let exclude rows records exist : wind_data = wind_data[wind_data[:,2 ] ! = ' Available ' ] 
 wind_data Learn Data Science : array([['WYETPUS ' , ' 198301 ' , ' 0.172 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 198302 ' , ' 0.018 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 198303 ' , ' 0.313 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        ... , 
        [ ' WYETPUS ' , ' 202009 ' , ' 23176.032 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 202010 ' , ' 29418.649 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 202011 ' , ' 33848.129 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] ] , dtype='<U80 ' ) Learn Data Science Note code performed indexing mask array . compactness , explicitly define mask array separate object . , let retain annual data . words , rows value column 1 ends ' 13 ' . , use list comprehension ( pure Python formalism ) generate mask array perform indexing . annual_mask_array = np.array(([x[-2 :] = = ' 13 ' x wind_data[:,1 ] ] ) ) 

 wind_data = wind_data[annual_mask_array ] 
 wind_data[:5 ] Learn Data Science : array([['WYETPUS ' , ' 198313 ' , ' 2.668 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 198413 ' , ' 6.49 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 198513 ' , ' 5.762 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 198613 ' , ' 4.189 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] , 
        [ ' WYETPUS ' , ' 198713 ' , ' 3.541 ' , ' 12 ' , 
         ' Electricity Net Generation Wind , Sectors ' , 
         ' Million Kilowatthours ' ] ] , dtype='<U80 ' ) Learn Data Science successfully isolated annual wind data . worth noting straightforward save NumPy array text file np.savetxt ( ) function . fun , let save results comma - delimited csv file . request NumPy converts string format exporting . np.savetxt('wind.csv',wind_data , fmt = ' % s ' , delimiter = ' , ' ) Learn Data Science let define new NumPy array containing annual wind energy produced , contained column wind data array . convert information float data type : energy = wind_data[:,2].astype(float ) 
 energy Learn Data Science : array([2.66800000e+00 , 6.49000000e+00 , 5.76200000e+00 , 4.18900000e+00 , 
        3.54100000e+00 , 8.71000000e-01 , 2.11204300e+03 , 2.78860000e+03 , 
        2.95095100e+03 , 2.88752300e+03 , 3.00582700e+03 , 3.44710900e+03 , 
        3.16425300e+03 , 3.23406900e+03 , 3.28803500e+03 , 3.02569600e+03 , 
        4.48799800e+03 , 5.59326100e+03 , 6.73733100e+03 , 1.03542800e+04 , 
        1.11874660e+04 , 1.41437410e+04 , 1.78105490e+04 , 2.65891370e+04 , 
        3.44499270e+04 , 5.53631000e+04 , 7.38861320e+04 , 9.46522460e+04 , 
        1.20176599e+05 , 1.40821703e+05 , 1.67839745e+05 , 1.81655282e+05 , 
        1.90718548e+05 , 2.26992562e+05 , 2.54302695e+05 , 2.72667454e+05 , 
        2.94906320e+05 ] ) Learn Data Science Success ! finally data interest array floating - point numbers , start taking advantage NumPy functions quickly easily perform numerical operations array . Mathematical functions NumPy offers mathematical functions called syntax array.method ( ) . instance , wanted compute sum elements array , use function array.sum ( ) : print(f'Total wind energy generated USA 1983 { energy.sum ( ) } Gigawatt - hours ' ) Learn Data Science : Total wind energy generated USA 1983 2235263.7029999997 Gigawatt - hours Learn Data Science Easy . NumPy functions available calculate things like mean standard deviation : print(f'The average annual energy generated wind { energy.mean ( ) } Gigawatt - hours , ' 
       f'with standard deviation { 100 * energy.std ( ) / energy.mean():.2f}% ' ) Learn Data Science : average annual energy generated wind 60412.532513513506 Gigawatt - hours , standard deviation 147.70 % Learn Data Science quickly answer questions functions . couple . maximum annual energy generated ? print(f'The highest recorded annual energy generated wind power { energy.max ( ) } Gigawatt - hours ' ) Learn Data Science : highest recorded annual energy generated wind power 294906.32 Gigawatt - hours Learn Data Science year occur ? index = energy.argmax ( ) # method returns index maximum value array 
 print(f'The highest energy generation occured year { wind_data[index,1][:-2 ] } ' ) Learn Data Science : highest energy generation occured year 2019 Learn Data Science Fitting important NumPy capability data fitting . Let wanted predict wind energy generated year period spanned dataset . straightforward approach fit straight line recent data extrapolate following year . SciPy powerful fitting tools , particular scipy.optimize.curve_fit ( ) , turns need outside NumPy perform fit . NumPy , options include np.linalg.lstsq ( ) NumPy polynomial package . , use . import numpy.polynomial.polynomial poly 

 x = np.array([int(j[:4 ] ) j wind_data[:,1 ] ] ) # Taking digits entry column 1 gives year 
 y = energy 

 poly_coeff= poly.polyfit(x[-10 :] , y[-10:],deg=1 ) # coefficients - degree polynomial ( straight line ) fit recent 10 years data 
 fit = poly.polyval(x[-10 :] , poly_coeff ) # Evaluate fitted polynomial polynomial coefficients 

 fig , ax = plt.subplots ( ) # Define figure axis plot data 
 ax.plot(x , y , ' ro ' , label = ' Data ' ) # Plot data 
 ax.plot(x[-10 :] , fit , ' b- ' , label='Linear fit 10 years ' ) # Plot fit 

 # Extrapolate 
 new_point = x[-1 ] + 1 # 1 year final datapoint 
 fit_new_point = poly.polyval(new_point , poly_coeff ) 
 ax.plot(new_point , fit_new_point , ' gs ' , label = f'Predicted value { str(new_point ) } ' ) # Plot fit 

 # Label axes 
 ax.set_xlabel('Year ' ) 
 ax.set_ylabel('Net electricity generation \n wind ( Gwh ) ' ) 

 # Add legend 
 plt.legend ( ) 

 plt.show ( ) 

 plt.close ( ) Learn Data Science RESULT : Notice matplotlib plotting commands accepted NumPy arrays inputs problem . find compatibility NumPy libraries Python . degree compatibility reflects NumPy core role Python overall data science scientific computing capability . plot ... plot shows wind - generated electricity increased rapidly USA years . simply consequence total electricity generation increasing ? national grid fundamentally shifting wind energy ? NumPy help answer . things compact , define function index certain rows primary dataset based earlier approach . def index_energy_data(data , startyear , energy_label ): 
     " " " returns NumPy array containing rows specified energy_label column 4 , 
     contain energy data , contain annual totals specified start year " " " 
    
     output = data[((data[:,4 ] = = energy_label ) ) ] 
     output = output[((output[:,2 ] ! = ' Available ' ) ) ] 
     output = output[np.array(([x[-2 :] = = ' 13 ' int(x[:4 ] ) > = startyear x output[:,1 ] ] ) ) ] 
    
     energy = output[:,2].astype(float ) 
     dates = np.array([int(j[:4 ] ) j output[:,1 ] ] )   # Taking digits entry column 1 gives year 
    
     return energy , dates Learn Data Science apply function generate arrays . Solar data recorded 1984 onwards , restrict arrays timeframe : energy_wind , dates = index_energy_data(data , 1984 , energy_label = ' Electricity Net Generation Wind , Sectors ' ) 
 energy_solar , dates = index_energy_data(data , 1984 , energy_label = ' Electricity Net Generation Solar , Sectors ' ) 
 energy_total , dates = index_energy_data(data , 1984 , energy_label = ' Electricity Net Generation Total ( including sources shown ) , Sectors ' ) Learn Data Science Let compute contribution wind , solar , combined contribution compared total energy generation USA : wind_frac = 100 * energy_wind / energy_total 
 solar_frac = 100 * energy_solar / energy_total 
 combined_frac = 100 * ( energy_solar + energy_wind ) / energy_total Learn Data Science data . notice use vectorization broadcasting ? Let proceed plotting results : # Prepare plot 
 fig , ax = plt.subplots ( ) # Define figure axis plot data 
 ax.plot(dates , wind_frac , ' ro- ' , label = ' Wind ' ) 
 ax.plot(dates , solar_frac , ' bo- ' , label = ' Solar ' ) 
 ax.plot(dates , combined_frac , ' ko- ' , label = ' Wind + Solar ' ) 

 # Label axes 
 ax.set_xlabel('Year ' ) 
 ax.set_ylabel('Contribution total USA \n electricity generation ( % ) ' ) 

 # add legend 
 plt.legend ( ) 

 plt.show ( ) 

 plt.close ( ) Learn Data Science RESULT : plot shows , nature national grid changing : rapid change mix electricity sources occurring . answer questions , like driving change , need lot data situation social economic factors . Rest assured , soon data , NumPy task performing required data manipulations ! Summary article , explored handy computing tools offered NumPy library . learned central object NumPy library - NumPy array . learned create arrays ways : manually , NumPy functions , loading data external file array . explored essential tools especially useful dealing large datasets : vectorization broadcasting . , walked example NumPy . loaded real set data historical electricity generation United States . analyzed data obtain insight fundamental change electricity mix time . article provided overview NumPy capabilities . ready start NumPy projects . sure refer documentation ( https://numpy.org/doc/ ) specifics capabilities . Good luck ! Course Recommendations learning : Numerical Python ( Book ) Scientific Computing Data Science Applications Numpy , SciPy Matplotlib Deeplearning.ai Neural Networks Deep Learning ( Course ) things , learn use NumPy building Neural Networks . Start Learning Free updates inbox Join 7,500 data science learners . Recent articles : 9 Best AI Courses Online 2024 : Beginner Advanced 6 Best Python Courses 2024 – Ranked Software Engineer Best Course Deals Black Friday Cyber Monday 2024 Sigmoid Function 7 Best Artificial Intelligence ( AI ) Courses courses today begin journey Artificial Intelligence field . Learn updates inbox Join 7,500 data science learners . Meet Authors Ricky Dunbar Solar Energy Engineer , Ph.D. Physics Ricky holds Ph.D. physics currently works Silicon Valley , USA . Editor : Rhys Psychometrician Editor : Brendan Founder LearnDataSci blog index Load Comments Best Data Science Courses Best Machine Learning Courses Best Udemy Courses Data Science & Machine Learning Glossary Free Data Science Books Privacy Policy © 2024 LearnDataSci . rights reserved . Use and/or registration portion site constitutes acceptance Privacy Policy . material site reproduced , distributed , transmitted , remixed , cached , prior written permission LearnDataSci.com . updates inbox Join 7,500 data science learners .