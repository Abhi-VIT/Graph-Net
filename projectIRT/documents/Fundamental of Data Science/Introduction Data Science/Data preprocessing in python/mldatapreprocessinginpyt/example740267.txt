ML | Data Preprocessing Python | GeeksforGeeks Skip content Courses DSA Development GATE Courses IBM Certification Newly Launched ! Master Django Framework AWS Certified Working Professionals Interview 101 : DSA & System Design Data Science Training Program JAVA Backend Development ( Live ) DevOps Engineering ( LIVE ) Data Structures & Algorithms Python Students Placement Preparation Course Data Science ( Live ) Data Structure & Algorithm - Self Paced ( C++/JAVA ) Master Competitive Programming ( Live ) Stack Development React & Node JS ( Live ) Stack Development Data Science Program Courses Tutorials Data Structures & Algorithms ML & Data Science Interview Corner Programming Languages Web Development GATE CS Subjects DevOps Linux School Learning Practice Practice Coding Problems GfG 160 Problem Day Discover GitHub Copilot Build AI Agent Contests Accenture Data & AI Week GfG Weekly [ Rated Contest ] Job - - Thon Hiring Challenge Contests Events Notifications Mark read View Notifications Mark read Unread Read caught ! ! Data Science IBM Certification Data Science Data Science Projects Data Analysis Data Visualization Machine Learning ML Projects Deep Learning NLP Computer Vision Artificial Intelligence Sign â–² Open App Explore GfG Courses Share Experiences Data Analysis Python Introduction Data Analysis Data Analysis ? Data Analytics type Install Numpy Windows ? Install Pandas Python ? Install Matplotlib python ? Install Python Tensorflow Windows ? Data Analysis Libraries Pandas Tutorial NumPy Tutorial - Python Library Data Analysis SciPy Introduction TensorFlow Data Visulization Libraries Matplotlib Tutorial Python Seaborn Tutorial Plotly tutorial Introduction Bokeh Python Exploratory Data Analysis ( EDA ) Univariate , Bivariate Multivariate data analysis Measures Central Tendency Statistics Measures Spread - Range , Variance , Standard Deviation Interquartile Range Quartile Deviation NumPy SciPy Anova Formula Skewness Statistical Data Calculate Skewness Kurtosis Python ? Difference Skewness Kurtosis Histogram | Meaning , Example , Types Steps Draw Interpretations Histogram Box Plot Quantile Quantile plots Univariate , Bivariate & Multivariate Analysis Data Visualisation ? pandas crosstab create bar plot Exploring Correlation Python Covariance Correlation Factor Analysis | Data Analysis Data Mining - Cluster Analysis MANOVA Test R Programming MANOVA Test R Programming Python - Central Limit Theorem Probability Distribution Function Probability Density Estimation & Maximum Likelihood Estimation Exponential Distribution R Programming - dexp ( ) , pexp ( ) , qexp ( ) , rexp ( ) Functions Mathematics | Probability Distributions Set 4 ( Binomial Distribution ) Poisson Distribution | Definition , Formula , Table Examples P - Value : Comprehensive Guide Understand , Apply , Interpret Z - Score Statistics | Definition , Formula , Calculation Uses Calculate Point Estimates R ? Confidence Interval Chi - square test Machine Learning Understanding Hypothesis Testing Data Preprocessing ML | Data Preprocessing Python ML | Overview Data Cleaning ML | Handling Missing Values Detect Remove Outliers Python Data Transformation Data Normalization Machine Learning Sampling distribution Python Time Series Data Analysis Data Mining - Time - Series , Symbolic Biological Sequences Data Basic DateTime Operations Python Time Series Analysis & Visualization Python deal missing values Timeseries Python ? calculate MOVING AVERAGE Pandas DataFrame ? trend time series ? Perform Augmented Dickey - Fuller Test R AutoCorrelation Case Studies Projects Step Step Predictive Analysis - Machine Learning 6 Tips Creating Effective Data Visualizations Machine Learning & Data Science Course ML | Data Preprocessing Python Updated : 17 Jan , 2025 Comments Improve Suggest changes Like Article Like Report Data preprocessing important step data science transforming raw data clean structured format analysis . involves tasks like handling missing values , normalizing data encoding variables . Mastering preprocessing Python ensures reliable insights accurate predictions effective decision - making . Pre - processing refers transformations applied data feeding algorithm . Data Preprocessing Steps Data Preprocessing Step 1 : Import necessary libraries Python # importing libraries import pandas pd import scipy import numpy np sklearn.preprocessing import MinMaxScaler import seaborn sns import matplotlib.pyplot plt Step 2 : Load dataset download dataset . Python # Load dataset df = pd . read_csv ( ' Geeksforgeeks / Data / diabetes.csv ' ) print ( df . head ( ) ) Output : Pregnancies   Glucose   BloodPressure   SkinThickness   Insulin    BMI   
 0             6       148              72              35         0   33.6   \ 
 1             1        85              66              29         0   26.6   
 2             8       183              64               0         0   23.3   
 3             1        89              66              23        94   28.1   
 4             0       137              40              35       168   43.1   

    DiabetesPedigreeFunction   Age   Outcome  
 0                      0.627    50         1  
 1                      0.351    31         0  
 2                      0.672    32         1  
 3                      0.167    21         0  
 4                      2.288    33         1 1 . Check data info Python df . info ( ) Output : < class ' pandas.core.frame . DataFrame ' > 
 RangeIndex : 768 entries , 0 767 
 Data columns ( total 9 columns ): 
  #    Column                     Non - Null Count   Dtype  
 ---   ------                     --------------   -----  
  0    Pregnancies                768 non - null     int64  
  1    Glucose                    768 non - null     int64  
  2    BloodPressure              768 non - null     int64  
  3    SkinThickness              768 non - null     int64  
  4    Insulin                    768 non - null     int64  
  5    BMI                        768 non - null     float64 
  6    DiabetesPedigreeFunction   768 non - null     float64 
  7    Age                        768 non - null     int64  
  8    Outcome                    768 non - null     int64  
 dtypes : float64(2 ) , int64(7 ) 
 memory usage : 54.1 KB info dataset 9 columns columns 768 values . Null values dataset . check null values df.isnull ( ) Python df . isnull ( ) . sum ( ) Output : Pregnancies                  0 
 Glucose                      0 
 BloodPressure                0 
 SkinThickness                0 
 Insulin                      0 
 BMI                          0 
 DiabetesPedigreeFunction     0 
 Age                          0 
 Outcome                      0 
 dtype : int64 Step 2 : Statistical Analysis statistical analysis use df.describe ( ) descriptive overview dataset . Python df . describe ( ) Output : Data summary table shows count , mean , standard deviation , min , 25 % , 50 % , 75 % max values column . carefully observe table find Insulin , Pregnancies , BMI , BloodPressure columns outliers . Let plot boxplot column easy understanding . Step 3 : Check outliers Python # Box Plots fig , axs = plt . subplots ( 9 , 1 , dpi = 95 , figsize = ( 7 , 17 ) ) = 0 col df . columns : axs [ ] . boxplot ( df [ col ] , vert = False ) axs [ ] . set_ylabel ( col ) + = 1 plt . ( ) Output : Boxplots boxplot clearly column amounts outliers . Step 4 : Drop outliers Python # Identify quartiles q1 , q3 = np . percentile ( df [ ' Insulin ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 1.5 * iqr ) upper_bound = q3 + ( 1.5 * iqr ) # Drop outliers clean_data = df [ ( df [ ' Insulin ' ] > = lower_bound ) & ( df [ ' Insulin ' ] < = upper_bound ) ] # Identify quartiles q1 , q3 = np . percentile ( clean_data [ ' Pregnancies ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 1.5 * iqr ) upper_bound = q3 + ( 1.5 * iqr ) # Drop outliers clean_data = clean_data [ ( clean_data [ ' Pregnancies ' ] > = lower_bound ) & ( clean_data [ ' Pregnancies ' ] < = upper_bound ) ] # Identify quartiles q1 , q3 = np . percentile ( clean_data [ ' Age ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 1.5 * iqr ) upper_bound = q3 + ( 1.5 * iqr ) # Drop outliers clean_data = clean_data [ ( clean_data [ ' Age ' ] > = lower_bound ) & ( clean_data [ ' Age ' ] < = upper_bound ) ] # Identify quartiles q1 , q3 = np . percentile ( clean_data [ ' Glucose ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 1.5 * iqr ) upper_bound = q3 + ( 1.5 * iqr ) # Drop outliers clean_data = clean_data [ ( clean_data [ ' Glucose ' ] > = lower_bound ) & ( clean_data [ ' Glucose ' ] < = upper_bound ) ] # Identify quartiles q1 , q3 = np . percentile ( clean_data [ ' BloodPressure ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 0.75 * iqr ) upper_bound = q3 + ( 0.75 * iqr ) # Drop outliers clean_data = clean_data [ ( clean_data [ ' BloodPressure ' ] > = lower_bound ) & ( clean_data [ ' BloodPressure ' ] < = upper_bound ) ] # Identify quartiles q1 , q3 = np . percentile ( clean_data [ ' BMI ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 1.5 * iqr ) upper_bound = q3 + ( 1.5 * iqr ) # Drop outliers clean_data = clean_data [ ( clean_data [ ' BMI ' ] > = lower_bound ) & ( clean_data [ ' BMI ' ] < = upper_bound ) ] # Identify quartiles q1 , q3 = np . percentile ( clean_data [ ' DiabetesPedigreeFunction ' ] , [ 25 , 75 ] ) # Calculate interquartile range iqr = q3 - q1 # Calculate lower upper bounds lower_bound = q1 - ( 1.5 * iqr ) upper_bound = q3 + ( 1.5 * iqr ) # Drop outliers clean_data = clean_data [ ( clean_data [ ' DiabetesPedigreeFunction ' ] > = lower_bound ) & ( clean_data [ ' DiabetesPedigreeFunction ' ] < = upper_bound ) ] Step 5 : Correlation Python # correlation corr = df . corr ( ) plt . figure ( dpi = 130 ) sns . heatmap ( df . corr ( ) , annot = True , fmt = ' .2f ' ) plt . ( ) Output : Correlation compare single columns descending order Python corr [ ' Outcome ' ] . sort_values ( ascending = False ) Output : Outcome                      1.000000 
 Glucose                      0.466581 
 BMI                          0.292695 
 Age                          0.238356 
 Pregnancies                  0.221898 
 DiabetesPedigreeFunction     0.173844 
 Insulin                      0.130548 
 SkinThickness                0.074752 
 BloodPressure                0.0 Step 6 : Check Outcomes Proportionality Python plt . pie ( df . Outcome . value_counts ( ) , labels = [ ' Diabetes ' , ' Diabetes ' ] , autopct = ' % .f ' , shadow = True ) plt . title ( ' Outcome Proportionality ' ) plt . ( ) Output : Outcome Proportionality Step 7 : Separate independent features Target Variables Python # separate array input output components X = df . drop ( columns = [ ' Outcome ' ] ) Y = df . Outcome Step 7 : Normalization Standardization Normalization Normalization works features different scales algorithm sensitive scale features , k - nearest neighbors neural networks . Rescale data scikit - learn MinMaxScaler . MinMaxScaler scales data feature range [ 0 , 1 ] . Python # initialising MinMaxScaler scaler = MinMaxScaler ( feature_range = ( 0 , 1 ) ) # learning statistical parameters data transforming rescaledX = scaler . fit_transform ( X ) rescaledX [: 5 ] Output : array([[0.353 , 0.744 , 0.59 , 0.354 , 0 .    , 0.501 , 0.234 , 0.483 ] , 
        [ 0.059 , 0.427 , 0.541 , 0.293 , 0 .    , 0.396 , 0.117 , 0.167 ] , 
        [ 0.471 , 0.92 , 0.525 , 0 .    , 0 .    , 0.347 , 0.254 , 0.183 ] , 
        [ 0.059 , 0.447 , 0.541 , 0.232 , 0.111 , 0.419 , 0.038 , 0 .    ] , 
        [ 0 .    , 0.688 , 0.328 , 0.354 , 0.199 , 0.642 , 0.944 , 0.2   ] ] ) Standardization Standardization useful technique transform attributes Gaussian distribution differing means standard deviations standard Gaussian distribution mean 0 standard deviation 1 . standardize data scikit - learn StandardScaler class . works features normal distribution algorithm sensitive scale features Python sklearn.preprocessing import StandardScaler scaler = StandardScaler ( ) . fit ( X ) rescaledX = scaler . transform ( X ) rescaledX [: 5 ] Output : array ( [ [ 0.64 ,   0.848 ,   0.15 ,   0.907 , -0.693 ,   0.204 ,   0.468 ,   1.426 ] , 
        [ -0.845 , -1.123 , -0.161 ,   0.531 , -0.693 , -0.684 , -0.365 , -0.191 ] , 
        [ 1.234 ,   1.944 , -0.264 , -1.288 , -0.693 , -1.103 ,   0.604 , -0.106 ] , 
        [ -0.845 , -0.998 , -0.161 ,   0.155 ,   0.123 , -0.494 , -0.921 , -1.042 ] , 
        [ -1.142 ,   0.504 , -1.505 ,   0.907 ,   0.766 ,   1.41 ,   5.485 ] conclusion data preprocessing important step raw data clean analysis . Python handle missing values , organize data prepare accurate results . ensures model reliable helps uncover valuable insights data . Comment info Advertise Article ML | Overview Data Cleaning GeeksforGeeks Improve Article Tags : AI - ML - DS Machine Learning AI - ML - DS Python Practice Tags : Machine Learning Similar Reads Categorical Data Encoding Techniques Machine Learning Machine learning algorithms perform effectively numeric values , categorical data converted numerical format . article , explore var ... 15 + min read Pandas Find Duplicate Rows simple way find duplicate rows DataFrame duplicated ( ) method . method returns boolean Series indicating row duplicate ... 8 min read Contextual Analysis NLP Contextual Analysis NLP understanding deeper meaning sentences looking bigger picture . helps answer simple important questions like : Wh ... 15 + min read Data Imputation Techniques ML Data lifeblood machine learning ( ML ) models . , real - world datasets incomplete missing data wreak havoc performance ML model ... 15 + min read ML | Overview Data Cleaning Data cleaning important step machine learning ( ML ) pipeline involves identifying removing missing duplicate irrelevant data . goal data ... 15 + min read ML | Handling Missing Values Missing values common issue machine learning . occurs particular variable lacks data points , resulting incomplete information potentially harmin ... 15 + min read Feature Engineering : Scaling , Normalization , Standardization Feature Scaling technique standardize independent features present data . performed data pre - processing handle highly varying values .... 15 + min read Getting started Classification Classification teaches machine sort things categories . learns looking examples labels ( like emails marked " spam " " spam " ) . learning , ... 15 + min read Best Python libraries Machine Learning Machine learning important component fields , enabling organizations analyze data , predictions , automate processes . Python known ... 15 + min read Data Preprocessing , Analysis , Visualization building Machine learning model article , going concept Data Preprocessing , Analysis , Visualization building Machine learning model . Business owners organization ... 15 + min read Like 2k+ interested Geeks Artificial Intelligence Kids - Complete AI Course Beginners Explore 419k+ interested Geeks Complete Machine Learning & Data Science Program Explore 44k+ interested Geeks Data Science Training Program Explore Corporate & Communications Address : A-143 , 7th Floor , Sovereign Corporate Tower , Sector- 136 , Noida , Uttar Pradesh ( 201305 ) Registered Address : K 061 , Tower K , Gulshan Vivante Apartment , Sector 137 , Noida , Gautam Buddh Nagar , Uttar Pradesh , 201305 Advertise Company Legal Privacy Policy Careers Media Contact GfG Corporate Solution Placement Training Program Explore Job - - Thon Hiring Challenge GfG Weekly Contest Offline Classroom Program DSA JAVA / C++ Master System Design Master CP GeeksforGeeks Videos Languages Python Java C++ PHP GoLang SQL R Language Android Tutorial DSA Data Structures Algorithms DSA Beginners Basic DSA Problems DSA Roadmap DSA Interview Questions Competitive Programming Data Science & ML Data Science Python Data Science Beginner Machine Learning ML Maths Data Visualisation Pandas NumPy NLP Deep Learning Web Technologies HTML CSS JavaScript TypeScript ReactJS NextJS NodeJs Bootstrap Tailwind CSS Python Tutorial Python Programming Examples Django Tutorial Python Projects Python Tkinter Web Scraping OpenCV Tutorial Python Interview Question Computer Science GATE CS Notes Operating Systems Computer Network Database Management System Software Engineering Digital Logic Design Engineering Maths DevOps Git AWS Docker Kubernetes Azure GCP DevOps Roadmap System Design High Level Design Low Level Design UML Diagrams Interview Guide Design Patterns OOAD System Design Bootcamp Interview Questions School Subjects Mathematics Physics Chemistry Biology Social Science English Grammar Databases SQL MYSQL PostgreSQL PL / SQL MongoDB Preparation Corner Company - Wise Recruitment Process Aptitude Preparation Puzzles Company - Wise Preparation Tutorials Software Development Software Testing Product Management Project Management Linux Excel Cheat Sheets Machine Learning/ Data Science Complete Machine Learning & Data Science Program - [ LIVE ] Data Analytics Training Excel , SQL , Python & PowerBI - [ LIVE ] Data Science Training Program - [ LIVE ] Data Science Course IBM Certification Programming Languages C Programming Data Structures C++ Programming Course Java Programming Course Python Course Clouds/ Devops DevOps Engineering AWS Solutions Architect Certification Salesforce Certified Administrator Course GATE 2026 GATE CS Rank Booster GATE DA Rank Booster GATE CS & Course - 2026 GATE DA Course 2026 GATE Rank Predictor @GeeksforGeeks , Sanchhaya Education Private Limited , rights reserved use cookies ensure best browsing experience website . site , 

         acknowledge read understood Cookie Policy & Privacy Policy Got ! Improvement Suggest changes Suggest Changes Help improve . Share suggestions enhance article . Contribute expertise difference GeeksforGeeks portal . Create Improvement Enhance article expertise . Contribute GeeksforGeeks community help create better learning resources . Suggest Changes min 4 words , max Words Limit:1000 Thank ! suggestions valuable . kind Experience want share ? Interview Experiences Admission Experiences Career Journeys Work Experiences Campus Experiences Competitive Exam Experiences