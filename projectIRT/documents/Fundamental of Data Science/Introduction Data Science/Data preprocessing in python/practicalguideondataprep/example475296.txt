Data Preprocessing Python | Sklearn Preprocessing Master Generative AI 10 + Real - world Projects 2025 ! d : h : m : s Download Projects Free Courses Learning Paths GenAI Pinnacle Plus New Agentic AI Pioneer DHS 2025 Login Switch Mode Logout Interview Prep Career GenAI Prompt Engg ChatGPT LLM Langchain RAG AI Agents Machine Learning Deep Learning GenAI Tools LLMOps Python NLP SQL AIML Projects Reading list Intoduction Python Brief Introduction Python Installing Python Windows , Linux , Mac Jupyter Notebook Google Colab Variables data types Variables Datatypes OOPs Concepts OOPs Concepts Conditional statement Conditional Statements Looping Constructs Looping Constructs Iterators Generators Data Structures Data Structures List Tuples Sets Dictionary String Manipulation Strings Functions Functions Lambda Functions Recursion Modules , Packages Standard Libraries Introduction Modules python Python Libraries Data Science Introduction Python Libraries Data Science Basics Numpy Basics Pandas Basics Matplotlib Basics Statsmodel Reading Data Files Python Reading Commonly File Formats Reading CSV files Reading Big CSV files Reading Excel & Spreadsheet Files Preprocessing , Subsetting Modifying Pandas Dataframes Subsetting Modifying Data Loc vs ILoc Sorting Aggregating Data Pandas Preprocessing , Sorting Aggregating Data Concatenating Dataframes Aggregating Summarizing Dataframes Data Munging Visualizing Patterns Trends Data Visualizing Patterns Trends Data Basics Matplotlib Basics Seaborn Data Visualization Seaborn Exploring Data Python Programming Tips Technique Optimize Python Code Home Business Analytics Practical Guide Data Preprocessing Python Scikit Learn Practical Guide Data Preprocessing Python Scikit Learn s syed Updated : 
                                 21 Oct , 2024 10 min read Introduction article primarily focuses data pre - processing techniques python . Learning algorithms affinity certain data types   perform incredibly . known   reckless   predictions unscaled unstandardized features .   Algorithm like XGBoost , specifically requires dummy encoded data algorithm like decision tree care ( ) ! simple words , pre - processing refers   transformations applied data feeding algorithm . python , scikit - learn library pre - built functionality sklearn.preprocessing . options pre - processing explore . finishing article , equipped basic techniques data pre - processing - depth understanding . convenience , attached resources - depth learning machine learning algorithms designed exercises good grip concepts . Available Data set article , subset Loan Prediction ( missing value observations dropped ) data set download final training testing data set : Download Data Note : Testing data provided subset training data Loan Prediction problem . , lets started importing important packages data set . # Importing pandas > > import pandas pd # Importing training data set > > X_train = pd.read_csv('X_train.csv ' ) 
 > > Y_train = pd.read_csv('Y_train.csv ' ) # Importing testing data set > > X_test = pd.read_csv('X_test.csv ' ) 
 > > Y_test = pd.read_csv('Y_test.csv ' ) Lets closer look data set . > > print ( X_train.head ( ) ) Loan_ID Gender Married Dependents Education Self_Employed 
 15    LP001032    Male                 0   Graduate               
 248   LP001824    Male      Yes           1   Graduate               
 590   LP002928    Male      Yes           0   Graduate               
 246   LP001814    Male      Yes           2   Graduate               
 388   LP002244    Male      Yes           0   Graduate               

      ApplicantIncome   CoapplicantIncome   LoanAmount   Loan_Amount_Term 
 15               4950                 0.0        125.0              360.0   
 248              2882              1843.0        123.0              480.0   
 590              3000              3416.0         56.0              180.0   
 246              9703                 0.0        112.0              360.0   
 388              2333              2417.0        136.0              360.0   

      Credit_History Property_Area  
 15               1.0          Urban  
 248              1.0      Semiurban  
 590              1.0      Semiurban  
 246              1.0          Urban  
 388              1.0          Urban Feature Scaling Feature scaling method   limit range variables compared common grounds .   performed continuous variables .   Lets plot distribution continuous variables   data set . > > import matplotlib.pyplot plt 
 > > X_train[X_train.dtypes[(X_train.dtypes=="float64")|(X_train.dtypes=="int64 " ) ] 
                         .index.values].hist(figsize=[11,11 ] ) understanding   plots , infer   ApplicantIncome CoapplicantIncome similar range ( 0 - 50000 $ ) LoanAmount thousands ranges 0 600$. story Loan_Amount_Term completely different variables unit months opposed variables unit dollars .   try apply distance based methods kNN features , feature largest range dominate outcome results obtain accurate predictions . overcome trouble feature scaling . Let practically . Resources : Check   article kNN better understanding . Wow ! ! got accuracy 63 % guessing , meaning , getting better accuracy prediction model ? happening insignificant variable larger range dominating objective function . remove problem scaling features range . sklearn provides tool MinMaxScaler scale features 0 1 . Mathematical formula MinMaxScaler . Lets try tool problem . # Importing MinMaxScaler initializing > > sklearn.preprocessing import MinMaxScaler 
 > > min_max = MinMaxScaler ( ) # Scaling train test data set > > X_train_minmax = min_max.fit_transform(X_train[['ApplicantIncome ' , ' CoapplicantIncome ' , 
                 ' LoanAmount ' , ' Loan_Amount_Term ' , ' Credit_History ' ] ] ) 
 > > X_test_minmax = min_max.fit_transform(X_test[['ApplicantIncome ' , ' CoapplicantIncome ' , 
                 ' LoanAmount ' , ' Loan_Amount_Term ' , ' Credit_History ' ] ] ) , scaling , lets apply kNN scaled data check accuracy . # Fitting k - NN scaled data set > > knn = KNeighborsClassifier(n_neighbors=5 ) 
 > > knn.fit(X_train_minmax , Y_train ) # Checking model accuracy > > accuracy_score(Y_test , knn.predict(X_test_minmax ) ) : 0.75 Great ! ! accuracy   increased 61 % 75 % . means features larger range   dominating prediction outcome domain distance based methods(kNN ) . kept mind performing distance based methods attempt   scale data , feature lesser significance end dominating objective function larger range . addition ,   features having different unit scaled providing feature equal initial weightage end better prediction model . Exercise 1 Try exercise logistic regression model(parameters : penalty=’l2′,C=0.01 ) provide accuracy scaling comment section . Feature Standardization jumping section suggest complete Exercise 1 . previous section , worked Loan_Prediction data set fitted kNN learner data set .   scaling data , got accuracy 75 % considerably good . tried exercise Logistic Regression got following result : Scaling : 61 % Scaling : 63 % accuracy got scaling close prediction guessing , impressive achievement . , happening ? accuracy increased satisfactory increased kNN ? Resources : article Logistic Regression better understanding . answer : logistic regression , feature assigned weight coefficient ( Wi ) . feature relatively large range insignificant objective function logistic regression assign low value co - efficient , neutralizing dominant effect particular feature , distance based method kNN inbuilt strategy , requires scaling . forgetting ? logistic model predicting accuracy closer guess . ,   introducing new concept called standardization . machine learning algorithms sklearn requires standardized data means having zero mean unit variance . Standardization ( Z - score normalization ) process features   rescaled properties standard normal distribution μ = 0 σ = 1 ,   μ mean ( average ) σ standard deviation mean . Standard scores ( called z scores ) samples calculated follows : Elements l1 , l2 regularizer linear models ( logistic comes category ) RBF kernel SVM objective function learners assumes features centered zero variance order . Features having larger order variance   dominate objective function happened previous section feature having large range . saw Exercise 1 preprocessing data accuracy 61 % , lets standardize data apply logistic regression . Sklearn provides scale standardize data . # Standardizing train test data > > sklearn.preprocessing import scale 
 > > X_train_scale = scale(X_train[['ApplicantIncome ' , ' CoapplicantIncome ' , 
                 ' LoanAmount ' , ' Loan_Amount_Term ' , ' Credit_History ' ] ] ) 
 > > X_test_scale = scale(X_test[['ApplicantIncome ' , ' CoapplicantIncome ' , 
                ' LoanAmount ' , ' Loan_Amount_Term ' , ' Credit_History ' ] ] ) # Fitting logistic regression standardized data set > > sklearn.linear_model import LogisticRegression 
 > > log = LogisticRegression(penalty='l2',C=.01 ) 
 > > log.fit(X_train_scale , Y_train ) # Checking model accuracy > > accuracy_score(Y_test , log.predict(X_test_scale ) ) : 0.75 reached maximum score attained   kNN scaling .   means standardizing data estimator having l1 l2 regularization helps increase accuracy prediction model . learners like kNN euclidean distance measure , k - means , SVM , perceptron , neural networks , linear discriminant analysis , principal component analysis   perform better standardized data . ,   suggest understand data kind algorithm going apply ; time able judge weather standardize data . Note : Choosing scaling standardizing confusing choice , dive deeper data learner going use reach decision . starters , try methods check cross validation score making choice . Resources : article cross validation better understanding . Exercise 2 Try exercise SVM model provide accuracy standardization comment section . Resources : article support vector machines better understanding . Label Encoding previous sections ,   pre - processing continuous numeric features . , data set features Gender , Married , Dependents , Self_Employed Education . categorical features string values . example , Gender levels Male Female . Lets feed features logistic regression model . # Fitting logistic regression model data > > log = LogisticRegression(penalty='l2',C=.01 ) 
 > > log.fit(X_train , Y_train ) # Checking model accuracy > > accuracy_score(Y_test , log.predict(X_test ) ) : ValueError : convert string float : Semiurban got error saying convert string float . , actually happening learners like logistic regression , distance based methods kNN , support vector machines , tree based methods etc . sklearn needs numeric arrays . Features having string values handled learners . Sklearn provides efficient tool encoding levels categorical features numeric values . LabelEncoder encode labels value 0 n_classes-1 . Lets encode categorical features . # Importing LabelEncoder initializing > > sklearn.preprocessing import LabelEncoder 
 > > le = LabelEncoder ( ) # Iterating common columns train test > > col X_test.columns.values : # Encoding categorical variables X_test[col].dtypes=='object ' : # data form exhaustive list levels data = X_train[col].append(X_test[col ] ) 
        le.fit(data.values ) 
        X_train[col]=le.transform(X_train[col ] ) 
        X_test[col]=le.transform(X_test[col ] ) categorical features encoded . look updated data set X_train.head ( ) . going look Gender frequency distribution encoding . : Male 318 
          Female 66 
 : Gender , dtype : int64 : 1 318 
         0 66 
 : Gender , dtype : int64 label encoding , lets run logistic regression model data set categorical continuous features . # Standardizing features > > X_train_scale = scale(X_train ) 
 > > X_test_scale = scale(X_test ) # Fitting logistic regression model > > log = LogisticRegression(penalty='l2',C=.01 ) 
 > > log.fit(X_train_scale , Y_train ) # Checking models accuracy > > accuracy_score(Y_test , log.predict(X_test_scale ) ) : 0.75 working . , accuracy got   logistic regression standardization numeric features .   means categorical features added significant objective function . Exercise 3 Try decision tree classifier features independent variables comment accuracy . Resources : article decision trees better understanding . - Hot Encoding - Hot Encoding transforms categorical feature n possible values n binary features , active . ML algorithms learn single weight feature computes distance samples . Algorithms like linear models ( logistic regression ) belongs category . Lets look example loan_prediction data set . Feature Dependents 4 possible values 0,1,2 3 + encoded loss generality 0,1,2 3 . , weight “ W ” assigned feature linear classifier , decision based constraints W*Dependents + K > 0 eqivalently W*Dependents < K . Let f(w)= W*Dependents Possible values attained equation 0 , W , 2W 3W. problem equation weight “ W ” decision based choices . reach decision following ways : leads decision ( < K vice versa ) 3:1 division levels ( Decision boundary f(w)>2W ) 2:2 division levels ( Decision boundary f(w)>W ) loosing different possible decisions case “ 0 ” “ 2W ” given label “ 3W ” “ W ” odd . problem solved - Hot - Encoding effectively changes dimensionality feature “ Dependents ” , value feature “ Dependents ” weights . Updated equation decison f'(w ) < K . , f'(w ) = W1*D_0 + W2*D_1 + W3*D_2 + W4*D_3 new variable boolean values ( 0 1 ) . thing happens   distance based methods kNN . encoding , distance “ 0 ” “ 1 ” values Dependents 1 distance “ 0 ” “ 3 + ” 3 , desirable distances similar . encoding , values new features ( sequence columns 0,1,2,3 + ) : [ 1,0,0,0 ] [ 0,0,0,1 ] ( initially finding distance “ 0 ” “ 3 + ” ) , distance √2 . tree based methods , situation ( values feature ) effect outcome extent methods like random forests deep , handle categorical variables - hot encoding . , lets look implementation - hot encoding algorithms . Lets create logistic regression model classification - hot encoding . # scaled variable saw previous section # scaling effect algo l1 l2 reguralizer > > X_train_scale = scale(X_train ) 
 > > X_test_scale = scale(X_test ) # Fitting logistic regression model > > log = LogisticRegression(penalty='l2',C=1 ) 
 > > log.fit(X_train_scale , Y_train ) # Checking model accur acy > > accuracy_score(Y_test , log.predict(X_test_scale ) ) : 0.73958333333333337 going encode data . > > sklearn.preprocessing import OneHotEncoder 
 > > enc = OneHotEncoder(sparse = False ) 
 > > X_train_1 = X_train 
 > > X_test_1 = X_test 
 > > columns=['Gender ' , ' Married ' , ' Dependents ' , ' Education','Self_Employed ' , 
           ' Credit_History ' , ' Property_Area ' ] 
 > > col columns : # creating exhaustive list possible categorical values data = X_train[[col]].append(X_test[[col ] ] ) 
        enc.fit(data ) # Fitting Hot Encoding train data temp = enc.transform(X_train[[col ] ] ) # Changing encoded features data frame new column names temp = pd . DataFrame(temp , columns=[(col+"_"+str(i ) ) data[col ] 
             .value_counts().index ] ) # concatenation index values # Setting index values similar X_train data frame temp = temp.set_index(X_train.index.values ) # adding new Hot Encoded varibales train data frame X_train_1 = pd.concat([X_train_1,temp],axis=1 ) # fitting Hot Encoding test data temp = enc.transform(X_test[[col ] ] ) # changing data frame adding column names temp = pd . DataFrame(temp , columns=[(col+"_"+str(i ) ) data[col ] 
             .value_counts().index ] ) # Setting index proper concatenation temp = temp.set_index(X_test.index.values ) # adding new Hot Encoded varibales test data frame X_test_1 = pd.concat([X_test_1,temp],axis=1 ) , lets apply logistic regression model - hot encoded data . # Standardizing data set > > X_train_scale = scale(X_train_1 ) 
 > > X_test_scale = scale(X_test_1 ) # Fitting logistic regression model > > log = LogisticRegression(penalty='l2',C=1 ) 
 > > log.fit(X_train_scale , Y_train ) # Checking model accuracy > > accuracy_score(Y_test , log.predict(X_test_scale ) ) : 0.75 , got maximum accuracy 0.75 gotten far . case ,   logistic regression regularization(C ) parameter 1 earlier C=0.01 . End Notes aim article familiarize basic data pre - processing techniques deeper understanding situations apply techniques . methods work underlying assumptions algorithms . means exhaustive list methods .   encourage     experiment methods heavily modified according problem hand . comprehensive guide data preprocessing , check course , “ Preprocess Data . “ plan provide advance techniques data pre - processing pipeline noise reduction post , stay tuned dive deeper data pre - processing . like reading article ? follow different approach / package / library perform talks . love interact comments .   test skills knowledge .   Check Live   Competitions compete best   Data Scientists world . s syed Syed Danish , currently pursuing bachelors Electronics & Communication Engineering ISM Dhanbad . data science machine learning enthusiast . Business Analytics Classification Data Exploration Intermediate Libraries Machine Learning Programming Python Python Structured Data Supervised Login continue reading enjoy expert - curated content . Reading Free Free Courses 4.7 Generative AI - Way Life Explore Generative AI beginners : create text images , use AI tools , learn practical skills , ethics . 4.5 Getting Started Large Language Models Master Large Language Models ( LLMs ) course , offering clear guidance NLP model training simple . 4.6 Building LLM Applications Prompt Engineering free course guides building LLM apps , mastering prompt engineering , developing chatbots enterprise data . 4.8 Improving Real World RAG Systems : Key Challenges & Practical Solutions Explore practical solutions , advanced retrieval strategies , agentic RAG systems improve context , relevance , accuracy AI - driven applications . 4.7 Microsoft Excel : Formulas & Functions Master MS Excel data analysis key formulas , functions , LookUp tools comprehensive course . Recommended Articles 10 Machine Learning Algorithms 2025 Comprehensive Guide Ensemble Learning ( wit ... Cook data Machine Learning Algorithm Organised Preprocessing Pandas Dataframe 12 Useful Pandas Techniques Python Data ... Practicing Machine Learning Techniques R wit ... Complete guide learn Scikit - Learn ... Understand Concept Standardization Ma ... Logistic Regression Python : Beginner ... Guide Building End - - End Logistic Regre ... Responses Readers Cancel reply Clear Submit reply Δ DR Venugopala Rao Manneni Useful ... 123 Cancel reply Clear Submit reply Δ Oluwadara Thanks post . useful ! 123 Cancel reply Clear Submit reply Δ Mukul Feature scaling code 

 X_train[X_train.dtypes[(X_train.dtypes=="float64")|(X_train.dtypes=="int64")].index.values].hist(figsize=[11,11 ] ) 

 working . wrong . 123 2 Cancel reply Clear Submit reply Δ 2 reply syed danish problem formatting inverted commas , Thanks bringing attention . 123 456 Cancel reply Clear Submit reply Δ Mukul thanks lot . . 123 456 Cancel reply Clear Submit reply Δ View Write Write , captivate , earn accolades rewards work Reach Global Audience Expert Feedback Build Brand & Audience Cash Knowledge Join Thriving Community Level Data Science Game use cookies essential site function . click help improve usefulness additional cookies . Learn use cookies Privacy Policy & Cookies Policy . details Accept cookies Use necessary cookies Powered Consent Details Cookies site uses cookies ensure best experience possible . learn use cookies , refer Privacy Policy & Cookies Policy . Necessary ( 2 ) Necessary cookies help website usable enabling basic functions like page navigation access secure areas website . website function properly cookies . Analytics Vidhya ( 4 ) learn analytics vidhya privacy brahmaid needed personalizing website . Expiry : Session Type : HTTP csrftoken cookie prevent Cross - site request forgery ( abbreviated CSRF ) attacks website Expiry : Session Type : HTTPS Identityid Preserves login / logout state users site . Expiry : Session Type : HTTPS sessionid Preserves users ' states page requests . Expiry : Session Type : HTTPS Google ( 1 ) learn google privacy g_state Google - Tap login adds g_state cookie set user status interact - Tap modal . Expiry : 365 days Type : HTTP Statistics ( 4 ) Statistic cookies help website owners understand visitors interact websites collecting reporting information anonymously . Microsoft ( 7 ) learn microsoft policy MUID Microsoft Clarity , store track visits websites . Expiry : 1 Year Type : HTTP _ clck Microsoft Clarity , Persists Clarity User ID preferences , unique site , browser . ensures behavior subsequent visits site attributed user ID . Expiry : 1 Year Type : HTTP _ clsk Microsoft Clarity , Connects multiple page views user single Clarity session recording . Expiry : 1 Day Type : HTTP SRM_I Collects user data specifically adapted user device . user followed outside loaded website , creating picture visitor behavior . Expiry : 2 Years Type : HTTP SM Use measure use website internal analytics Expiry : 1 Years Type : HTTP CLID cookie set embedded Microsoft Clarity scripts . purpose cookie heatmap session recording . Expiry : 1 Year Type : HTTP SRM_B Collected user data specifically adapted user device . user followed outside loaded website , creating picture visitor behavior . Expiry : 2 Months Type : HTTP Google ( 7 ) learn google privacy _ gid cookie installed Google Analytics . cookie store information visitors use website helps creating analytics report website . data collected includes number visitors , source come , pages visited anonymous form . Expiry : 399 Days Type : HTTP _ ga _ # Google Analytics , store count pageviews . Expiry : 399 Days Type : HTTP _ gat _ # Google Analytics collect data number times user visited website dates recent visit . Expiry : 1 Day Type : HTTP collect send data Google Analytics visitor device behavior . Tracks visitor devices marketing channels . Expiry : Session Type : PIXEL AEC cookies ensure requests browsing session user , sites . Expiry : 6 Months Type : HTTP G_ENABLED_IDPS use cookie customers want referral gmail contacts ; helps auth gmail account . Expiry : 2 Years Type : HTTP test_cookie cookie set DoubleClick ( owned Google ) determine website visitor browser supports cookies . Expiry : 1 Year Type : HTTP Webengage ( 2 ) Learn webengage privacy _ we_us send push notification webengage . Expiry : 1 Year Type : HTTP WebKlipperAuth webenage track auth webenagage . Expiry : Session Type : HTTP LinkedIn ( 16 ) learn linkedin privacy ln_or Linkedin sets cookie registers statistical data users ' behavior website internal analytics . Expiry : 1 Day Type : HTTP JSESSIONID Use maintain anonymous user session server . Expiry : 1 Year Type : HTTP li_rm LinkedIn Remember feature set user clicks Remember device easier sign device . Expiry : 1 Year Type : HTTP AnalyticsSyncHistory store information time sync lms_analytics cookie took place users Designated Countries . Expiry : 6 Months Type : HTTP lms_analytics store information time sync AnalyticsSyncHistory cookie took place users Designated Countries . Expiry : 6 Months Type : HTTP liap Cookie Sign - Linkedin and/or allow Linkedin follow feature . Expiry : 6 Months Type : HTTP visit allow Linkedin follow feature . Expiry : 1 Year Type : HTTP li_at identify , including , interests , previous activity . Expiry : 2 Months Type : HTTP s_plt Tracks time previous page took load Expiry : Session Type : HTTP lang remember user language setting ensure LinkedIn.com displays language selected user settings Expiry : Session Type : HTTP s_tp Tracks percent page viewed Expiry : Session Type : HTTP AMCV_14215E3D5995C57C0A495C55%40AdobeOrg Indicates start session Adobe Experience Cloud Expiry : Session Type : HTTP s_pltp Provides page value ( URL ) use Adobe Analytics Expiry : Session Type : HTTP s_tslv retain fetch time visit Adobe Analytics Expiry : 6 Months Type : HTTP li_theme Remembers user display preference / theme setting Expiry : 6 Months Type : HTTP li_theme_set Remembers users updated display / theme preferences Expiry : 6 Months Type : HTTP Preferences ( 0 ) Preference cookies enable website remember information changes way website behaves looks , like preferred language region . use cookies type . Marketing ( 4 ) Marketing cookies track visitors websites . intention display ads relevant engaging individual user valuable publishers party advertisers . Google ( 11 ) learn google privacy _ gcl_au Google Adsense , store track conversions . Expiry : 3 Months Type : HTTP SID Save certain preferences , example number search results page activation SafeSearch Filter . Adjusts ads appear Google Search . Expiry : 2 Years Type : HTTP SAPISID Save certain preferences , example number search results page activation SafeSearch Filter . Adjusts ads appear Google Search . Expiry : 2 Years Type : HTTP _ _ Secure- # Save certain preferences , example number search results page activation SafeSearch Filter . Adjusts ads appear Google Search . Expiry : 2 Years Type : HTTP APISID Save certain preferences , example number search results page activation SafeSearch Filter . Adjusts ads appear Google Search . Expiry : 2 Years Type : HTTP SSID Save certain preferences , example number search results page activation SafeSearch Filter . Adjusts ads appear Google Search . Expiry : 2 Years Type : HTTP HSID Save certain preferences , example number search results page activation SafeSearch Filter . Adjusts ads appear Google Search . Expiry : 2 Years Type : HTTP DV cookies purpose targeted advertising . Expiry : 6 Hours Type : HTTP NID cookies purpose targeted advertising . Expiry : 1 Month Type : HTTP 1P_JAR cookies gather website statistics , track conversion rates . Expiry : 1 Month Type : HTTP OTZ Aggregate analysis website visitors Expiry : 6 Months Type : HTTP Facebook ( 2 ) learn facebook privacy _ fbp cookie set Facebook deliver advertisements Facebook digital platform powered Facebook advertising visiting website . Expiry : 4 Months Type : HTTP fr Contains unique browser user ID , targeted advertising . Expiry : 2 Months Type : HTTP LinkedIn ( 6 ) Learn linkedin policy bscookie LinkedIn track use embedded services . Expiry : 1 Year Type : HTTP lidc LinkedIn tracking use embedded services . Expiry : 1 Day Type : HTTP bcookie LinkedIn track use embedded services . Expiry : 6 Months Type : HTTP aam_uuid Use cookies assign unique ID users visit website . Expiry : 6 Months Type : HTTP UserMatchHistory cookies set LinkedIn advertising purposes , including : tracking visitors relevant ads presented , allowing users use ' Apply LinkedIn ' ' Sign - LinkedIn ' functions , collecting information visitors use site , etc . Expiry : 6 Months Type : HTTP li_sugr probabilistic match user identity outside Designated Countries Expiry : 90 Days Type : HTTP Microsoft ( 2 ) Learn microsoft privacy . MR collect information analytics purposes . Expiry : 1 year Type : HTTP ANONCHK store session ID users session ensure clicks adverts Bing search engine verified reporting purposes personalisation Expiry : 1 Day Type : HTTP UnclassNameified ( 0 ) UnclassNameified cookies cookies process classNameifying , providers individual cookies . use cookies type . Cookie declaration updated 24/03/2023 Analytics Vidhya . Cookies small text files websites user experience efficient . law states store cookies device strictly necessary operation site . types cookies , need permission . site uses different types cookies . cookies placed - party services appear pages . Learn , contact , process personal data Privacy Policy . Accept cookies Use necessary cookies Flagship Programs GenAI Pinnacle Program | GenAI Pinnacle Plus Program | AI / ML BlackBelt Program | Agentic AI Pioneer Program Free Courses Generative AI | DeepSeek | OpenAI Agent SDK | LLM Applications Prompt Engineering | DeepSeek Scratch | Stability . AI | SSM & MAMBA | RAG Systems LlamaIndex | Building LLMs Code | Python | Microsoft Excel | Machine Learning | Deep Learning | Mastering Multimodal RAG | Introduction Transformer Model | Bagging & Boosting | Loan Prediction | Time Series Forecasting | Tableau | Business Analytics | Vibe Coding Windsurf | Model Deployment FastAPI | Building Data Analyst AI Agent | Getting started OpenAI o3 - mini | Introduction Transformers Attention Mechanisms Popular Categories AI Agents | Generative AI | Prompt Engineering | Generative AI Application | News | Technical Guides | AI Tools | Interview Preparation | Research Papers | Success Stories | Quiz | Use Cases | Listicles Generative AI Tools Techniques GANs | VAEs | Transformers | StyleGAN | Pix2Pix | Autoencoders | GPT | BERT | Word2Vec | LSTM | Attention Mechanisms | Diffusion Models | LLMs | SLMs | Encoder Decoder Models | Prompt Engineering | LangChain | LlamaIndex | RAG | Fine - tuning | LangChain AI Agent | Multimodal Models | RNNs | DCGAN | ProGAN | Text - - Image Models | DDPM | Document Question Answering | Imagen | T5 ( Text - - Text Transfer Transformer ) | Seq2seq Models | WaveNet | Attention Need ( Transformer Architecture ) | WindSurf | Cursor Popular GenAI Models Llama 4 | Llama 3.1 | GPT 4.5 | GPT 4.1 | GPT 4o | o3 - mini | Sora | DeepSeek R1 | DeepSeek V3 | Janus Pro | Veo 2 | Gemini 2.5 Pro | Gemini 2.0 | Gemma 3 | Claude Sonnet 3.7 | Claude 3.5 Sonnet | Phi 4 | Phi 3.5 | Mistral Small 3.1 | Mistral NeMo | Mistral-7b | Bedrock | Vertex AI | Qwen QwQ 32B | Qwen 2 | Qwen 2.5 VL | Qwen Chat | Grok 3 AI Development Frameworks n8n | LangChain | Agent SDK | A2A Google | SmolAgents | LangGraph | CrewAI | Agno | LangFlow | AutoGen | LlamaIndex | Swarm | AutoGPT Data Science Tools Techniques Python | R | SQL | Jupyter Notebooks | TensorFlow | Scikit - learn | PyTorch | Tableau | Apache Spark | Matplotlib | Seaborn | Pandas | Hadoop | Docker | Git | Keras | Apache Kafka | AWS | NLP | Random Forest | Computer Vision | Data Visualization | Data Exploration | Big Data | Common Machine Learning Algorithms | Machine Learning | Google Data Science Agent Company Contact Careers Discover Blogs Expert Sessions Learning Paths Comprehensive Guides Learn Free Courses AI&ML Program Pinnacle Plus Program Agentic AI Program Engage Community Hackathons Events Podcasts Contribute Author Speaker Mentor Instructor Enterprise Offerings Trainings Data Culture AI Newsletter Terms & conditions Refund Policy Privacy Policy Cookies Policy © Analytics Vidhya 2025.All rights reserved . Free Course GenAI Landscape Beginner Level 1 Hour Duration Enroll Free Know SKIP Continue learning FREE Login Google Login Email Forgot password ? accept Terms Conditions Receive updates WhatsApp Enter email address continue Email address OTP Enter OTP sent Edit Enter OTP Resend OTP Resend OTP 45s Verify OTP