Evaluating Machine Learning Model Performance Python * * * New Feature Release * * * “ Datatron 3.0 ” – JupyterHub Integration , Kubernetes Management , Model Autocontainerization … New Features ! Datatron Platform MLOps AI Model Monitoring & AI Governance Enterprise - ready Works Solutions Business Executive Data Scientist Engineering / DevOps Learn MLOps & AI Governance 101 MLOps ? AI Governance ? Model Governance ? Model Risk Management ? Events Webinars Whitepapers Blog Company Datatron Press Contact Contact Platform MLOps AI Model Monitoring & AI Governance Enterprise - ready Works Solutions Business Executive Data Scientist Engineering / DevOps Learn MLOps & AI Governance 101 MLOps ? AI Governance ? Model Governance ? Model Risk Management ? Events Webinars Whitepapers Blog Company Datatron Press Contact Contact Datatron Blog Stay Current AI / ML Blog Category Machine Learning Python Search Search Search Evaluate Machine Learning Models Python Code ! finally built machine learning model predict future prices Bitcoin finally multi - billionaire . know model created good ? article , going talk ways evaluate machine learning model code provided ! parts article : ) Evaluating Regression Models B ) Evaluating Classification Models know difference regression classification models , check . specifically , going cover following metrics : R - Squared Adjusted R - Squared Mean Absolute Error Mean Squared Error Confusion Matrix related metrics F1 Score AUC - ROC Curve ) Evaluating Regression Models 1 . R - Squared R Square measurement tells extent proportion variance dependent variable explained variance independent variables . simpler terms , coefficients estimate trends , R - squared represents scatter line best fit . example , R² 0.80 , 80 % variation explained model inputs . R² 1.0 100 % , means movements dependent variable entirely explained movements independent variables . visual example , despite having line best fit , R² right higher left . Comparison model low R² vs high R² equation R² follows : Explained Variation equal sum squared residuals total variation equal total sum squared . understand R² , code straightforward ! sklearn.metrics import r2_score sklearn.metrics . r2_score ( y_true , y_pred ) 2 . Adjusted R - Squared additional independent variable added model increases R² value — , model independent variables better fit . Adjusted R² comes . adjusted R² compensates additional independent variable increases given variable improves model possible probability . couple ways find adjusted R² Python : Option 1 : Manual Calculation # n = number sample size # p = number independent variables Adj_r2 = 1-(1 - R2)*(n-1)/(n - p-1 ) Option 2 : statsmodel.api import statsmodels.api sm statsmodels.sandbox.regression.predstd import wls_prediction_std model1 = sm . OLS(y_train , x_train ) result = model1.fit ( ) print(result.summary ( ) ) 3 . Mean Absolute Error ( MAE ) absolute error difference predicted values actual values . , mean absolute error average absolute error . importing mean_absolute_error sklearn.metrics , compute easily compute MAE model . sklearn.metrics import mean_absolute_error mean_absolute_error(y_true , y_pred ) 4 . Mean Squared Error ( MSE ) mean squared error MSE similar MAE , average squared differences predicted values actual values . differences squared , larger errors weighted highly , MAE want minimize large errors . equation MSE , code . sklearn.metrics import mean_squared_error mean_squared_error(y_true , y_pred ) Infographic MLOps Maturity Model [ M3 ] Infographic , learn : stages maturity Machine Learning Operations , i.e. , MLOps DevOps ML software , MLOps needed ideal teams , stacks , features look reach Maturity ML program Learn companies succeed , struggle AI / ML seeing signatures success Ideation , Team , Stack , Process , & Outcome informative ( Hi - res ) Infographic . Infographic : MLOps Maturity Model [ M3 ] * : * Business Email : * Job Title * Company : * hear Datatron ? * Select ... Event Search Engine ( Google , Bing , ... ) Social Media News Referral B ) Evaluating Classification Models 5 . Confusion Matrix related metrics confusion matrix , known error matrix , performance measurement assessing classification models . example - class confusion matrix . confusion matrix , terms need know , calculate metrics : True Positive : Outcome model correctly predicts positive class . True Negative : Outcome model correctly predicts negative class . False Positive ( Type 1 Error ) : Outcome model incorrectly predicts positive class . False Negative ( Type 2 Error ) : Outcome model incorrectly predicts negative class . know terms , number metrics calculate : Accuracy : equal fraction predictions model got right . Recall : attempts answer “ proportion actual positives identified correctly ? ” Precision : attempts answer “ proportion positive identifications actually correct ? ” hit home , diagram great way remember difference precision recall ( certainly helped ) ! Taken Wikipedia Code confusion matrix related metrics : # Confusion Matrix sklearn.metrics import confusion_matrix confusion_matrix(y_true , y_pred ) # Accuracy sklearn.metrics import accuracy_score accuracy_score(y_true , y_pred ) # Recall sklearn.metrics import recall_score recall_score(y_true , y_pred , average = ) # Precision sklearn.metrics import precision_score precision_score(y_true , y_pred , average = ) Formula F1 Score F1 score measure test accuracy — harmonic mean precision recall . maximum score 1 ( perfect precision recall ) minimum 0 . Overall , measure preciseness robustness model . ways calculate F1 score Python : # Method 1 : sklearn sklearn.metrics import f1_score f1_score(y_true , y_pred , average = ) # Method 2 : Manual Calculation F1 = 2 * ( precision * recall ) / ( precision + recall ) # Method 3 : BONUS – classification report sklearn.metrics import classification_report print(classification_report(y_true , y_pred , target_names = target_names ) ) 7 . AUC - ROC Curve AUC - ROC Curve performance measurement classification problems tells model capable distinguishing classes . higher AUC means model accurate . want learn , Sarang great job explaining . calculate AUC - ROC score , replicate code : import numpy np sklearn.metrics import roc_auc_score y_true = np.array([0 , 0 , 1 , 1 ] ) y_scores = np.array([0.1 , 0.4 , 0.35 , 0.8 ] ) roc_auc_score(y_true , y_scores ) 0.75 ! know evaluate machine learning models determine actually useful . , ways improve machine learning model . articles like , check https://blog.datatron.com/ Thanks Reading ! Datatron , offer platform govern manage Machine Learning , Artificial Intelligence , Data Science Models Production . Additionally , help automate , optimize , accelerate ML models ensure running smoothly efficiently production   —   learn services sure Book Demo . Infographic MLOps Maturity Model [ M3 ] Infographic , learn : stages maturity Machine Learning Operations , i.e. , MLOps DevOps ML software , MLOps needed ideal teams , stacks , features look reach Maturity ML program Learn companies succeed , struggle AI / ML seeing signatures success Ideation , Team , Stack , Process , & Outcome informative ( Hi - res ) Infographic . Infographic : MLOps Maturity Model [ M3 ] * : * Business Email : * Job Title * Company : * hear Datatron ? * Select ... Event Search Engine ( Google , Bing , ... ) Social Media News Referral BLOG Artificial Intelligence Transforming Business 2020 Datatron Technologies previous BLOG Statistical Bias Important Data Science ? Datatron Technologies whitepaper Datatron 3.0 Product Release – Enterprise Feature Enhancements Streamlined features improve operational workflows , enforce enterprise - grade security , simplify troubleshooting . Whitepaper whitepaper Datatron 3.0 Product Release – Simplified Kubernetes Management Eliminate complexities Kubernetes management deploy new virtual private cloud environments clicks . Whitepaper whitepaper Datatron 3.0 Product Release – JupyterHub Integration Datatron continues lead way simplifying data scientist workflows delivering value AI / ML new JupyterHub integration “ Datatron 3.0 ” product release . Whitepaper whitepaper Success Story : Global Bank Monitors 1,000 Models Datatron global bank looking AI Governance platform discovered . Datatron , executives easily monitor “ Health ” thousands models , data scientists decreased time required identify issues models uncover root cause 65 % , BU decreased audit reporting time 65 % . Whitepaper whitepaper Success Story : Domino 10x Model Deployment Velocity Domino looking AI Governance platform discovered . Datatron , Domino accelerated model deployment 10x , achieved 80 % risk - free model deployments , giving executives global view models helping understand KPI metrics achieved increase ROI . Whitepaper whitepaper 5 Reasons AI / ML Models Stuck Lab AI / ML Executive need ROI AI / ML ? Data Scientist want models production ? ML DevOps Engineer / want easier way manage multiple models . Learn enterprises mature AI / ML programs overcome obstacles operationalize models greater ease manpower . Whitepaper view Platform ModelOps AI Monitoring & AI Governance Enterprise - ready Solutions Business Executive Data Scientist Engineering & DevOps Learn Events Webinars Whitepapers Company Datatron Careers Blog Privacy Policy Terms Service Enterprise - Grade , Production Proven . Reliable AI ™ Reliable AI ™ platform built enterprise Built Love San Francisco , USA ! © Copyright 2025 .   Rights Reserved . San Francisco Web Design Thomas Digital